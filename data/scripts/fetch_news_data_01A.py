#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø± Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ - ÙÙ‚Ø· RSS
Ù†Ø³Ø®Ù‡ Simplified v2.0

ğŸ¯ Ù‡Ø¯Ù: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø·Ù…Ø¦Ù† Ùˆ Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø§Ø®Ø¨Ø§Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ
ğŸ“¡ Ù…Ù†Ø¨Ø¹: ÙÙ‚Ø· RSS Feeds (Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ØŒ Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª)
ğŸš€ Ù…Ø²Ø§ÛŒØ§: Ø±Ø§ÛŒÚ¯Ø§Ù† Ú©Ø§Ù…Ù„ØŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ØŒ Ø§Ø®Ø¨Ø§Ø± Ù…Ø¹ØªØ¨Ø±

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² RSS feeds Ù…Ø¹ØªØ¨Ø± (CoinDesk, CoinTelegraph)
- ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§ VADER
- Ú©Ø´ Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª  
- Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ¶Ø¹ÛŒØª Ø³Ø§Ø¯Ù‡
- Ø®Ø·Ø§ÛŒØ§Ø¨ÛŒ Ù‚ÙˆÛŒ
"""

import pandas as pd
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import time

# ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ import Ú©Ø±Ø¯Ù† feedparser
try:
    import feedparser
    RSS_AVAILABLE = True
except ImportError:
    RSS_AVAILABLE = False
    logging.warning("âš ï¸ feedparser Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install feedparser")

# ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª
try:
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    SENTIMENT_AVAILABLE = True
except ImportError:
    SENTIMENT_AVAILABLE = False
    logging.warning("âš ï¸ vaderSentiment Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install vaderSentiment")

# import Ø§Ø¬Ø²Ø§ÛŒ Ù…Ø´ØªØ±Ú©
from fetch_historical_data_01 import (
    state_manager, rate_limiter, setup_logging,
    safe_request, sanitize_filename, get_user_selection,
    COMMON_SYMBOLS, MAX_NEWS_PER_SYMBOL,
    RAW_DATA_PATH
)

# --- ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ ---
setup_logging('fetch_news_data_01A')

class RSSNewsFetcher:
    """
    Ú©Ù„Ø§Ø³ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² RSS feeds
    
    ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
    - Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª
    - Ú©ÛŒÙÛŒØª Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§Ù„Ø§
    - Ø³Ø±Ø¹Øª Ù…Ù†Ø§Ø³Ø¨ (Ú©Ø´ Ù…Ø­Ù„ÛŒ)
    - Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø±
    """
    
    def __init__(self):
        # RSS feeds Ù…Ø¹ØªØ¨Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ
        self.rss_feeds = {
            'CoinDesk': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
            'CoinTelegraph': 'https://cointelegraph.com/rss',
            'Decrypt': 'https://decrypt.co/feed',
            'CryptoNews': 'https://cryptonews.com/news/feed'
        }
        
        # Ú©Ø´ Ù…Ø­Ù„ÛŒ
        self._feed_cache = {}
        self._last_fetch = {}
        self.cache_duration = 300  # 5 Ø¯Ù‚ÛŒÙ‚Ù‡
        
        # ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª
        if SENTIMENT_AVAILABLE:
            self.sentiment_analyzer = SentimentIntensityAnalyzer()
        else:
            self.sentiment_analyzer = None
        
        logging.info("ğŸ“¡ RSS News Fetcher Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯")
        logging.info(f"ğŸ“° Ù…Ù†Ø§Ø¨Ø¹: {list(self.rss_feeds.keys())}")
    
    def analyze_sentiment(self, text: str) -> Dict[str, float]:
        """
        ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ†
        
        Args:
            text: Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        
        Returns:
            Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø§Ø­Ø³Ø§Ø³Ø§Øª
        """
        if not self.sentiment_analyzer or not text:
            return {'compound': 0, 'neg': 0, 'neu': 1, 'pos': 0}
        
        try:
            scores = self.sentiment_analyzer.polarity_scores(text)
            return scores
        except Exception as e:
            logging.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª: {e}")
            return {'compound': 0, 'neg': 0, 'neu': 1, 'pos': 0}
    
    def fetch_rss_feed(self, feed_name: str, feed_url: str) -> List[Dict]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ÛŒÚ© RSS feed
        
        Args:
            feed_name: Ù†Ø§Ù… feed
            feed_url: Ø¢Ø¯Ø±Ø³ RSS
        
        Returns:
            Ù„ÛŒØ³Øª Ù…Ù‚Ø§Ù„Ø§Øª
        """
        if not RSS_AVAILABLE:
            logging.error("âŒ feedparser Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª")
            return []
        
        current_time = time.time()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´
        if (feed_name in self._last_fetch and 
            current_time - self._last_fetch[feed_name] < self.cache_duration):
            logging.info(f"ğŸ“‹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø¨Ø±Ø§ÛŒ {feed_name}")
            return self._feed_cache.get(feed_name, [])
        
        try:
            logging.info(f"ğŸ“¡ Ø¯Ø±ÛŒØ§ÙØª RSS: {feed_name}")
            
            # Ø§Ø¹Ù…Ø§Ù„ rate limiting
            rate_limiter.wait_if_needed('rss')
            
            # Ø¯Ø±ÛŒØ§ÙØª feed
            feed = feedparser.parse(feed_url)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆÙÙ‚ÛŒØª
            if hasattr(feed, 'status') and feed.status != 200:
                logging.warning(f"âš ï¸ RSS {feed_name} ÙˆØ¶Ø¹ÛŒØª {feed.status} Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯")
                return []
            
            if not hasattr(feed, 'entries') or not feed.entries:
                logging.warning(f"âš ï¸ RSS {feed_name} Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
                return []
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù‚Ø§Ù„Ø§Øª
            articles = []
            for entry in feed.entries[:20]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 20 Ù…Ù‚Ø§Ù„Ù‡
                try:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
                    title = entry.get('title', '').strip()
                    summary = entry.get('summary', '').strip()
                    link = entry.get('link', '')
                    published = entry.get('published', '')
                    
                    # ØªØ±Ú©ÛŒØ¨ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                    full_text = f"{title}. {summary}"
                    
                    # ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                    sentiment = self.analyze_sentiment(full_text)
                    
                    # Ø§ÛŒØ¬Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ù…Ù‚Ø§Ù„Ù‡
                    article = {
                        'timestamp': self._parse_published_date(published),
                        'title': title,
                        'content': summary,
                        'description': summary,
                        'source': feed_name,
                        'url': link,
                        'language': 'en',
                        'api_source': 'RSS',
                        'full_text': full_text,
                        
                        # Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø§Ø­Ø³Ø§Ø³Ø§Øª
                        'sentiment_compound': sentiment['compound'],
                        'sentiment_positive': sentiment['pos'],
                        'sentiment_negative': sentiment['neg'],
                        'sentiment_neutral': sentiment['neu'],
                        
                        # Ø¨Ø±Ú†Ø³Ø¨ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                        'sentiment_label': self._get_sentiment_label(sentiment['compound']),
                        
                        # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
                        'text_length': len(full_text),
                        'title_length': len(title)
                    }
                    
                    articles.append(article)
                    
                except Exception as e:
                    logging.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù‚Ø§Ù„Ù‡ {feed_name}: {e}")
                    continue
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
            self._feed_cache[feed_name] = articles
            self._last_fetch[feed_name] = current_time
            
            logging.info(f"âœ… {feed_name}: {len(articles)} Ù…Ù‚Ø§Ù„Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
            return articles
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª RSS {feed_name}: {e}")
            return []
    
    def _parse_published_date(self, published_str: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø§Ù†ØªØ´Ø§Ø± Ø¨Ù‡ ÙØ±Ù…Øª ISO"""
        try:
            if not published_str:
                return datetime.now().isoformat()
            
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§ feedparser
            import time
            time_struct = feedparser._parse_date(published_str)
            if time_struct:
                dt = datetime(*time_struct[:6])
                return dt.isoformat()
            
            # fallback Ø¨Ù‡ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ
            return datetime.now().isoformat()
            
        except Exception:
            return datetime.now().isoformat()
    
    def _get_sentiment_label(self, compound_score: float) -> str:
        """ØªØ¹ÛŒÛŒÙ† Ø¨Ø±Ú†Ø³Ø¨ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² compound"""
        if compound_score >= 0.05:
            return 'positive'
        elif compound_score <= -0.05:
            return 'negative'
        else:
            return 'neutral'
    
    def fetch_all_feeds(self) -> List[Dict]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù‡Ù…Ù‡ RSS feeds
        
        Returns:
            Ù„ÛŒØ³Øª Ú©Ù„ Ù…Ù‚Ø§Ù„Ø§Øª
        """
        all_articles = []
        
        for feed_name, feed_url in self.rss_feeds.items():
            articles = self.fetch_rss_feed(feed_name, feed_url)
            all_articles.extend(articles)
        
        logging.info(f"ğŸ“° Ù…Ø¬Ù…ÙˆØ¹ {len(all_articles)} Ù…Ù‚Ø§Ù„Ù‡ Ø§Ø² {len(self.rss_feeds)} Ù…Ù†Ø¨Ø¹")
        return all_articles
    
    def filter_relevant_news(self, articles: List[Dict], symbol: str, 
                           max_news: int = MAX_NEWS_PER_SYMBOL) -> List[Dict]:
        """
        ÙÛŒÙ„ØªØ± Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù†Ù…Ø§Ø¯
        
        Args:
            articles: Ù„ÛŒØ³Øª Ù‡Ù…Ù‡ Ù…Ù‚Ø§Ù„Ø§Øª
            symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø² (Ù…Ø«Ù„ BTC/USDT)
            max_news: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø±
        
        Returns:
            Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø·
        """
        crypto_name = symbol.split('/')[0].lower()
        relevant_articles = []
        
        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·
        keywords = [
            crypto_name,
            'crypto', 'cryptocurrency', 'bitcoin', 'blockchain',
            'digital currency', 'altcoin', 'defi', 'nft'
        ]
        
        for article in articles:
            title_lower = article.get('title', '').lower()
            content_lower = article.get('content', '').lower()
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
            is_relevant = False
            
            # Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§: Ù†Ø§Ù… Ø§Ø±Ø² Ø¯Ø± Ø¹Ù†ÙˆØ§Ù† ÛŒØ§ Ù…Ø­ØªÙˆØ§
            if crypto_name in title_lower or crypto_name in content_lower:
                is_relevant = True
            
            # Ø§ÙˆÙ„ÙˆÛŒØª Ù…ØªÙˆØ³Ø·: Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ú©Ø±ÛŒÙ¾ØªÙˆ
            elif any(keyword in title_lower or keyword in content_lower for keyword in keywords):
                is_relevant = True
            
            if is_relevant:
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯ Ø¨Ù‡ Ù…Ù‚Ø§Ù„Ù‡
                article_copy = article.copy()
                article_copy['symbol'] = symbol
                relevant_articles.append(article_copy)
                
                if len(relevant_articles) >= max_news:
                    break
        
        logging.info(f"ğŸ¯ {symbol}: {len(relevant_articles)} Ø®Ø¨Ø± Ù…Ø±ØªØ¨Ø· ÛŒØ§ÙØª Ø´Ø¯")
        return relevant_articles

class NewsDataManager:
    """
    Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø±
    
    ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
    - Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø´Ù†â€ŒÙ‡Ø§
    - Ø¢Ù…Ø§Ø± Ù¾ÛŒØ´Ø±ÙØª
    - Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ Ø¬Ø§Ù…Ø¹
    """
    
    def __init__(self):
        self.fetcher = RSSNewsFetcher()
        self.session_id = None
        logging.info("ğŸ¯ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø± Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
    
    def save_news_data(self, articles: List[Dict], symbol: str) -> str:
        """
        Ø°Ø®ÛŒØ±Ù‡ Ø§Ø®Ø¨Ø§Ø± Ø¯Ø± ÙØ§ÛŒÙ„ CSV
        
        Args:
            articles: Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø±
            symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²
        
        Returns:
            Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
        """
        try:
            if not articles:
                return ""
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            df = pd.DataFrame(articles)
            
            # Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„
            symbol_clean = sanitize_filename(symbol)
            timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"news_{symbol_clean}_en_{timestamp_str}.csv"
            file_path = f"{RAW_DATA_PATH}/{filename}"
            
            # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
            
            logging.info(f"ğŸ’¾ ÙØ§ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
            return file_path
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ø®Ø¨Ø§Ø± {symbol}: {e}")
            return ""
    
    def fetch_symbol_news(self, symbol: str, max_news: int = MAX_NEWS_PER_SYMBOL) -> int:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± ÛŒÚ© Ù†Ù…Ø§Ø¯
        
        Args:
            symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø²
            max_news: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø±
        
        Returns:
            ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡
        """
        try:
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª
            state_manager.update_news_progress(
                self.session_id, symbol, 'processing'
            )
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù‡Ù…Ù‡ Ø§Ø®Ø¨Ø§Ø±
            all_articles = self.fetcher.fetch_all_feeds()
            
            if not all_articles:
                logging.warning(f"âš ï¸ Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} ÛŒØ§ÙØª Ù†Ø´Ø¯")
                state_manager.update_news_progress(
                    self.session_id, symbol, 'failed',
                    error_message="Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯"
                )
                return 0
            
            # ÙÛŒÙ„ØªØ± Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø·
            relevant_news = self.fetcher.filter_relevant_news(all_articles, symbol, max_news)
            
            if not relevant_news:
                logging.warning(f"âš ï¸ Ù‡ÛŒÚ† Ø®Ø¨Ø± Ù…Ø±ØªØ¨Ø·ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} ÛŒØ§ÙØª Ù†Ø´Ø¯")
                state_manager.update_news_progress(
                    self.session_id, symbol, 'failed',
                    error_message="Ù‡ÛŒÚ† Ø®Ø¨Ø± Ù…Ø±ØªØ¨Ø· ÛŒØ§ÙØª Ù†Ø´Ø¯"
                )
                return 0
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø®Ø¨Ø§Ø±
            file_path = self.save_news_data(relevant_news, symbol)
            
            if file_path:
                # Ù…ÙˆÙÙ‚ÛŒØª
                state_manager.update_news_progress(
                    self.session_id, symbol, 'completed',
                    file_path=file_path, news_count=len(relevant_news)
                )
                return len(relevant_news)
            else:
                # Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡
                state_manager.update_news_progress(
                    self.session_id, symbol, 'failed',
                    error_message="Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„"
                )
                return 0
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± {symbol}: {e}")
            state_manager.update_news_progress(
                self.session_id, symbol, 'failed',
                error_message=str(e)
            )
            return 0
    
    def fetch_multiple_symbols_news(self, symbols: List[str], 
                                  max_news: int = MAX_NEWS_PER_SYMBOL) -> Dict:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯ÛŒÙ† Ù†Ù…Ø§Ø¯
        
        Args:
            symbols: Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§
            max_news: Ø­Ø¯Ø§Ú©Ø«Ø± Ø§Ø®Ø¨Ø§Ø± Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯
        
        Returns:
            Ø¢Ù…Ø§Ø± Ù†ØªØ§ÛŒØ¬
        """
        logging.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± {len(symbols)} Ù†Ù…Ø§Ø¯")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø´Ù†
        self.session_id = state_manager.create_session('news', len(symbols))
        
        # Ø¢Ù…Ø§Ø±
        total_news = 0
        successful_symbols = 0
        failed_symbols = 0
        
        # Ø¯Ø±ÛŒØ§ÙØª ÛŒÚ©Ø¨Ø§Ø± Ù‡Ù…Ù‡ Ø§Ø®Ø¨Ø§Ø± (Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø§Ø±Ø§ÛŒÛŒ)
        logging.info("ğŸ“¡ Ø¯Ø±ÛŒØ§ÙØª Ù‡Ù…Ù‡ Ø§Ø®Ø¨Ø§Ø± RSS...")
        all_articles = self.fetcher.fetch_all_feeds()
        
        if not all_articles:
            logging.error("âŒ Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ø§Ø² RSS feeds Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
            state_manager.complete_session(self.session_id)
            return {
                'session_id': self.session_id,
                'total_symbols': len(symbols),
                'successful_symbols': 0,
                'failed_symbols': len(symbols),
                'total_news': 0,
                'success_rate': 0
            }
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ù†Ù…Ø§Ø¯
        for i, symbol in enumerate(symbols, 1):
            logging.info(f"ğŸ“° [{i}/{len(symbols)}] Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø®Ø¨Ø§Ø± {symbol}...")
            
            try:
                # ÙÛŒÙ„ØªØ± Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø·
                relevant_news = self.fetcher.filter_relevant_news(all_articles, symbol, max_news)
                
                if relevant_news:
                    # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø®Ø¨Ø§Ø±
                    file_path = self.save_news_data(relevant_news, symbol)
                    
                    if file_path:
                        state_manager.update_news_progress(
                            self.session_id, symbol, 'completed',
                            file_path=file_path, news_count=len(relevant_news)
                        )
                        total_news += len(relevant_news)
                        successful_symbols += 1
                    else:
                        state_manager.update_news_progress(
                            self.session_id, symbol, 'failed',
                            error_message="Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡"
                        )
                        failed_symbols += 1
                else:
                    state_manager.update_news_progress(
                        self.session_id, symbol, 'failed',
                        error_message="Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø· ÛŒØ§ÙØª Ù†Ø´Ø¯"
                    )
                    failed_symbols += 1
                
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± {symbol}: {e}")
                state_manager.update_news_progress(
                    self.session_id, symbol, 'failed',
                    error_message=str(e)
                )
                failed_symbols += 1
            
            # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
            progress = (i / len(symbols)) * 100
            logging.info(f"âš¡ Ù¾ÛŒØ´Ø±ÙØª: {progress:.1f}% | Ù…ÙˆÙÙ‚: {successful_symbols} | Ø§Ø®Ø¨Ø§Ø±: {total_news}")
        
        # Ø§ØªÙ…Ø§Ù… Ø³Ø´Ù†
        state_manager.complete_session(self.session_id)
        
        # Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
        stats = {
            'session_id': self.session_id,
            'total_symbols': len(symbols),
            'successful_symbols': successful_symbols,
            'failed_symbols': failed_symbols,
            'total_news': total_news,
            'avg_news_per_symbol': round(total_news / max(successful_symbols, 1), 1),
            'success_rate': round((successful_symbols / len(symbols)) * 100, 1) if symbols else 0
        }
        
        return stats

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ - Ù…Ù†ÙˆÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ"""
    logging.info("ğŸš€ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø± Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ (RSS Only)")
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
    if not RSS_AVAILABLE:
        print("âŒ Ø®Ø·Ø§: feedparser Ù†ØµØ¨ Ù†ÛŒØ³Øª")
        print("Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install feedparser")
        return
    
    if not SENTIMENT_AVAILABLE:
        print("âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: vaderSentiment Ù†ØµØ¨ Ù†ÛŒØ³Øª")
        print("Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install vaderSentiment")
        print("Ø¨Ø¯ÙˆÙ† Ø¢Ù†ØŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª ØºÛŒØ±ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯")
    
    # Ù†Ù…Ø§ÛŒØ´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    print("\n" + "="*70)
    print("ğŸ“° Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø± Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡")
    print("="*70)
    print("ğŸ“¡ Ù…Ù†Ø¨Ø¹: RSS Feeds (Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ØŒ Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª)")
    print("ğŸš€ Ù…Ø²Ø§ÛŒØ§: Ø±Ø§ÛŒÚ¯Ø§Ù† Ú©Ø§Ù…Ù„ØŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ØŒ Ø§Ø®Ø¨Ø§Ø± Ù…Ø¹ØªØ¨Ø±")
    print("âš¡ Ú©Ø´: 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª")
    print("ğŸ­ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª: VADER (Ø®ÙˆØ¯Ú©Ø§Ø±)")
    
    # Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª
    manager = NewsDataManager()
    
    while True:
        print("\n" + "="*50)
        print("ğŸ“‹ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø±")
        print("="*50)
        print("1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨ (30 Ù†Ù…Ø§Ø¯)")
        print("2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÙØ§Ø±Ø´ÛŒ (Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø² Ù„ÛŒØ³Øª)")
        print("3. ØªØ³Øª RSS feeds (Ø¨Ø±Ø±Ø³ÛŒ Ø§ØªØµØ§Ù„)")
        print("4. Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø³Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ")
        print("5. Ø®Ø±ÙˆØ¬")
        
        choice = input("\nØ§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§: ").strip()
        
        if choice == '1':
            # Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨
            print(f"\nğŸ“° Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± {len(COMMON_SYMBOLS)} Ù†Ù…Ø§Ø¯ Ù…Ø­Ø¨ÙˆØ¨...")
            
            # ØªÙ†Ø¸ÛŒÙ… ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø±
            max_news_choice = input(f"\nØ­Ø¯Ø§Ú©Ø«Ø± Ø§Ø®Ø¨Ø§Ø± Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: {MAX_NEWS_PER_SYMBOL}): ").strip()
            max_news = int(max_news_choice) if max_news_choice.isdigit() else MAX_NEWS_PER_SYMBOL
            
            # ØªØ£ÛŒÛŒØ¯ Ù†Ù‡Ø§ÛŒÛŒ
            estimated_time = (len(COMMON_SYMBOLS) * 0.5) / 60  # Ø¯Ù‚ÛŒÙ‚Ù‡
            
            print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡:")
            print(f"   Ù†Ù…Ø§Ø¯Ù‡Ø§: {len(COMMON_SYMBOLS)}")
            print(f"   Ø­Ø¯Ø§Ú©Ø«Ø± Ø§Ø®Ø¨Ø§Ø±/Ù†Ù…Ø§Ø¯: {max_news}")
            print(f"   Ù…Ù†Ø§Ø¨Ø¹ RSS: {len(manager.fetcher.rss_feeds)}")
            print(f"   Ø²Ù…Ø§Ù† ØªØ®Ù…ÛŒÙ†ÛŒ: {estimated_time:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡")
            
            confirm = input("\nØ§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯ØŸ (y/n): ").lower()
            if confirm != 'y':
                continue
            
            # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬
            stats = manager.fetch_multiple_symbols_news(COMMON_SYMBOLS, max_news)
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            print(f"\nâœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
            print(f"ğŸ“Š Ù…ÙˆÙÙ‚: {stats['successful_symbols']}/{stats['total_symbols']} Ù†Ù…Ø§Ø¯ ({stats['success_rate']}%)")
            print(f"ğŸ“° Ú©Ù„ Ø§Ø®Ø¨Ø§Ø±: {stats['total_news']} (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: {stats['avg_news_per_symbol']}/Ù†Ù…Ø§Ø¯)")
            print(f"ğŸ†” Session ID: {stats['session_id']}")
        
        elif choice == '2':
            # Ø§Ù†ØªØ®Ø§Ø¨ Ø³ÙØ§Ø±Ø´ÛŒ
            print("\nğŸ“° Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÙØ§Ø±Ø´ÛŒ Ø§Ø®Ø¨Ø§Ø±...")
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù…Ø§Ø¯Ù‡Ø§
            symbols = get_user_selection(
                COMMON_SYMBOLS,
                "Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù…Ø§Ø¯Ù‡Ø§",
                allow_manual=True,
                allow_multi=True,
                allow_all=True
            )
            
            if not symbols:
                print("âŒ Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯")
                continue
            
            # ØªÙ†Ø¸ÛŒÙ… ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø±
            max_news_choice = input(f"\nØ­Ø¯Ø§Ú©Ø«Ø± Ø§Ø®Ø¨Ø§Ø± Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: {MAX_NEWS_PER_SYMBOL}): ").strip()
            max_news = int(max_news_choice) if max_news_choice.isdigit() else MAX_NEWS_PER_SYMBOL
            
            # ØªØ£ÛŒÛŒØ¯ Ù†Ù‡Ø§ÛŒÛŒ
            estimated_time = (len(symbols) * 0.5) / 60
            
            print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡:")
            print(f"   Ù†Ù…Ø§Ø¯Ù‡Ø§: {len(symbols)}")
            print(f"   Ø­Ø¯Ø§Ú©Ø«Ø± Ø§Ø®Ø¨Ø§Ø±/Ù†Ù…Ø§Ø¯: {max_news}")
            print(f"   Ù…Ù†Ø§Ø¨Ø¹ RSS: {len(manager.fetcher.rss_feeds)}")
            print(f"   Ø²Ù…Ø§Ù† ØªØ®Ù…ÛŒÙ†ÛŒ: {estimated_time:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡")
            
            confirm = input("\nØ§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯ØŸ (y/n): ").lower()
            if confirm != 'y':
                continue
            
            # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬
            stats = manager.fetch_multiple_symbols_news(symbols, max_news)
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            print(f"\nâœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
            print(f"ğŸ“Š Ù…ÙˆÙÙ‚: {stats['successful_symbols']}/{stats['total_symbols']} Ù†Ù…Ø§Ø¯ ({stats['success_rate']}%)")
            print(f"ğŸ“° Ú©Ù„ Ø§Ø®Ø¨Ø§Ø±: {stats['total_news']} (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: {stats['avg_news_per_symbol']}/Ù†Ù…Ø§Ø¯)")
            print(f"ğŸ†” Session ID: {stats['session_id']}")
        
        elif choice == '3':
            # ØªØ³Øª RSS feeds
            print("\nğŸ” ØªØ³Øª Ø§ØªØµØ§Ù„ RSS feeds...")
            
            for feed_name, feed_url in manager.fetcher.rss_feeds.items():
                print(f"\nğŸ“¡ ØªØ³Øª {feed_name}...")
                articles = manager.fetcher.fetch_rss_feed(feed_name, feed_url)
                
                if articles:
                    print(f"âœ… {feed_name}: {len(articles)} Ù…Ù‚Ø§Ù„Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                    
                    # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡
                    if articles:
                        sample = articles[0]
                        print(f"   ğŸ“° Ù†Ù…ÙˆÙ†Ù‡: {sample['title'][:50]}...")
                        print(f"   ğŸ­ Ø§Ø­Ø³Ø§Ø³Ø§Øª: {sample['sentiment_label']} ({sample['sentiment_compound']:.3f})")
                else:
                    print(f"âŒ {feed_name}: Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
        
        elif choice == '4':
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
            print("\nğŸ“Š Ø¢Ù…Ø§Ø± Ø³Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ:")
            
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± rate limiter
            rate_stats = rate_limiter.get_stats()
            print(f"ğŸ“ˆ Ú©Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§: {rate_stats['total_requests']:,}")
            print(f"   RSS: {rate_stats['rss_requests']:,}")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
        
        elif choice == '5':
            print("\nğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸!")
            logging.info("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø± Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯")
            break
        
        else:
            print("âŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")

if __name__ == '__main__':
    main()
