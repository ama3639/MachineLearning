#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ú© ØªØ³Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú†Ù†Ø¯ Ø¯Ø§Ø±Ø§ÛŒÛŒ
Ù†Ø³Ø®Ù‡ 2.1 - Ø±ÙØ¹ Ù…Ø´Ú©Ù„ "max() arg is an empty sequence"

ğŸ”§ Ø§ØµÙ„Ø§Ø­Ø§Øª v2.1:
- âœ… Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ "max() arg is an empty sequence"  
- âœ… Ø¨Ù‡Ø¨ÙˆØ¯ error handling Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨ÙˆØ¯Ù†
- âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† fallback mechanism
- âœ… Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…Ø³ÛŒØ±Ù‡Ø§ Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
- âœ… Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ØªØ± Ø¨Ø±Ø§ÛŒ debugging

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
- Ø¨Ú© ØªØ³Øª Ú†Ù†Ø¯ Ù†Ù…Ø§Ø¯ÛŒ Ùˆ Ú†Ù†Ø¯ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ
- Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø¯Ù„ÛŒÙ„ Ø®Ø±ÙˆØ¬
- Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ø´Ø§Ø±Ù¾ØŒ Ø­Ø¯Ø§Ú©Ø«Ø± Ø§ÙØª Ø³Ø±Ù…Ø§ÛŒÙ‡ Ùˆ ØºÛŒØ±Ù‡)
- ØªØ¬Ø³Ù… ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨Ø§ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
- Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¯Ù‚ÛŒÙ‚
"""
import os
import glob
import pandas as pd
import numpy as np
import logging
import configparser
import joblib
from datetime import datetime
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns

# --- Configuration and Logging Setup ---
config = configparser.ConfigParser()
CONFIG_FILE_PATH = 'config.ini'
try:
    config.read(CONFIG_FILE_PATH, encoding='utf-8')
    FEATURES_PATH = config.get('Paths', 'features')
    MODELS_PATH = config.get('Paths', 'models')
    LOG_PATH = config.get('Paths', 'logs')
    REPORTS_PATH = config.get('Paths', 'reports')
    INITIAL_CAPITAL = config.getfloat('Backtester_Settings', 'initial_capital')
    TRADE_SIZE_PERCENT = config.getfloat('Backtester_Settings', 'trade_size_percent')
    TARGET_FUTURE_PERIODS = config.getint('ETL_Settings', 'target_future_periods')
except Exception as e:
    print(f"CRITICAL ERROR: Could not read 'config.ini'. Error: {e}")
    exit()

script_name = os.path.splitext(os.path.basename(__file__))[0]
log_subfolder_path = os.path.join(LOG_PATH, script_name)
report_subfolder_path = os.path.join(REPORTS_PATH, script_name)
os.makedirs(log_subfolder_path, exist_ok=True)
os.makedirs(report_subfolder_path, exist_ok=True)
log_filename = os.path.join(log_subfolder_path, f"log_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler(log_filename, encoding='utf-8'), logging.StreamHandler()])

# ğŸ”§ ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ error handling Ø¨Ù‡ØªØ±
def find_latest_file(pattern: str, description: str) -> str:
    """
    ÛŒØ§ÙØªÙ† Ø¢Ø®Ø±ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø§ pattern Ù…Ø´Ø®Øµ - Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ empty sequence
    """
    try:
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ
        files = glob.glob(pattern)
        logging.info(f"ğŸ” Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ {description} Ø¯Ø±: {pattern}")
        logging.info(f"ğŸ“ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(files)}")
        
        if files:
            # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            existing_files = [f for f in files if os.path.exists(f) and os.path.getsize(f) > 0]
            logging.info(f"ğŸ“„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±: {len(existing_files)}")
            
            if existing_files:
                latest_file = max(existing_files, key=os.path.getctime)
                logging.info(f"âœ… Ø¢Ø®Ø±ÛŒÙ† ÙØ§ÛŒÙ„ {description}: {os.path.basename(latest_file)}")
                return latest_file
        
        # Ø§Ú¯Ø± Ø¯Ø± Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ ÙØ§ÛŒÙ„ Ù†ÛŒØ§ÙØªØŒ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
        parent_dir = os.path.dirname(pattern)
        file_pattern = os.path.basename(pattern)
        
        logging.info(f"ğŸ” Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ {parent_dir}...")
        alternative_patterns = [
            os.path.join(parent_dir, "**", file_pattern),  # Ø¬Ø³ØªØ¬Ùˆ recursive
            os.path.join(parent_dir, "run_*", file_pattern),  # Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ run_*
        ]
        
        for alt_pattern in alternative_patterns:
            alt_files = glob.glob(alt_pattern, recursive=True)
            logging.info(f"ğŸ“ Ø¯Ø± {alt_pattern}: {len(alt_files)} ÙØ§ÛŒÙ„")
            
            if alt_files:
                existing_alt_files = [f for f in alt_files if os.path.exists(f) and os.path.getsize(f) > 0]
                if existing_alt_files:
                    latest_file = max(existing_alt_files, key=os.path.getctime)
                    logging.info(f"âœ… ÙØ§ÛŒÙ„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† {description}: {os.path.basename(latest_file)}")
                    return latest_file
        
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯
        logging.error(f"âŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ {description} ÛŒØ§ÙØª Ù†Ø´Ø¯")
        logging.error(f"ğŸ’¡ Pattern Ø¬Ø³ØªØ¬Ùˆ Ø´Ø¯Ù‡: {pattern}")
        logging.error(f"ğŸ’¡ Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ø³ØªÙ†Ø¯")
        
        # Ù†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ø¨Ø±Ø§ÛŒ debugging
        try:
            parent_directory = os.path.dirname(pattern) if os.path.dirname(pattern) else "."
            if os.path.exists(parent_directory):
                all_files = os.listdir(parent_directory)
                logging.info(f"ğŸ“‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± {parent_directory}:")
                for file in all_files[:10]:  # Ù†Ù…Ø§ÛŒØ´ Ø§ÙˆÙ„ 10 ÙØ§ÛŒÙ„
                    logging.info(f"   - {file}")
                if len(all_files) > 10:
                    logging.info(f"   ... Ùˆ {len(all_files) - 10} ÙØ§ÛŒÙ„ Ø¯ÛŒÚ¯Ø±")
        except Exception as list_error:
            logging.warning(f"Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆØ´Ù‡ Ø±Ø§ Ù„ÛŒØ³Øª Ú©Ø±Ø¯: {list_error}")
        
        return None
        
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ ÙØ§ÛŒÙ„ {description}: {e}")
        return None

def calculate_max_drawdown(equity_curve):
    """Calculate maximum drawdown"""
    if equity_curve.empty:
        return 0
    peak = equity_curve.expanding(min_periods=1).max()
    drawdown = (equity_curve - peak) / peak
    return drawdown.min()

def calculate_sharpe_ratio(returns, risk_free_rate=0.02):
    """Calculate Sharpe ratio"""
    if len(returns) == 0:
        return 0
    excess_returns = returns - risk_free_rate/252  # Assuming 252 trading days
    if excess_returns.std() == 0:
        return 0
    return np.sqrt(252) * excess_returns.mean() / excess_returns.std()

def generate_report_file(report_data, symbol, timeframe):
    """Generate simple text report (backward compatibility)"""
    timestamp_str = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
    filename = f"Backtest-Report_{symbol.replace('/', '-')}_{timeframe}_{timestamp_str}.txt"
    filepath = os.path.join(report_subfolder_path, filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write("================================================\n")
        f.write("      BACKTEST STRATEGY PERFORMANCE REPORT\n")
        f.write("================================================\n\n")
        f.write(f"Symbol tested:         {symbol}\n")
        f.write(f"Timeframe tested:      {timeframe}\n")
        f.write(f"Report date:           {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("------------------------------------------------\n")
        f.write("      Summary of Results\n")
        f.write("------------------------------------------------\n")
        for key, value in report_data.items():
            if key != 'trade_history':
                f.write(f"{key:<20} {value}\n")
        f.write("\n\n------------------------------------------------\n")
        f.write("      Trade History\n")
        f.write("------------------------------------------------\n")
        if report_data['trade_history']:
            f.write(f"{'#':<3} {'Entry Time':<16} {'Exit Time':<16} {'Entry $':<10} {'Exit $':<10} {'P/L':<8} {'Exit Reason':<20}\n")
            f.write("-"*90 + "\n")
            for i, trade in enumerate(report_data['trade_history'], 1):
                entry_ts = pd.to_datetime(str(trade['entry_date'])).strftime('%Y-%m-%d %H:%M')
                exit_ts = pd.to_datetime(str(trade['exit_date'])).strftime('%Y-%m-%d %H:%M')
                exit_reason = trade.get('exit_reason', 'Target reached')
                f.write(f"{i:<3} {entry_ts:<16} {exit_ts:<16} "
                       f"${trade['entry_price']:<9.4f} ${trade['exit_price']:<9.4f} "
                       f"{trade['pnl']:<7.2%} {exit_reason:<20}\n")
        else:
            f.write("No trades executed in this period.\n")
    
    logging.info(f"Report file saved to '{filepath}'")

def generate_visualizations(df, trade_history, symbol, timeframe, report_path):
    """Generate analytical charts"""
    timestamp_str = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
    
    # Price and signals chart
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)
    
    # Price and entry/exit points
    ax1.plot(df.index, df['close'], label='Close Price', alpha=0.7)
    
    # Display trades with reasons
    if trade_history:
        for trade in trade_history:
            try:
                entry_idx = df.index.get_loc(trade['entry_date'])
                exit_idx = df.index.get_loc(trade['exit_date'])
                color = 'green' if trade['pnl'] > 0 else 'red'
                
                # Plot trade line
                ax1.plot([trade['entry_date'], trade['exit_date']], 
                        [trade['entry_price'], trade['exit_price']], 
                        'o-', color=color, markersize=8, linewidth=2)
                
                # Add reason annotation
                mid_date = df.index[entry_idx + (exit_idx - entry_idx) // 2]
                mid_price = (trade['entry_price'] + trade['exit_price']) / 2
                reason = trade.get('exit_reason', 'Target reached')
                ax1.annotate(f"{trade['pnl']:.1%}\n{reason}", 
                            xy=(mid_date, mid_price),
                            xytext=(10, 10), textcoords='offset points',
                            fontsize=8, ha='left',
                            bbox=dict(boxstyle="round,pad=0.3", fc=color, alpha=0.3))
            except (KeyError, ValueError) as e:
                logging.warning(f"Error plotting trade: {e}")
                continue
    
    ax1.set_ylabel('Price')
    ax1.set_title(f'Price Chart and Trades - {symbol} ({timeframe})')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # Model prediction chart
    if 'prediction' in df.columns:
        ax2.plot(df.index, df['prediction'], label='Model Prediction', color='orange', alpha=0.5)
        ax2.fill_between(df.index, 0, df['prediction'], alpha=0.3, color='orange')
        ax2.set_xlabel('Time')
        ax2.set_ylabel('Signal')
        ax2.set_title('Model Signals')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
    
    plt.tight_layout()
    chart_filename = os.path.join(report_path, f"backtest_chart_{symbol.replace('/', '-')}_{timeframe}_{timestamp_str}.png")
    plt.savefig(chart_filename, dpi=300, bbox_inches='tight')
    plt.close()
    
    logging.info(f"Chart saved to '{chart_filename}'")
    
    # P&L distribution chart
    if trade_history:
        pnl_values = [t['pnl'] * 100 for t in trade_history]
        
        plt.figure(figsize=(10, 6))
        plt.hist(pnl_values, bins=20, alpha=0.7, color='blue', edgecolor='black')
        plt.axvline(x=0, color='red', linestyle='--', linewidth=2)
        plt.xlabel('Profit/Loss (%)')
        plt.ylabel('Number of Trades')
        plt.title(f'P&L Distribution - {symbol} ({timeframe})')
        plt.grid(True, alpha=0.3)
        
        hist_filename = os.path.join(report_path, f"pnl_distribution_{symbol.replace('/', '-')}_{timeframe}_{timestamp_str}.png")
        plt.savefig(hist_filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        logging.info(f"Distribution chart saved to '{hist_filename}'")

def generate_enhanced_report(report_data, symbol, timeframe, df, equity_curve):
    """Generate enhanced report with additional metrics"""
    timestamp_str = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
    filename = f"Enhanced_Backtest_Report_{symbol.replace('/', '-')}_{timeframe}_{timestamp_str}.txt"
    filepath = os.path.join(report_subfolder_path, filename)
    
    # Calculate additional metrics
    if report_data['trade_history']:
        returns = pd.Series([t['pnl'] for t in report_data['trade_history']])
        avg_win = np.mean([t['pnl'] for t in report_data['trade_history'] if t['pnl'] > 0]) if any(t['pnl'] > 0 for t in report_data['trade_history']) else 0
        avg_loss = np.mean([t['pnl'] for t in report_data['trade_history'] if t['pnl'] < 0]) if any(t['pnl'] < 0 for t in report_data['trade_history']) else 0
        profit_factor = abs(sum([t['pnl'] for t in report_data['trade_history'] if t['pnl'] > 0]) / 
                           sum([t['pnl'] for t in report_data['trade_history'] if t['pnl'] < 0])) if any(t['pnl'] < 0 for t in report_data['trade_history']) else np.inf
    else:
        returns = pd.Series()
        avg_win = avg_loss = profit_factor = 0
    
    max_drawdown = calculate_max_drawdown(equity_curve)
    sharpe_ratio = calculate_sharpe_ratio(returns)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("      COMPREHENSIVE BACKTEST REPORT\n")
        f.write("="*70 + "\n\n")
        
        f.write("ğŸ“Š General Information:\n")
        f.write("-"*50 + "\n")
        f.write(f"Symbol:                {symbol}\n")
        f.write(f"Timeframe:             {timeframe}\n")
        f.write(f"Report Date:           {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Test Period:           {df.index[0]} to {df.index[-1]}\n")
        f.write(f"Total Candles:         {len(df)}\n\n")
        
        f.write("ğŸ’° Financial Results:\n")
        f.write("-"*50 + "\n")
        f.write(f"Initial Capital:       ${float(report_data.get('Initial Capital', report_data.get('Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø§ÙˆÙ„ÛŒÙ‡', '0')).replace(',', '')):,.2f}\n")
        f.write(f"Final Capital:         ${float(report_data.get('Final Capital', report_data.get('Ø³Ø±Ù…Ø§ÛŒÙ‡ Ù†Ù‡Ø§ÛŒÛŒ', '0')).replace(',', '')):,.2f}\n")
        f.write(f"Total Return:          {report_data.get('Total Return', report_data.get('Ø¨Ø§Ø²Ø¯Ù‡ Ú©Ù„', 'N/A'))}\n")
        f.write(f"Max Drawdown:          {max_drawdown:.2%}\n")
        f.write(f"Sharpe Ratio:          {sharpe_ratio:.2f}\n\n")
        
        f.write("ğŸ“ˆ Trade Statistics:\n")
        f.write("-"*50 + "\n")
        f.write(f"Total Trades:          {report_data.get('Total Trades', report_data.get('ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª', 0))}\n")
        f.write(f"Winning Trades:        {report_data.get('Winning Trades', report_data.get('ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…ÙˆÙÙ‚', 0))}\n")
        f.write(f"Losing Trades:         {report_data.get('Losing Trades', report_data.get('ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù†Ø§Ù…ÙˆÙÙ‚', 0))}\n")
        f.write(f"Win Rate:              {report_data.get('Win Rate', report_data.get('Ø¯Ø±ØµØ¯ Ù…ÙˆÙÙ‚ÛŒØª', 'N/A'))}\n")
        f.write(f"Average Win:           {avg_win:.2%}\n")
        f.write(f"Average Loss:          {avg_loss:.2%}\n")
        f.write(f"Profit Factor:         {profit_factor:.2f}\n\n")
        
        f.write("ğŸ“‹ Trade Details:\n")
        f.write("-"*90 + "\n")
        if report_data['trade_history']:
            f.write(f"{'#':<3} {'Entry':<16} {'Exit':<16} {'Entry $':<10} {'Exit $':<10} {'P&L':<8} {'Reason':<20}\n")
            f.write("-"*90 + "\n")
            for i, trade in enumerate(report_data['trade_history'], 1):
                entry_ts = pd.to_datetime(str(trade['entry_date'])).strftime('%Y-%m-%d %H:%M')
                exit_ts = pd.to_datetime(str(trade['exit_date'])).strftime('%Y-%m-%d %H:%M')
                reason = trade.get('exit_reason', 'Target reached')
                f.write(f"{i:<3} {entry_ts:<16} {exit_ts:<16} "
                       f"${trade['entry_price']:<9.4f} ${trade['exit_price']:<9.4f} "
                       f"{trade['pnl']:<7.2%} {reason:<20}\n")
        else:
            f.write("No trades executed during this period.\n")
        
        f.write("\n" + "="*70 + "\n")
        f.write("End of Report\n")
        
    logging.info(f"Enhanced report saved to '{filepath}'")

def select_symbols_and_timeframes(df_full):
    """Interactive selection of symbols and timeframes with multi-select option"""
    # Symbol selection
    available_symbols = df_full.index.get_level_values('symbol').unique().tolist()
    print("\nğŸ“Š Available Symbols:")
    print("-" * 50)
    for i, sym in enumerate(available_symbols, 1):
        print(f"{i:3d}. {sym}")
    print(f"{len(available_symbols)+1:3d}. ALL SYMBOLS")
    print("-" * 50)
    
    symbol_choice = input("\nğŸ’± Enter symbol number(s) or symbol name (e.g., 1 or BTC/USDT or 1,3,5): ").strip()
    
    selected_symbols = []
    if symbol_choice == str(len(available_symbols)+1) or symbol_choice.upper() == 'ALL':
        selected_symbols = available_symbols
        print(f"âœ… Selected ALL {len(selected_symbols)} symbols")
    elif ',' in symbol_choice:
        # Multiple selection
        try:
            indices = [int(x.strip()) - 1 for x in symbol_choice.split(',') if x.strip().isdigit()]
            selected_symbols = [available_symbols[i] for i in indices if 0 <= i < len(available_symbols)]
        except (ValueError, IndexError):
            print("âŒ Invalid selection format")
            return None, None
    elif symbol_choice.isdigit():
        # Single number selection
        try:
            idx = int(symbol_choice) - 1
            if 0 <= idx < len(available_symbols):
                selected_symbols = [available_symbols[idx]]
        except (ValueError, IndexError):
            print("âŒ Invalid selection")
            return None, None
    else:
        # Direct symbol name
        symbol_choice = symbol_choice.upper()
        if symbol_choice in available_symbols:
            selected_symbols = [symbol_choice]
    
    if not selected_symbols:
        print("âŒ Invalid selection")
        return None, None
    
    # Timeframe selection for first symbol (to get available timeframes)
    try:
        first_symbol_tf = df_full.loc[selected_symbols[0]].index.get_level_values('timeframe').unique().tolist()
    except KeyError:
        print(f"âŒ Symbol {selected_symbols[0]} not found in dataset")
        return None, None
        
    print(f"\nâ±ï¸ Available Timeframes:")
    print("-" * 30)
    for i, tf in enumerate(first_symbol_tf, 1):
        print(f"{i:2d}. {tf}")
    print(f"{len(first_symbol_tf)+1:2d}. ALL TIMEFRAMES")
    print("-" * 30)
    
    tf_choice = input("\nğŸ• Enter timeframe number(s) or name (e.g., 2 or 1h or 1,2,3): ").strip()
    
    selected_timeframes = []
    if tf_choice == str(len(first_symbol_tf)+1) or tf_choice.upper() == 'ALL':
        selected_timeframes = first_symbol_tf
        print(f"âœ… Selected ALL {len(selected_timeframes)} timeframes")
    elif ',' in tf_choice:
        # Multiple selection
        try:
            indices = [int(x.strip()) - 1 for x in tf_choice.split(',') if x.strip().isdigit()]
            selected_timeframes = [first_symbol_tf[i] for i in indices if 0 <= i < len(first_symbol_tf)]
        except (ValueError, IndexError):
            print("âŒ Invalid selection format")
            return None, None
    elif tf_choice.isdigit():
        # Single number selection
        try:
            idx = int(tf_choice) - 1
            if 0 <= idx < len(first_symbol_tf):
                selected_timeframes = [first_symbol_tf[idx]]
        except (ValueError, IndexError):
            print("âŒ Invalid selection")
            return None, None
    else:
        # Direct timeframe name
        tf_choice = tf_choice.lower()
        if tf_choice in first_symbol_tf:
            selected_timeframes = [tf_choice]
    
    if not selected_timeframes:
        print("âŒ Invalid selection")
        return None, None
    
    return selected_symbols, selected_timeframes

def run_simple_backtest(features_path: str, models_path: str):
    """Run simple backtest (backward compatibility) - Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡"""
    logging.info("--- Starting Strategy Backtest Process ---")
    
    try:
        # ğŸ”§ ÛŒØ§ÙØªÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ error handling Ø¨Ù‡ØªØ±
        feature_file = find_latest_file(
            os.path.join(features_path, 'final_dataset_for_training_*.parquet'),
            "dataset file"
        )
        if not feature_file:
            logging.error("âŒ No dataset file found. Cannot proceed with backtest.")
            print("âŒ Ø®Ø·Ø§: Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§Ø³Øª ÛŒØ§ÙØª Ù†Ø´Ø¯")
            print("ğŸ’¡ Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ prepare_features_03.py Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return
            
        model_file = find_latest_file(
            os.path.join(models_path, 'optimized_model_*.joblib'),
            "optimized model"
        )
        if not model_file:
            # fallback Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
            model_file = find_latest_file(
                os.path.join(models_path, 'random_forest_model_*.joblib'),
                "random forest model"
            )
            
        scaler_file = find_latest_file(
            os.path.join(models_path, 'scaler_optimized_*.joblib'),
            "optimized scaler"
        )
        if not scaler_file:
            # fallback Ø¨Ù‡ scaler Ù‚Ø¯ÛŒÙ…ÛŒ
            scaler_file = find_latest_file(
                os.path.join(models_path, 'scaler_*.joblib'),
                "scaler"
            )
        
        if not model_file or not scaler_file:
            logging.error("âŒ Required model or scaler files not found")
            print("âŒ Ø®Ø·Ø§: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ ÛŒØ§ scaler ÛŒØ§ÙØª Ù†Ø´Ø¯")
            print("ğŸ’¡ Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ train_model_04.py Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return
            
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        logging.info(f"ğŸ“ Loading dataset: {os.path.basename(feature_file)}")
        df_full = pd.read_parquet(feature_file)
        
        logging.info(f"ğŸ¤– Loading model: {os.path.basename(model_file)}")
        model_data = joblib.load(model_file)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ù…Ø¯Ù„ (optimized ÛŒØ§ Ù‚Ø¯ÛŒÙ…ÛŒ)
        if isinstance(model_data, dict) and 'model' in model_data:
            # Ù…Ø¯Ù„ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡
            model = model_data['model']
            optimal_threshold = model_data.get('optimal_threshold', 0.5)
            logging.info(f"âœ… Optimized model loaded with threshold: {optimal_threshold:.4f}")
        else:
            # Ù…Ø¯Ù„ Ù‚Ø¯ÛŒÙ…ÛŒ
            model = model_data
            optimal_threshold = 0.5
            logging.info("âš ï¸ Legacy model loaded, using default threshold: 0.5")
        
        logging.info(f"ğŸ“ Loading scaler: {os.path.basename(scaler_file)}")
        scaler = joblib.load(scaler_file)
        
        logging.info("âœ… Data files, model and scaler loaded successfully.")
        
    except Exception as e:
        logging.error(f"Error loading files: {e}")
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {e}")
        return

    # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    if df_full.index.nlevels > 1:
        available_symbols = df_full.index.get_level_values('symbol').unique().tolist()
    else:
        logging.error("âŒ Dataset format is not compatible (missing multi-index)")
        print("âŒ ÙØ±Ù…Øª Ø¯ÛŒØªØ§Ø³Øª Ø³Ø§Ø²Ú¯Ø§Ø± Ù†ÛŒØ³Øª")
        return
        
    print(f"\nğŸ“Š Available symbols in dataset: {available_symbols}")
    symbol_to_test = input("ğŸ’± Which symbol to test? (e.g. BTC/USDT): ").upper().strip()
    
    if symbol_to_test not in available_symbols:
        print(f"âŒ Symbol '{symbol_to_test}' not found in dataset")
        print(f"âœ… Available symbols: {', '.join(available_symbols)}")
        return

    try:
        available_timeframes = df_full.loc[symbol_to_test].index.get_level_values('timeframe').unique().tolist()
        print(f"â±ï¸ Available timeframes for {symbol_to_test}: {available_timeframes}")
        timeframe_to_test = input("ğŸ• Which timeframe to test? (e.g. 1h): ").lower().strip()
        
        if timeframe_to_test not in available_timeframes:
            print(f"âŒ Timeframe '{timeframe_to_test}' not found")
            print(f"âœ… Available timeframes: {', '.join(available_timeframes)}")
            return
            
    except KeyError as e:
        logging.error(f"Symbol/timeframe combination error: {e}")
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§Ø¯")
        return

    try:
        df = df_full.loc[(symbol_to_test, timeframe_to_test)].copy()
        logging.info(f"ğŸ“ˆ Dataset for {symbol_to_test} {timeframe_to_test}: {len(df)} records")
        
        if len(df) < TARGET_FUTURE_PERIODS * 2:
            logging.warning(f"âš ï¸ Insufficient data for meaningful backtest")
            print(f"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ú©â€ŒØªØ³Øª Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±")
            
    except KeyError:
        logging.error(f"Symbol/timeframe combination not found.")
        print(f"âŒ ØªØ±Ú©ÛŒØ¨ Ù†Ù…Ø§Ø¯/ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return
        
    logging.info(f"ğŸš€ Starting backtest for {symbol_to_test} on {timeframe_to_test}...")

    # Ø´Ø±ÙˆØ¹ Ø¨Ú©â€ŒØªØ³Øª
    capital = INITIAL_CAPITAL
    position_open = False
    entry_price = 0
    entry_index = -1
    entry_date = None
    trade_history = []

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    feature_columns = [col for col in df.columns if col not in ['target', 'timestamp']]
    if not feature_columns:
        logging.error("âŒ No feature columns found in dataset")
        print("âŒ Ù‡ÛŒÚ† ÙˆÛŒÚ˜Ú¯ÛŒ Ø¯Ø± Ø¯ÛŒØªØ§Ø³Øª ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return
        
    X = df[feature_columns]
    
    try:
        X_scaled = scaler.transform(X)
        if hasattr(model, 'predict_proba'):
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² threshold Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            y_prob = model.predict_proba(X_scaled)[:, 1]
            df['prediction'] = (y_prob >= optimal_threshold).astype(int)
            df['prediction_prob'] = y_prob
            logging.info(f"âœ… Using optimized threshold: {optimal_threshold:.4f}")
        else:
            df['prediction'] = model.predict(X_scaled)
            df['prediction_prob'] = 0.5  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            
    except Exception as pred_error:
        logging.error(f"Error in model prediction: {pred_error}")
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„: {pred_error}")
        return
    
    # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
    for i in range(len(df) - TARGET_FUTURE_PERIODS):
        current_row = df.iloc[i]
        
        if not position_open and current_row['prediction'] == 1:
            position_open = True
            entry_price = current_row['close']
            entry_index = i
            entry_date = df.index[i]
            logging.info(f"ğŸŸ¢ Entry at {entry_date}: price ${entry_price:.4f}")

        elif position_open and (i >= entry_index + TARGET_FUTURE_PERIODS):
            exit_price = current_row['close']
            exit_date = df.index[i]
            pnl_percent = (exit_price - entry_price) / entry_price
            
            # ØªØ¹ÛŒÛŒÙ† Ø¯Ù„ÛŒÙ„ Ø®Ø±ÙˆØ¬
            exit_reason = "Target period reached"
            if pnl_percent < -0.05:
                exit_reason = "Stop loss (-5%)"
            elif pnl_percent > 0.10:
                exit_reason = "Take profit (+10%)"
            
            trade_history.append({
                'entry_date': entry_date, 
                'entry_price': entry_price,
                'exit_date': exit_date, 
                'exit_price': exit_price, 
                'pnl': pnl_percent,
                'exit_reason': exit_reason
            })
            
            trade_amount = capital * TRADE_SIZE_PERCENT
            capital += trade_amount * pnl_percent
            position_open = False
            entry_index = -1
            logging.info(f"ğŸ”´ Exit at {exit_date}: price ${exit_price:.4f}, P/L: {pnl_percent:.2%}, Reason: {exit_reason}")

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
    final_capital = capital
    total_return = (final_capital - INITIAL_CAPITAL) / INITIAL_CAPITAL
    num_trades = len(trade_history)
    wins = [t for t in trade_history if t['pnl'] > 0]
    losses = [t for t in trade_history if t['pnl'] <= 0]
    win_rate = len(wins) / num_trades if num_trades > 0 else 0
    
    report_data = {
        'Initial Capital': f"${INITIAL_CAPITAL:,.2f}",
        'Final Capital': f"${final_capital:,.2f}",
        'Total Return': f"{total_return:.2%}",
        'Total Trades': num_trades,
        'Winning Trades': len(wins),
        'Losing Trades': len(losses),
        'Win Rate': f"{win_rate:.2%}",
        'trade_history': trade_history
    }
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    print("\n" + "="*50 + "\n      Strategy Performance Report\n" + "="*50)
    for key, value in report_data.items():
        if key != 'trade_history': 
            print(f"{key:<20} {value}")
    print("="*50)
    
    # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
    generate_report_file(report_data, symbol_to_test, timeframe_to_test)
    
    # ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
    try:
        generate_visualizations(df, trade_history, symbol_to_test, timeframe_to_test, report_subfolder_path)
    except Exception as viz_error:
        logging.warning(f"Error generating visualizations: {viz_error}")
    
    print(f"\nâœ… Backtest completed successfully!")
    print(f"ğŸ“ Reports saved to: {report_subfolder_path}")

def run_enhanced_backtest(features_path: str, models_path: str):
    """Run enhanced backtest with multi-symbol and multi-timeframe support - Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡"""
    logging.info("="*70)
    logging.info("Starting Enhanced Backtest Strategy")
    logging.info("="*70)
    
    try:
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ error handling Ø¨Ù‡ØªØ±
        feature_file = find_latest_file(
            os.path.join(features_path, 'final_dataset_for_training_*.parquet'),
            "dataset file"
        )
        if not feature_file:
            logging.error("âŒ No dataset file found")
            print("âŒ ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§Ø³Øª ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return
            
        logging.info(f"Loading dataset: {os.path.basename(feature_file)}")
        df_full = pd.read_parquet(feature_file)
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
        model_file = find_latest_file(
            os.path.join(models_path, 'optimized_model_*.joblib'),
            "optimized model"
        )
        if not model_file:
            model_file = find_latest_file(
                os.path.join(models_path, 'random_forest_model_*.joblib'),
                "random forest model"
            )
            
        scaler_file = find_latest_file(
            os.path.join(models_path, 'scaler_optimized_*.joblib'),
            "optimized scaler"
        )
        if not scaler_file:
            scaler_file = find_latest_file(
                os.path.join(models_path, 'scaler_*.joblib'),
                "scaler"
            )
        
        if not model_file or not scaler_file:
            logging.error("âŒ Required model or scaler files not found")
            print("âŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ ÛŒØ§ scaler ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ scaler
        model_data = joblib.load(model_file)
        if isinstance(model_data, dict) and 'model' in model_data:
            model = model_data['model']
            optimal_threshold = model_data.get('optimal_threshold', 0.5)
        else:
            model = model_data
            optimal_threshold = 0.5
            
        scaler = joblib.load(scaler_file)
        logging.info("âœ… Model and scaler loaded successfully.")
        
    except Exception as e:
        logging.error(f"Error loading files: {e}")
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {e}")
        return

    # Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
    selected_symbols, selected_timeframes = select_symbols_and_timeframes(df_full)
    if not selected_symbols or not selected_timeframes:
        return
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ú©Ù„ÛŒ
    all_results = []
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ú©â€ŒØªØ³Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØªØ±Ú©ÛŒØ¨
    for symbol in selected_symbols:
        for timeframe in selected_timeframes:
            try:
                df = df_full.loc[(symbol, timeframe)].copy()
                if len(df) < TARGET_FUTURE_PERIODS * 2:
                    logging.warning(f"Insufficient data for {symbol}/{timeframe}. Skipping...")
                    continue
                
                logging.info(f"\n{'='*50}")
                logging.info(f"Backtesting {symbol} on {timeframe}")
                logging.info(f"Records: {len(df)}")
                
                # Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¨Ú©â€ŒØªØ³Øª
                capital = INITIAL_CAPITAL
                equity_curve = [capital]
                position_open = False
                entry_price = 0
                entry_index = -1
                entry_date = None
                trade_history = []
                
                # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„
                feature_columns = [col for col in df.columns if col not in ['target', 'timestamp']]
                X = df[feature_columns]
                X_scaled = scaler.transform(X)
                
                if hasattr(model, 'predict_proba'):
                    y_prob = model.predict_proba(X_scaled)[:, 1]
                    df['prediction'] = (y_prob >= optimal_threshold).astype(int)
                    df['prediction_proba'] = y_prob
                else:
                    df['prediction'] = model.predict(X_scaled)
                    df['prediction_proba'] = model.predict_proba(X_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
                
                # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
                for i in range(len(df) - TARGET_FUTURE_PERIODS):
                    current_row = df.iloc[i]
                    
                    # Ù…Ù†Ø·Ù‚ ÙˆØ±ÙˆØ¯
                    if not position_open and current_row['prediction'] == 1:
                        position_open = True
                        entry_price = current_row['close']
                        entry_index = i
                        entry_date = df.index[i]
                        logging.info(f"ğŸŸ¢ Entry at {entry_date}: ${entry_price:.4f}")
                    
                    # Ù…Ù†Ø·Ù‚ Ø®Ø±ÙˆØ¬
                    elif position_open:
                        exit_condition = False
                        exit_reason = ""
                        
                        # Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø±Ø§ÛŒØ· Ù…Ø®ØªÙ„Ù Ø®Ø±ÙˆØ¬
                        if i >= entry_index + TARGET_FUTURE_PERIODS:
                            exit_condition = True
                            exit_reason = "Target period reached"
                        elif (current_row['close'] - entry_price) / entry_price < -0.05:  # 5% stop loss
                            exit_condition = True
                            exit_reason = "Stop loss (-5%)"
                        elif (current_row['close'] - entry_price) / entry_price > 0.10:  # 10% take profit
                            exit_condition = True
                            exit_reason = "Take profit (+10%)"
                        elif current_row['prediction'] == 0 and i > entry_index + 5:  # ØªØºÛŒÛŒØ± Ø³ÛŒÚ¯Ù†Ø§Ù„
                            exit_condition = True
                            exit_reason = "Signal reversed"
                        
                        if exit_condition:
                            exit_price = current_row['close']
                            exit_date = df.index[i]
                            pnl_percent = (exit_price - entry_price) / entry_price
                            
                            trade_history.append({
                                'entry_date': entry_date,
                                'entry_price': entry_price,
                                'exit_date': exit_date,
                                'exit_price': exit_price,
                                'pnl': pnl_percent,
                                'exit_reason': exit_reason
                            })
                            
                            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³Ø±Ù…Ø§ÛŒÙ‡
                            trade_amount = capital * TRADE_SIZE_PERCENT
                            profit_loss = trade_amount * pnl_percent
                            capital += profit_loss
                            equity_curve.append(capital)
                            
                            position_open = False
                            entry_index = -1
                            
                            emoji = "âœ…" if pnl_percent > 0 else "âŒ"
                            logging.info(f"{emoji} Exit at {exit_date}: ${exit_price:.4f}, "
                                       f"P&L: {pnl_percent:.2%}, Reason: {exit_reason}")
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
                final_capital = capital
                total_return = (final_capital - INITIAL_CAPITAL) / INITIAL_CAPITAL
                num_trades = len(trade_history)
                wins = [t for t in trade_history if t['pnl'] > 0]
                losses = [t for t in trade_history if t['pnl'] <= 0]
                win_rate = len(wins) / num_trades if num_trades > 0 else 0
                
                # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
                result = {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'total_return': total_return,
                    'num_trades': num_trades,
                    'win_rate': win_rate,
                    'final_capital': final_capital
                }
                all_results.append(result)
                
                # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´
                report_data = {
                    'Initial Capital': f"{INITIAL_CAPITAL:,.2f}",
                    'Final Capital': f"{final_capital:,.2f}",
                    'Total Return': f"{total_return:.2%}",
                    'Total Trades': num_trades,
                    'Winning Trades': len(wins),
                    'Losing Trades': len(losses),
                    'Win Rate': f"{win_rate:.2%}",
                    'trade_history': trade_history
                }
                
                # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡
                print(f"\n{'='*40}")
                print(f"ğŸ“Š {symbol} ({timeframe}) Results:")
                print(f"ğŸ’° Return: {total_return:.2%}")
                print(f"ğŸ“ˆ Trades: {num_trades} (Win Rate: {win_rate:.1%})")
                print(f"ğŸ’µ Final Capital: ${final_capital:,.2f}")
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØ¬Ø³Ù…â€ŒÙ‡Ø§ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§
                equity_series = pd.Series(equity_curve, index=df.index[:len(equity_curve)])
                generate_enhanced_report(report_data, symbol, timeframe, df, equity_series)
                
                try:
                    generate_visualizations(df, trade_history, symbol, timeframe, report_subfolder_path)
                except Exception as viz_error:
                    logging.warning(f"Error generating visualizations for {symbol}/{timeframe}: {viz_error}")
                
            except KeyError:
                logging.error(f"Combination {symbol}/{timeframe} not found.")
                continue
            except Exception as e:
                logging.error(f"Error processing {symbol}/{timeframe}: {e}")
                continue
    
    # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ú†Ù†Ø¯ ØªØ³Øª
    if len(all_results) > 1:
        print("\n" + "="*60)
        print("ğŸ“Š OVERALL BACKTEST SUMMARY")
        print("="*60)
        print(f"{'Symbol':<15} {'TF':<5} {'Return':<10} {'Trades':<8} {'Win%':<8} {'Final $':<12}")
        print("-"*60)
        
        total_return_sum = 0
        for r in all_results:
            print(f"{r['symbol']:<15} {r['timeframe']:<5} "
                  f"{r['total_return']:>9.2%} {r['num_trades']:>7} "
                  f"{r['win_rate']:>7.1%} ${r['final_capital']:>11,.2f}")
            total_return_sum += r['total_return']
        
        print("-"*60)
        avg_return = total_return_sum / len(all_results) if all_results else 0
        print(f"Average Return: {avg_return:.2%}")
        print("="*60)
    
    print(f"\nâœ… All reports and charts saved to:")
    print(f"   ğŸ“ {report_subfolder_path}")

if __name__ == '__main__':
    print("\n" + "="*70)
    print("ğŸš€ Advanced Backtesting System v2.1")
    print("ğŸ“Š Multi-Symbol & Multi-Timeframe Support")
    print("ğŸ”§ Fixed 'max() arg is an empty sequence' Error")
    print("="*70)
    
    choice = input("\nSelect mode:\n1. Enhanced Backtest (recommended)\n2. Simple Backtest\nChoice (1/2): ").strip()
    
    if choice == '2':
        run_simple_backtest(FEATURES_PATH, MODELS_PATH)
    else:
        run_enhanced_backtest(FEATURES_PATH, MODELS_PATH)