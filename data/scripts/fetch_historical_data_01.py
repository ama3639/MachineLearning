#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø± (Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ)

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø§Ø¯ØºØ§Ù…ÛŒ Ø§Ø² fetch_historical_data_01.py Ùˆ fetch_news_01a.py Ø§Ø³Øª
Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
- State Management ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù…Ø§Ø¯ Ùˆ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ
- Ù…Ø¯ÛŒØ±ÛŒØª Rate Limit Ù…Ø´ØªØ±Ú©
- Ù…Ù†ÙˆÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ú©Ø§Ù…Ù„
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¯Ø± Ù‡Ù…Ù‡ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
- Ø§Ø®Ø¨Ø§Ø± ÙÙ‚Ø· Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù API)
- Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ ÙØ¹Ø§Ù„
- Backfill Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
- Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡: GNews + NewsAPI + CoinGecko + RSS (Ø¬Ø¯ÛŒØ¯)
"""

import os
import time
import pandas as pd
import requests
import logging
import configparser
from datetime import datetime, timezone, timedelta
import threading
import json
import sqlite3
from typing import Dict, List, Optional, Tuple
import threading
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# === imports Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ø§Ø¶Ø§ÙÛŒ ===
try:
    import feedparser
    RSS_AVAILABLE = True
except ImportError:
    RSS_AVAILABLE = False
    logging.warning("feedparser not available. RSS feeds disabled.")

try:
    from concurrent.futures import ThreadPoolExecutor, as_completed
    CONCURRENT_AVAILABLE = True
except ImportError:
    CONCURRENT_AVAILABLE = False
    logging.warning("concurrent.futures not available. Parallel processing disabled.")

# --- Ø¨Ø®Ø´ Ø®ÙˆØ§Ù†Ø¯Ù† Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ---
config = configparser.ConfigParser()
CONFIG_FILE_PATH = 'config.ini'
try:
    config.read(CONFIG_FILE_PATH, encoding='utf-8')
    RAW_DATA_PATH = config.get('Paths', 'raw')
    LOG_PATH = config.get('Paths', 'logs')
    
    # Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ù…ÙˆØ¬ÙˆØ¯
    CRYPTOCOMPARE_API_KEY = config.get('API_Keys', 'cryptocompare_api_key', fallback=None)
    GNEWS_API_KEY = config.get('API_Keys', 'gnews_api_key', fallback=None)
    
    # === Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø¬Ø¯ÛŒØ¯ ===
    NEWSAPI_KEY = config.get('API_Keys', 'newsapi_key', fallback=None)
    ALPHA_VANTAGE_KEY = config.get('API_Keys', 'alpha_vantage_key', fallback=None)
    
    # === ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹ ===
    GNEWS_ENABLED = config.getboolean('News_Sources', 'gnews_enabled', fallback=True)
    NEWSAPI_ENABLED = config.getboolean('News_Sources', 'newsapi_enabled', fallback=True)
    COINGECKO_ENABLED = config.getboolean('News_Sources', 'coingecko_enabled', fallback=True)
    RSS_ENABLED = config.getboolean('News_Sources', 'rss_enabled', fallback=True)
    PARALLEL_FETCHING = config.getboolean('News_Sources', 'parallel_fetching', fallback=True)
    REMOVE_DUPLICATES = config.getboolean('News_Sources', 'remove_duplicates', fallback=True)
    
    # Rate Limits Ù…ÙˆØ¬ÙˆØ¯
    CRYPTOCOMPARE_DELAY = config.getfloat('Rate_Limits', 'cryptocompare_delay', fallback=0.6)
    BINANCE_DELAY = config.getfloat('Rate_Limits', 'binance_delay', fallback=0.1)
    KRAKEN_DELAY = config.getfloat('Rate_Limits', 'kraken_delay', fallback=1.5)
    GNEWS_DELAY = config.getfloat('Rate_Limits', 'gnews_delay', fallback=1.0)
    
    # === Rate Limits Ø¬Ø¯ÛŒØ¯ ===
    NEWSAPI_DELAY = config.getfloat('Rate_Limits', 'newsapi_delay', fallback=2.0)
    COINGECKO_DELAY = config.getfloat('Rate_Limits', 'coingecko_delay', fallback=1.0)
    RSS_DELAY = config.getfloat('Rate_Limits', 'rss_delay', fallback=0.5)
    
    # Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    DAILY_LIMIT = config.getint('Rate_Limits', 'cryptocompare_daily_limit', fallback=3200)
    HOURLY_LIMIT = config.getint('Rate_Limits', 'cryptocompare_hourly_limit', fallback=135)
    GNEWS_DAILY_LIMIT = config.getint('Rate_Limits', 'gnews_daily_limit', fallback=100)
    GNEWS_HOURLY_LIMIT = config.getint('Rate_Limits', 'gnews_hourly_limit', fallback=10)
    
    # === Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ ===
    NEWSAPI_DAILY_LIMIT = config.getint('Rate_Limits', 'newsapi_daily_limit', fallback=33)
    NEWSAPI_MONTHLY_LIMIT = config.getint('Rate_Limits', 'newsapi_monthly_limit', fallback=1000)
    
    MAX_REQUESTS_PER_SESSION = config.getint('Data_Settings', 'max_requests_per_session', fallback=500)
    
    # === ØªÙ†Ø¸ÛŒÙ…Ø§Øª RSS ===
    RSS_CACHE_MINUTES = config.getint('RSS_Feeds', 'rss_cache_minutes', fallback=5)
    MAX_ARTICLES_PER_FEED = config.getint('RSS_Feeds', 'max_articles_per_feed', fallback=20)
    RSS_TIMEOUT = config.getint('RSS_Feeds', 'rss_timeout', fallback=10)
    
except Exception as e:
    print(f"CRITICAL ERROR: Could not read 'config.ini'. Error: {e}")
    exit()

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª logging
script_name = os.path.splitext(os.path.basename(__file__))[0]
log_subfolder_path = os.path.join(LOG_PATH, script_name)
os.makedirs(log_subfolder_path, exist_ok=True)
os.makedirs(RAW_DATA_PATH, exist_ok=True)

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² Ù…Ø³ÛŒØ± raw Ø¨Ø¯ÙˆÙ† Ø§ÛŒØ¬Ø§Ø¯ Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡
price_data_path = RAW_DATA_PATH
news_data_path = RAW_DATA_PATH
os.makedirs(price_data_path, exist_ok=True)
os.makedirs(news_data_path, exist_ok=True)

log_filename = os.path.join(log_subfolder_path, f"log_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler(log_filename, encoding='utf-8'), logging.StreamHandler()])

# Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ - Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù…
COMMON_PAIRS = [
    "BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "SOL/USDT", "ADA/USDT", 
    "DOGE/USDT", "SHIB/USDT", "TRX/USDT", "MATIC/USDT", "LTC/USDT", "DOT/USDT", 
    "AVAX/USDT", "LINK/USDT", "BCH/USDT", "UNI/USDT", "FIL/USDT", "ETC/USDT", 
    "ATOM/USDT", "ICP/USDT", "VET/USDT", "OP/USDT", "ARB/USDT", "APT/USDT", 
    "NEAR/USDT", "FTM/USDT", "RNDR/USDT", "GRT/USDT", "MANA/USDT", "SAND/USDT"
]
COMMON_TIMEFRAMES = ["1m", "5m", "15m", "1h", "4h", "1d"]
LIMIT = 2000
MAX_NEWS_PER_SYMBOL = 10

# --- Ú©Ù„Ø§Ø³ State Management ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ ---
class UnifiedStateManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª state ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±"""
    
    def __init__(self, db_path: str = None):
        if db_path is None:
            db_path = os.path.join(RAW_DATA_PATH, 'unified_extraction_state.db')
        self.db_path = db_path
        self.setup_database()
        logging.info(f"ğŸ’¾ Unified State Manager Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯: {db_path}")
    
    def setup_database(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²"""
        with sqlite3.connect(self.db_path) as conn:
            conn.executescript('''
                -- Ø¬Ø¯ÙˆÙ„ Ø§ØµÙ„ÛŒ sessions
                CREATE TABLE IF NOT EXISTS extraction_sessions (
                    session_id TEXT PRIMARY KEY,
                    session_type TEXT CHECK(session_type IN ('price', 'news', 'unified')),
                    status TEXT DEFAULT 'active',
                    total_symbols INTEGER,
                    completed_symbols INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                
                -- Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª
                CREATE TABLE IF NOT EXISTS price_progress (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    exchange TEXT,
                    symbol TEXT,
                    timeframe TEXT,
                    status TEXT DEFAULT 'pending',
                    file_path TEXT,
                    records_count INTEGER,
                    error_message TEXT,
                    completed_at TIMESTAMP,
                    FOREIGN KEY (session_id) REFERENCES extraction_sessions(session_id)
                );
                
                -- Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ´Ø±ÙØª Ø§Ø®Ø¨Ø§Ø±
                CREATE TABLE IF NOT EXISTS news_progress (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    symbol TEXT,
                    language TEXT,
                    status TEXT DEFAULT 'pending',
                    file_path TEXT,
                    news_count INTEGER,
                    error_message TEXT,
                    completed_at TIMESTAMP,
                    FOREIGN KEY (session_id) REFERENCES extraction_sessions(session_id)
                );
                
                -- Ø¬Ø¯ÙˆÙ„ rate limits
                CREATE TABLE IF NOT EXISTS rate_limits (
                    api_name TEXT PRIMARY KEY,
                    daily_count INTEGER DEFAULT 0,
                    hourly_count INTEGER DEFAULT 0,
                    last_daily_reset TEXT,
                    last_hourly_reset TEXT,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                
                -- Ø¬Ø¯ÙˆÙ„ failed items
                CREATE TABLE IF NOT EXISTS failed_items (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    item_type TEXT CHECK(item_type IN ('price', 'news')),
                    exchange TEXT,
                    symbol TEXT,
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            ''')
        logging.info("âœ… Unified Database ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯")
    
    def create_unified_session(self, symbols: List[str], include_price: bool = True, 
                              include_news: bool = True) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ session ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¬Ø¯ÛŒØ¯"""
        session_id = f"unified_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        session_type = 'unified' if include_price and include_news else ('price' if include_price else 'news')
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT INTO extraction_sessions 
                (session_id, session_type, total_symbols, status)
                VALUES (?, ?, ?, 'active')
            ''', (session_id, session_type, len(symbols)))
        
        logging.info(f"ğŸ†• Unified Session Ø¬Ø¯ÛŒØ¯: {session_id} (Ù†ÙˆØ¹: {session_type})")
        return session_id
    
    def update_price_progress(self, session_id: str, exchange: str, symbol: str, 
                            timeframe: str, status: str, **kwargs):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª"""
        with sqlite3.connect(self.db_path) as conn:
            # Ú†Ú© ÙˆØ¬ÙˆØ¯ Ø±Ú©ÙˆØ±Ø¯
            cursor = conn.execute('''
                SELECT id FROM price_progress 
                WHERE session_id = ? AND exchange = ? AND symbol = ? AND timeframe = ?
            ''', (session_id, exchange, symbol, timeframe))
            
            if cursor.fetchone():
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
                update_fields = ['status = ?']
                update_values = [status]
                
                if 'file_path' in kwargs:
                    update_fields.append('file_path = ?')
                    update_values.append(kwargs['file_path'])
                if 'records_count' in kwargs:
                    update_fields.append('records_count = ?')
                    update_values.append(kwargs['records_count'])
                if 'error_message' in kwargs:
                    update_fields.append('error_message = ?')
                    update_values.append(kwargs['error_message'])
                
                if status == 'completed':
                    update_fields.append('completed_at = CURRENT_TIMESTAMP')
                
                update_values.extend([session_id, exchange, symbol, timeframe])
                
                conn.execute(f'''
                    UPDATE price_progress 
                    SET {', '.join(update_fields)}
                    WHERE session_id = ? AND exchange = ? AND symbol = ? AND timeframe = ?
                ''', update_values)
            else:
                # Ø¯Ø±Ø¬ Ø¬Ø¯ÛŒØ¯
                conn.execute('''
                    INSERT INTO price_progress 
                    (session_id, exchange, symbol, timeframe, status, file_path, records_count, error_message)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (session_id, exchange, symbol, timeframe, status, 
                     kwargs.get('file_path'), kwargs.get('records_count'), kwargs.get('error_message')))
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ session
            if status == 'completed':
                conn.execute('''
                    UPDATE extraction_sessions 
                    SET completed_symbols = completed_symbols + 1, updated_at = CURRENT_TIMESTAMP
                    WHERE session_id = ?
                ''', (session_id,))
    
    def update_news_progress(self, session_id: str, symbol: str, language: str, 
                           status: str, **kwargs):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø§Ø®Ø¨Ø§Ø±"""
        with sqlite3.connect(self.db_path) as conn:
            # Ú†Ú© ÙˆØ¬ÙˆØ¯ Ø±Ú©ÙˆØ±Ø¯
            cursor = conn.execute('''
                SELECT id FROM news_progress 
                WHERE session_id = ? AND symbol = ? AND language = ?
            ''', (session_id, symbol, language))
            
            if cursor.fetchone():
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
                update_fields = ['status = ?']
                update_values = [status]
                
                if 'file_path' in kwargs:
                    update_fields.append('file_path = ?')
                    update_values.append(kwargs['file_path'])
                if 'news_count' in kwargs:
                    update_fields.append('news_count = ?')
                    update_values.append(kwargs['news_count'])
                if 'error_message' in kwargs:
                    update_fields.append('error_message = ?')
                    update_values.append(kwargs['error_message'])
                
                if status == 'completed':
                    update_fields.append('completed_at = CURRENT_TIMESTAMP')
                
                update_values.extend([session_id, symbol, language])
                
                conn.execute(f'''
                    UPDATE news_progress 
                    SET {', '.join(update_fields)}
                    WHERE session_id = ? AND symbol = ? AND language = ?
                ''', update_values)
            else:
                # Ø¯Ø±Ø¬ Ø¬Ø¯ÛŒØ¯
                conn.execute('''
                    INSERT INTO news_progress 
                    (session_id, symbol, language, status, file_path, news_count, error_message)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (session_id, symbol, language, status, 
                     kwargs.get('file_path'), kwargs.get('news_count'), kwargs.get('error_message')))
    
    def get_session_status(self, session_id: str) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ session"""
        with sqlite3.connect(self.db_path) as conn:
            # Ø§Ø·Ù„Ø§Ø¹Ø§Øª session
            cursor = conn.execute('''
                SELECT * FROM extraction_sessions WHERE session_id = ?
            ''', (session_id,))
            session_info = cursor.fetchone()
            
            if not session_info:
                return None
            
            # Ù¾ÛŒØ´Ø±ÙØª Ù‚ÛŒÙ…Øª
            cursor = conn.execute('''
                SELECT COUNT(*) total, 
                       SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) completed
                FROM price_progress WHERE session_id = ?
            ''', (session_id,))
            price_progress = cursor.fetchone()
            
            # Ù¾ÛŒØ´Ø±ÙØª Ø§Ø®Ø¨Ø§Ø±
            cursor = conn.execute('''
                SELECT COUNT(*) total, 
                       SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) completed
                FROM news_progress WHERE session_id = ?
            ''', (session_id,))
            news_progress = cursor.fetchone()
            
            return {
                'session_id': session_info[0],
                'session_type': session_info[1],
                'status': session_info[2],
                'total_symbols': session_info[3],
                'completed_symbols': session_info[4],
                'price_progress': {
                    'total': price_progress[0] if price_progress else 0,
                    'completed': price_progress[1] if price_progress else 0
                },
                'news_progress': {
                    'total': news_progress[0] if news_progress else 0,
                    'completed': news_progress[1] if news_progress else 0
                }
            }
    
    def add_failed_item(self, item_type: str, symbol: str, error_msg: str, exchange: str = None):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO failed_items (item_type, exchange, symbol, error_message)
                VALUES (?, ?, ?, ?)
            ''', (item_type, exchange, symbol, error_msg))
    
    def is_failed_item(self, item_type: str, symbol: str, exchange: str = None) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø¢ÛŒØªÙ… Ù‚Ø¨Ù„Ø§Ù‹ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT 1 FROM failed_items 
                WHERE item_type = ? AND symbol = ? AND (exchange = ? OR exchange IS NULL)
            ''', (item_type, symbol, exchange))
            return cursor.fetchone() is not None

# --- Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Rate Limit ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ (Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡) ---
class UnifiedRateLimiter:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†Ø±Ø® Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ API Ù‡Ø§"""
    
    def __init__(self, state_manager: UnifiedStateManager):
        self.state_manager = state_manager
        self.last_request_time = {}
        self.request_counters = {
            'CryptoCompare': {'daily': 0, 'hourly': 0, 'session': 0},
            'Binance': {'session': 0},
            'Kraken': {'session': 0},
            'GNews': {'daily': 0, 'hourly': 0, 'session': 0},
            # === Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ ===
            'NewsAPI': {'daily': 0, 'monthly': 0, 'session': 0},
            'CoinGecko': {'session': 0},
            'RSS': {'session': 0}
        }
        
        self.min_intervals = {
            'CryptoCompare': CRYPTOCOMPARE_DELAY,
            'Binance': BINANCE_DELAY,
            'Kraken': KRAKEN_DELAY,
            'GNews': GNEWS_DELAY,
            # === Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ ===
            'NewsAPI': NEWSAPI_DELAY,
            'CoinGecko': COINGECKO_DELAY,
            'RSS': RSS_DELAY
        }
        
        self.limits = {
            'CryptoCompare': {
                'daily': DAILY_LIMIT,
                'hourly': HOURLY_LIMIT,
                'session': MAX_REQUESTS_PER_SESSION
            },
            'GNews': {
                'daily': GNEWS_DAILY_LIMIT,
                'hourly': GNEWS_HOURLY_LIMIT,
                'session': MAX_REQUESTS_PER_SESSION
            },
            # === Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ ===
            'NewsAPI': {
                'daily': NEWSAPI_DAILY_LIMIT,
                'monthly': NEWSAPI_MONTHLY_LIMIT,
                'session': MAX_REQUESTS_PER_SESSION
            }
        }
        
        self.lock = threading.Lock()
        self.load_persisted_state()
        self.hour_start = time.time()
        self.day_start = time.time()
        logging.info(f"ğŸ”§ Enhanced Rate Limiter Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯")
    
    def load_persisted_state(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø² database"""
        with sqlite3.connect(self.state_manager.db_path) as conn:
            for api_name in ['CryptoCompare', 'GNews', 'NewsAPI']:
                cursor = conn.execute('SELECT * FROM rate_limits WHERE api_name = ?', (api_name,))
                row = cursor.fetchone()
                
                if row and api_name in self.request_counters:
                    self.request_counters[api_name]['daily'] = row[1]
                    self.request_counters[api_name]['hourly'] = row[2]
                    
                    # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø±ÛŒØ³Øª
                    if row[3]:  # last_daily_reset
                        last_daily = datetime.fromisoformat(row[3])
                        if (datetime.now() - last_daily).days >= 1:
                            self.reset_daily_counter(api_name)
                    
                    if row[4]:  # last_hourly_reset  
                        last_hourly = datetime.fromisoformat(row[4])
                        if (datetime.now() - last_hourly).total_seconds() >= 3600:
                            self.reset_hourly_counter(api_name)
    
    def save_state(self, api_name: str):
        """Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± database"""
        if api_name not in ['CryptoCompare', 'GNews', 'NewsAPI']:
            return
            
        counters = self.request_counters[api_name]
        now = datetime.now().isoformat()
        
        with sqlite3.connect(self.state_manager.db_path) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO rate_limits 
                (api_name, daily_count, hourly_count, last_daily_reset, last_hourly_reset)
                VALUES (?, ?, ?, ?, ?)
            ''', (api_name, counters.get('daily', 0), counters.get('hourly', 0), now, now))
    
    def reset_daily_counter(self, api_name: str):
        """Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡"""
        if api_name in self.request_counters:
            self.request_counters[api_name]['daily'] = 0
            logging.info(f"ğŸ”„ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡ {api_name} Ø±ÛŒØ³Øª Ø´Ø¯")
            self.save_state(api_name)
    
    def reset_hourly_counter(self, api_name: str):
        """Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø³Ø§Ø¹ØªÛŒ"""
        if api_name in self.request_counters:
            self.request_counters[api_name]['hourly'] = 0
            logging.info(f"ğŸ”„ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø³Ø§Ø¹ØªÛŒ {api_name} Ø±ÛŒØ³Øª Ø´Ø¯")
            self.save_state(api_name)
    
    def check_and_wait_for_reset(self, api_name: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ùˆ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø±ÛŒØ³Øª Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²"""
        if api_name not in self.limits:
            return True
        
        counters = self.request_counters[api_name]
        limits = self.limits[api_name]
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø§Ø¹ØªÛŒ
        if 'hourly' in limits and counters.get('hourly', 0) >= limits['hourly']:
            logging.warning(f"â³ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø§Ø¹ØªÛŒ {api_name} Ø±Ø³ÛŒØ¯Ù‡ - Ø§Ù†ØªØ¸Ø§Ø± ØªØ§ Ø±ÛŒØ³Øª...")
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† ØªØ§ Ø±ÛŒØ³Øª
            now = datetime.now()
            next_hour = now.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)
            wait_seconds = (next_hour - now).total_seconds()
            
            logging.info(f"â° Ø§Ù†ØªØ¸Ø§Ø± {wait_seconds:.0f} Ø«Ø§Ù†ÛŒÙ‡ ØªØ§ Ø±ÛŒØ³Øª Ø³Ø§Ø¹ØªÛŒ...")
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
            for remaining in range(int(wait_seconds), 0, -60):
                minutes = remaining // 60
                logging.info(f"â³ {minutes} Ø¯Ù‚ÛŒÙ‚Ù‡ ØªØ§ Ø±ÛŒØ³Øª Ø³Ø§Ø¹ØªÛŒ...")
                time.sleep(min(60, remaining))
            
            # Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡
            self.reset_hourly_counter(api_name)
            logging.info("âœ… Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø§Ø¹ØªÛŒ Ø±ÛŒØ³Øª Ø´Ø¯ - Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø±...")
            return True
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡
        if 'daily' in limits and counters.get('daily', 0) >= limits['daily']:
            logging.warning(f"â³ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ {api_name} Ø±Ø³ÛŒØ¯Ù‡ - Ø§Ù†ØªØ¸Ø§Ø± ØªØ§ Ø±ÛŒØ³Øª...")
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† ØªØ§ Ø±ÛŒØ³Øª
            now = datetime.now()
            next_day = now.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1)
            wait_seconds = (next_day - now).total_seconds()
            
            logging.info(f"â° Ø§Ù†ØªØ¸Ø§Ø± {wait_seconds:.0f} Ø«Ø§Ù†ÛŒÙ‡ ØªØ§ Ø±ÛŒØ³Øª Ø±ÙˆØ²Ø§Ù†Ù‡...")
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ
            time.sleep(wait_seconds)
            self.reset_daily_counter(api_name)
            return True
        
        return True
    
    def wait_if_needed(self, api_name: str) -> bool:
        """Ø§Ø¹Ù…Ø§Ù„ ØªØ£Ø®ÛŒØ± Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª"""
        with self.lock:
            # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø±ÛŒØ³Øª Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
            if not self.check_and_wait_for_reset(api_name):
                return False
            
            # Ø§Ø¹Ù…Ø§Ù„ ØªØ£Ø®ÛŒØ± Ù…Ø¹Ù…ÙˆÙ„
            current_time = time.time()
            if api_name in self.last_request_time:
                elapsed = current_time - self.last_request_time[api_name]
                required_interval = self.min_intervals.get(api_name, 1.0)
                
                if elapsed < required_interval:
                    wait_time = required_interval - elapsed
                    time.sleep(wait_time)
            
            # Ø«Ø¨Øª Ø²Ù…Ø§Ù† Ùˆ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡
            self.last_request_time[api_name] = time.time()
            
            if api_name in self.request_counters:
                self.request_counters[api_name]['session'] += 1
                if api_name in ['CryptoCompare', 'GNews', 'NewsAPI']:
                    if 'daily' in self.request_counters[api_name]:
                        self.request_counters[api_name]['daily'] += 1
                    if 'hourly' in self.request_counters[api_name]:
                        self.request_counters[api_name]['hourly'] += 1
                    self.save_state(api_name)
            
            return True
    
    def get_stats(self, api_name: str) -> dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡"""
        if api_name not in self.request_counters:
            return {}
            
        counters = self.request_counters[api_name]
        if api_name in self.limits:
            limits = self.limits[api_name]
            result = {}
            if 'daily' in limits:
                result['daily'] = f"{counters.get('daily', 0)}/{limits['daily']}"
            if 'hourly' in limits:
                result['hourly'] = f"{counters.get('hourly', 0)}/{limits['hourly']}"
            result['session'] = f"{counters['session']}/{limits.get('session', 'N/A')}"
            return result
        else:
            return {'session': counters['session']}

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
def safe_request(url: str, params: dict = None, headers: dict = None, 
                api_name: str = None, max_retries: int = 3) -> requests.Response:
    """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§ÛŒÙ…Ù† Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯"""
    for retry in range(max_retries):
        try:
            response = requests.get(url, params=params, headers=headers, timeout=30)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            if retry == max_retries - 1:
                logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù¾Ø³ Ø§Ø² {max_retries} ØªÙ„Ø§Ø´: {e}")
                raise
            
            wait_time = 2 ** retry
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª. Ø§Ù†ØªØ¸Ø§Ø± {wait_time} Ø«Ø§Ù†ÛŒÙ‡ Ù‚Ø¨Ù„ Ø§Ø² ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
            time.sleep(wait_time)

# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
def fetch_from_cryptocompare(symbol: str, timeframe: str, limit: int, to_ts: int = None) -> pd.DataFrame:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø§Ø² CryptoCompare API"""
    if not CRYPTOCOMPARE_API_KEY:
        logging.warning("Ú©Ù„ÛŒØ¯ API Ø¨Ø±Ø§ÛŒ CryptoCompare ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return pd.DataFrame()
    
    BASE_URL = "https://min-api.cryptocompare.com/data/v2/"
    endpoint_map = {'m': 'histominute', 'h': 'histohour', 'd': 'histoday'}
    
    try:
        tf_unit = timeframe.lower()[-1]
        tf_agg = int(timeframe[:-1])
        endpoint = endpoint_map.get(tf_unit)
        if not endpoint: raise ValueError("Timeframe unit not recognized.")
        base_sym, quote_sym = symbol.upper().split('/')
    except Exception:
        logging.error(f"[CryptoCompare] ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… ÛŒØ§ Ù†Ù…Ø§Ø¯ Ù†Ø§Ù…Ø¹ØªØ¨Ø±: '{timeframe}', '{symbol}'")
        return pd.DataFrame()
    
    params = {"fsym": base_sym, "tsym": quote_sym, "limit": limit, "aggregate": tf_agg}
    if CRYPTOCOMPARE_API_KEY:
        params["api_key"] = CRYPTOCOMPARE_API_KEY
    if to_ts:
        params['toTs'] = to_ts
    
    logging.info(f"[CryptoCompare] Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} | {timeframe}...")
    
    try:
        response = safe_request(f"{BASE_URL}{endpoint}", params=params, api_name="CryptoCompare")
        data = response.json()
        
        if data.get('Response') == 'Error':
            error_msg = data.get('Message', 'Unknown error')
            logging.error(f"[CryptoCompare] Ø®Ø·Ø§ Ø§Ø² API: {error_msg}")
            return pd.DataFrame()
        
        df = pd.DataFrame(data['Data']['Data'])
        if df.empty: return pd.DataFrame()
        
        df.rename(columns={'volumefrom': 'volume'}, inplace=True)
        df['timestamp'] = pd.to_datetime(df['time'], unit='s')
        df['symbol'] = symbol
        df['timeframe'] = timeframe
        df['exchange'] = 'CryptoCompare'
        
        return df
        
    except Exception as e:
        logging.error(f"[CryptoCompare] Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡: {e}")
        return pd.DataFrame()

def fetch_from_binance(symbol: str, timeframe: str, limit: int, **kwargs) -> pd.DataFrame:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Binance API"""
    try:
        binance_symbol = symbol.replace('/', '').upper()
        timeframe_map = {
            '1m': '1m', '3m': '3m', '5m': '5m', '15m': '15m', '30m': '30m',
            '1h': '1h', '2h': '2h', '4h': '4h', '6h': '6h', '8h': '8h', '12h': '12h',
            '1d': '1d', '3d': '3d', '1w': '1w', '1M': '1M'
        }
        
        binance_interval = timeframe_map.get(timeframe, timeframe)
        params = {
            'symbol': binance_symbol,
            'interval': binance_interval,
            'limit': min(limit, 1000)
        }
        
        logging.info(f"[Binance] Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} | {timeframe}...")
        
        response = safe_request("https://api.binance.com/api/v3/klines", params=params, api_name="Binance")
        data = response.json()
        
        if not data:
            logging.warning(f"[Binance] Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} | {timeframe} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return pd.DataFrame()
        
        df = pd.DataFrame(data, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_asset_volume', 'number_of_trades',
            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
        ])
        
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].copy()
        
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['symbol'] = symbol
        df['timeframe'] = timeframe
        df['exchange'] = 'Binance'
        
        return df
        
    except Exception as e:
        logging.error(f"[Binance] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} | {timeframe}: {e}")
        return pd.DataFrame()

def fetch_from_kraken(symbol: str, timeframe: str, limit: int, **kwargs) -> pd.DataFrame:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Kraken API"""
    try:
        symbol_map = {
            'BTC/USDT': 'XBTUSD', 'BTC/USD': 'XBTUSD',
            'ETH/USDT': 'ETHUSD', 'ETH/USD': 'ETHUSD',
            'XRP/USDT': 'XRPUSD', 'XRP/USD': 'XRPUSD',
            'LTC/USDT': 'LTCUSD', 'LTC/USD': 'LTCUSD',
            'ADA/USDT': 'ADAUSD', 'ADA/USD': 'ADAUSD',
            'DOT/USDT': 'DOTUSD', 'DOT/USD': 'DOTUSD',
            'SOL/USDT': 'SOLUSD', 'SOL/USD': 'SOLUSD'
        }
        
        kraken_symbol = symbol_map.get(symbol.upper(), symbol.replace('/', '').upper())
        timeframe_minutes = {
            '1m': 1, '5m': 5, '15m': 15, '30m': 30,
            '1h': 60, '4h': 240, '1d': 1440, '1w': 10080
        }
        
        interval = timeframe_minutes.get(timeframe, 60)
        end_date = datetime.now()
        days_back = min(365, limit * interval // 1440) if interval < 1440 else 365
        start_date = end_date - timedelta(days=days_back)
        
        params = {
            'pair': kraken_symbol,
            'interval': interval,
            'since': int(start_date.timestamp())
        }
        
        logging.info(f"[Kraken] Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} | {timeframe}...")
        
        response = safe_request("https://api.kraken.com/0/public/OHLC", params=params, api_name="Kraken")
        result = response.json()
        
        if 'error' in result and result['error']:
            logging.error(f"[Kraken] Ø®Ø·Ø§ÛŒ API: {result['error']}")
            return pd.DataFrame()
        
        if 'result' not in result:
            logging.warning(f"[Kraken] Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}")
            return pd.DataFrame()
        
        data_key = list(result['result'].keys())[0]
        data = result['result'][data_key]
        
        if not data:
            logging.warning(f"[Kraken] Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} | {timeframe} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return pd.DataFrame()
        
        df = pd.DataFrame(data, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'vwap', 'volume', 'count'
        ])
        
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].copy()
        
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
        df['symbol'] = symbol
        df['timeframe'] = timeframe
        df['exchange'] = 'Kraken'
        
        return df
        
    except Exception as e:
        logging.error(f"[Kraken] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} | {timeframe}: {e}")
        return pd.DataFrame()

# === Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ø§Ø¶Ø§ÙÛŒ ===

class NewsAPIFetcher:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² NewsAPI.org - 1000 Ø¯Ø±Ø®ÙˆØ§Ø³Øª/Ù…Ø§Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù†"""
    
    def __init__(self, api_key: str, rate_limiter: UnifiedRateLimiter):
        self.api_key = api_key
        self.rate_limiter = rate_limiter
        self.base_url = "https://newsapi.org/v2/everything"
        
    def fetch_crypto_news(self, symbol: str, max_news: int = 10) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯"""
        if not self.api_key:
            return []
            
        crypto_name = symbol.split('/')[0]
        
        params = {
            'q': f'{crypto_name} cryptocurrency',
            'language': 'en',
            'sortBy': 'publishedAt',
            'pageSize': min(max_news, 20),
            'apiKey': self.api_key
        }
        
        try:
            # Ø§Ø¹Ù…Ø§Ù„ rate limit
            self.rate_limiter.wait_if_needed('NewsAPI')
            
            response = safe_request(self.base_url, params=params, api_name='NewsAPI')
            data = response.json()
            
            if data.get('status') != 'ok':
                error_msg = data.get('message', 'Unknown NewsAPI error')
                logging.warning(f"NewsAPI Ø®Ø·Ø§: {error_msg}")
                return []
            
            articles = []
            for article in data.get('articles', []):
                articles.append({
                    'timestamp': article.get('publishedAt', ''),
                    'symbol': symbol,
                    'title': article.get('title', ''),
                    'content': article.get('content', ''),
                    'description': article.get('description', ''),
                    'source': article.get('source', {}).get('name', 'NewsAPI'),
                    'url': article.get('url', ''),
                    'language': 'en',
                    'image': article.get('urlToImage', ''),
                    'api_source': 'NewsAPI'
                })
            
            logging.info(f"ğŸ“° NewsAPI: {len(articles)} Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ {symbol}")
            return articles
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± NewsAPI Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return []

class CoinGeckoNewsFetcher:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² CoinGecko - Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯ (Ø¨Ø§ rate limiting Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡)"""
    
    def __init__(self, rate_limiter: UnifiedRateLimiter):
        self.rate_limiter = rate_limiter
        self.base_url = "https://api.coingecko.com/api/v3"
        
        # === Circuit breaker Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ ===
        self.consecutive_errors = 0
        self.max_consecutive_errors = 3
        self.circuit_open = False
        self.circuit_reset_time = None
        
        # Ù†Ù‚Ø´Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ù†Ù…Ø§Ø¯ Ø¨Ù‡ coin_id
        self.symbol_map = {
            'BTC': 'bitcoin', 'ETH': 'ethereum', 'BNB': 'binancecoin',
            'XRP': 'ripple', 'SOL': 'solana', 'ADA': 'cardano',
            'DOGE': 'dogecoin', 'MATIC': 'polygon', 'LTC': 'litecoin',
            'DOT': 'polkadot', 'AVAX': 'avalanche-2', 'LINK': 'chainlink',
            'BCH': 'bitcoin-cash', 'UNI': 'uniswap', 'ATOM': 'cosmos',
            'FIL': 'filecoin', 'VET': 'vechain', 'ICP': 'internet-computer',
            'TRX': 'tron', 'ETC': 'ethereum-classic', 'NEAR': 'near',
            'FTM': 'fantom', 'SAND': 'the-sandbox', 'MANA': 'decentraland',
            'SHIB': 'shiba-inu', 'OP': 'optimism', 'ARB': 'arbitrum',
            'APT': 'aptos', 'RNDR': 'render-token', 'GRT': 'the-graph'
        }
    
    def is_circuit_open(self) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ circuit breaker Ø¨Ø§Ø² Ø§Ø³Øª"""
        if not self.circuit_open:
            return False
        
        # Ø§Ú¯Ø± Û±Û° Ø¯Ù‚ÛŒÙ‚Ù‡ Ú¯Ø°Ø´ØªÙ‡ØŒ circuit Ø±Ø§ Ø±ÛŒØ³Øª Ú©Ù†
        if self.circuit_reset_time and time.time() - self.circuit_reset_time > 600:
            self.circuit_open = False
            self.consecutive_errors = 0
            self.circuit_reset_time = None
            logging.info("ğŸ”„ CoinGecko circuit breaker Ø±ÛŒØ³Øª Ø´Ø¯")
            return False
        
        return True
    
    def record_error(self):
        """Ø«Ø¨Øª Ø®Ø·Ø§ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª circuit breaker"""
        self.consecutive_errors += 1
        if self.consecutive_errors >= self.max_consecutive_errors:
            self.circuit_open = True
            self.circuit_reset_time = time.time()
            logging.warning(f"âš ï¸ CoinGecko circuit breaker ÙØ¹Ø§Ù„ Ø´Ø¯ - Û±Û° Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ù†ØªØ¸Ø§Ø±")
    
    def record_success(self):
        """Ø«Ø¨Øª Ù…ÙˆÙÙ‚ÛŒØª Ùˆ Ø±ÛŒØ³Øª Ø®Ø·Ø§Ù‡Ø§"""
        self.consecutive_errors = 0
        if self.circuit_open:
            self.circuit_open = False
            self.circuit_reset_time = None
            logging.info("âœ… CoinGecko circuit breaker Ø±ÛŒØ³Øª Ø´Ø¯")
    
    def get_coin_id(self, symbol: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ Ù†Ù…Ø§Ø¯ Ø¨Ù‡ coin_id Ú©ÙˆÛŒÙ†â€ŒÚ¯Ú©Ùˆ"""
        crypto_name = symbol.split('/')[0].upper()
        return self.symbol_map.get(crypto_name, crypto_name.lower())
    
    def fetch_crypto_news(self, symbol: str, max_news: int = 10) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯"""
        
        # Ø¨Ø±Ø±Ø³ÛŒ circuit breaker
        if self.is_circuit_open():
            logging.warning(f"ğŸš« CoinGecko circuit breaker ÙØ¹Ø§Ù„ - Ø±Ø¯ Ú©Ø±Ø¯Ù† {symbol}")
            return []
        
        try:
            # Ø§Ø¹Ù…Ø§Ù„ rate limit Ø¨Ø§ ØªØ§Ø®ÛŒØ± Ø¨ÛŒØ´ØªØ±
            self.rate_limiter.wait_if_needed('CoinGecko')
            
            # ØªØ§Ø®ÛŒØ± Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ CoinGecko (3 Ø«Ø§Ù†ÛŒÙ‡)
            time.sleep(3.0)
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² trending news (Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ø¯Ø³ØªØ±Ø³)
            url = f"{self.base_url}/news"
            response = safe_request(url, api_name='CoinGecko', max_retries=2)
            data = response.json()
            
            # Ø«Ø¨Øª Ù…ÙˆÙÙ‚ÛŒØª
            self.record_success()
            
            articles = []
            news_items = data.get('data', [])
            crypto_name = symbol.split('/')[0].lower()
            
            # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù†Ù…Ø§Ø¯
            relevant_count = 0
            for item in news_items:
                title = item.get('title', '').lower()
                description = item.get('description', '').lower()
                
                # Ø§Ú¯Ø± Ù†Ø§Ù… Ø§Ø±Ø² Ø¯Ø± Ø¹Ù†ÙˆØ§Ù† ÛŒØ§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨Ø§Ø´Ø¯ØŒ ÛŒØ§ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù… Ø¨Ø§Ø´Ø¯
                if (crypto_name in title or crypto_name in description or 
                    'crypto' in title or 'bitcoin' in title or relevant_count < 3):
                    
                    articles.append({
                        'timestamp': item.get('updated_at', ''),
                        'symbol': symbol,
                        'title': item.get('title', ''),
                        'content': item.get('description', ''),
                        'description': item.get('description', ''),
                        'source': item.get('news_site', 'CoinGecko'),
                        'url': item.get('url', ''),
                        'language': 'en',
                        'image': item.get('thumb_2x', ''),
                        'api_source': 'CoinGecko'
                    })
                    
                    relevant_count += 1
                    if relevant_count >= max_news:
                        break
            
            logging.info(f"ğŸ¦ CoinGecko: {len(articles)} Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ {symbol}")
            return articles
            
        except requests.exceptions.RequestException as e:
            # Ø«Ø¨Øª Ø®Ø·Ø§
            self.record_error()
            
            if "429" in str(e) or "Too Many Requests" in str(e):
                logging.error(f"ğŸš« CoinGecko rate limit: {symbol} - {e}")
            else:
                logging.error(f"Ø®Ø·Ø§ Ø¯Ø± CoinGecko Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return []
        except Exception as e:
            # Ø«Ø¨Øª Ø®Ø·Ø§
            self.record_error()
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± CoinGecko Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return []

class RSSNewsFetcher:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² RSS feeds - Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯"""
    
    def __init__(self, rate_limiter: UnifiedRateLimiter):
        self.rate_limiter = rate_limiter
        
        # ÙÛŒØ¯Ù‡Ø§ÛŒ RSS Ù…Ø¹ØªØ¨Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ
        self.rss_feeds = {
            'CoinDesk': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
            'CoinTelegraph': 'https://cointelegraph.com/rss',
            'Decrypt': 'https://decrypt.co/feed',
            'CryptoNews': 'https://cryptonews.com/news/feed'
        }
        
        # Ú©Ø´ Ø¨Ø±Ø§ÛŒ RSS feeds
        self._feed_cache = {}
        self._last_fetch = {}
        
    def fetch_rss_feed(self, feed_name: str, feed_url: str) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ú©Ø´ RSS feed"""
        current_time = time.time()
        
        # Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Øª Ø²Ù…Ø§Ù† ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡
        cache_seconds = RSS_CACHE_MINUTES * 60
        if (feed_name in self._last_fetch and 
            current_time - self._last_fetch[feed_name] < cache_seconds):
            return self._feed_cache.get(feed_name, [])
        
        if not RSS_AVAILABLE:
            logging.warning(f"feedparser not available. Skipping {feed_name}")
            return []
        
        try:
            # Ø§Ø¹Ù…Ø§Ù„ rate limit
            self.rate_limiter.wait_if_needed('RSS')
            
            logging.info(f"ğŸ“¡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ RSS: {feed_name}")
            feed = feedparser.parse(feed_url)
            
            articles = []
            max_articles = min(MAX_ARTICLES_PER_FEED, len(feed.entries))
            
            for entry in feed.entries[:max_articles]:
                articles.append({
                    'timestamp': entry.get('published', ''),
                    'title': entry.get('title', ''),
                    'content': entry.get('summary', ''),
                    'description': entry.get('summary', ''),
                    'source': feed_name,
                    'url': entry.get('link', ''),
                    'language': 'en',
                    'image': '',
                    'api_source': 'RSS'
                })
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
            self._feed_cache[feed_name] = articles
            self._last_fetch[feed_name] = current_time
            
            logging.info(f"ğŸ“¡ {feed_name}: {len(articles)} Ø®Ø¨Ø± Ú©Ø´ Ø´Ø¯")
            return articles
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± RSS {feed_name}: {e}")
            return []
    
    def fetch_crypto_news(self, symbol: str, max_news: int = 10) -> List[Dict]:
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø§Ø®Ø¨Ø§Ø± RSS Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ Ù…Ø´Ø®Øµ"""
        crypto_name = symbol.split('/')[0].lower()
        relevant_articles = []
        
        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø² Ù‡Ù…Ù‡ RSS feeds
        all_articles = []
        for feed_name, feed_url in self.rss_feeds.items():
            feed_articles = self.fetch_rss_feed(feed_name, feed_url)
            all_articles.extend(feed_articles)
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø·
        for article in all_articles:
            title = article.get('title', '').lower()
            content = article.get('content', '').lower()
            
            # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… Ø§Ø±Ø² ÛŒØ§ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ú©Ø±ÛŒÙ¾ØªÙˆ
            if (crypto_name in title or crypto_name in content or 
                'crypto' in title or 'bitcoin' in title or 'blockchain' in title):
                article['symbol'] = symbol
                relevant_articles.append(article)
                
                if len(relevant_articles) >= max_news:
                    break
        
        logging.info(f"ğŸ“¡ RSS: {len(relevant_articles)} Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø· Ø¨Ø±Ø§ÛŒ {symbol}")
        return relevant_articles

class MultiSourceNewsFetcher:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÙˆØ§Ø²ÛŒ Ú†Ù†Ø¯ÛŒÙ† Ù…Ù†Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ (Ø¨Ø§ timeout handling Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡)"""
    
    def __init__(self, rate_limiter: UnifiedRateLimiter):
        self.rate_limiter = rate_limiter
        self.sources = {}
        
        # Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹ ÙØ¹Ø§Ù„
        if GNEWS_ENABLED and GNEWS_API_KEY:
            # GNews Ø¨Ø§ interface Ù…ØªÙØ§ÙˆØª
            self.sources['GNews'] = 'gnews_special'
            
        if NEWSAPI_ENABLED and NEWSAPI_KEY:
            self.sources['NewsAPI'] = NewsAPIFetcher(NEWSAPI_KEY, rate_limiter)
            
        if COINGECKO_ENABLED:
            self.sources['CoinGecko'] = CoinGeckoNewsFetcher(rate_limiter)
            
        if RSS_ENABLED and RSS_AVAILABLE:
            self.sources['RSS'] = RSSNewsFetcher(rate_limiter)
        
        logging.info(f"ğŸ”— MultiSource ØªØ´Ú©ÛŒÙ„ Ø´Ø¯: {list(self.sources.keys())}")
    
    def fetch_from_single_source(self, source_name: str, fetcher, 
                                symbols: List[str], max_news: int) -> List[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² ÛŒÚ© Ù…Ù†Ø¨Ø¹ (Ø¨Ø§ timeout Ùˆ error handling Ø¨Ù‡ØªØ±)"""
        all_articles = []
        
        try:
            if source_name == 'GNews':
                # GNews Ø¨Ø§ interface Ø®Ø§Øµ
                df = fetch_crypto_news(GNEWS_API_KEY, symbols, max_news, self.rate_limiter)
                if not df.empty:
                    articles_dict = df.to_dict('records')
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† api_source
                    for article in articles_dict:
                        article['api_source'] = 'GNews'
                    all_articles = articles_dict
            else:
                # Ø³Ø§ÛŒØ± Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ø± symbol
                for i, symbol in enumerate(symbols):
                    try:
                        articles = fetcher.fetch_crypto_news(symbol, max_news)
                        all_articles.extend(articles)
                        
                        # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø­Ø¬Ù… Ø²ÛŒØ§Ø¯
                        if len(all_articles) > len(symbols) * max_news:
                            break
                            
                        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø¢Ù‡Ø³ØªÙ‡
                        if source_name == 'CoinGecko' and (i + 1) % 3 == 0:
                            logging.info(f"ğŸ¦ CoinGecko Ù¾ÛŒØ´Ø±ÙØª: {i + 1}/{len(symbols)} Ù†Ù…Ø§Ø¯")
                            
                    except Exception as symbol_error:
                        logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± {source_name} Ø¨Ø±Ø§ÛŒ {symbol}: {symbol_error}")
                        continue
            
            logging.info(f"âœ… {source_name}: {len(all_articles)} Ø®Ø¨Ø± Ú©Ù„")
            return all_articles
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± {source_name}: {e}")
            return []
    
    def fetch_parallel(self, symbols: List[str], max_news: int = 10) -> pd.DataFrame:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ø²ÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ù…Ù†Ø§Ø¨Ø¹ (Ø¨Ø§ timeout management Ø¨Ù‡ØªØ±)"""
        all_articles = []
        
        logging.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² {len(self.sources)} Ù…Ù†Ø¨Ø¹...")
        
        if PARALLEL_FETCHING and CONCURRENT_AVAILABLE and len(self.sources) > 1:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ timeout management Ø¨Ù‡ØªØ±
            with ThreadPoolExecutor(max_workers=min(4, len(self.sources))) as executor:
                # Ø§Ø±Ø³Ø§Ù„ tasks
                futures = {}
                for source_name, fetcher in self.sources.items():
                    future = executor.submit(
                        self.fetch_from_single_source, 
                        source_name, fetcher, symbols, max_news
                    )
                    futures[future] = source_name
                
                # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ timeout Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ
                completed_sources = []
                
                try:
                    # timeout Ø§ÙˆÙ„ÛŒÙ‡: 120 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø³Ø±ÛŒØ¹
                    for future in as_completed(futures, timeout=120):
                        source_name = futures[future]
                        try:
                            articles = future.result(timeout=30)  # timeout per source
                            all_articles.extend(articles)
                            completed_sources.append(source_name)
                            logging.info(f"âœ… {source_name} ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
                        except Exception as e:
                            logging.error(f"âŒ {source_name} Ù†Ø§Ù…ÙˆÙÙ‚: {e}")
                
                except Exception as timeout_error:
                    logging.warning(f"â° Timeout Ø¯Ø± parallel processing: {timeout_error}")
                    
                    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬ Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡
                    remaining_futures = [f for f in futures.keys() if futures[f] not in completed_sources]
                    
                    if remaining_futures:
                        logging.info(f"ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬ {len(remaining_futures)} Ù…Ù†Ø¨Ø¹ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡...")
                        
                        for future in remaining_futures:
                            source_name = futures[future]
                            try:
                                if future.done():
                                    articles = future.result(timeout=10)
                                    all_articles.extend(articles)
                                    logging.info(f"âœ… {source_name} (ØªØ§Ø®ÛŒØ±ÛŒ) ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
                                else:
                                    logging.warning(f"â° {source_name} Ù‡Ù…Ú†Ù†Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ - Ø±Ø¯ Ø´Ø¯")
                                    future.cancel()
                            except Exception as e:
                                logging.error(f"âŒ {source_name} (ØªØ§Ø®ÛŒØ±ÛŒ) Ù†Ø§Ù…ÙˆÙÙ‚: {e}")
        else:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙˆØ§Ù„ÛŒ
            for source_name, fetcher in self.sources.items():
                articles = self.fetch_from_single_source(source_name, fetcher, symbols, max_news)
                all_articles.extend(articles)
        
        if not all_articles:
            logging.warning("âŒ Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ø§Ø² Ù‡ÛŒÚ† Ù…Ù†Ø¨Ø¹ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return pd.DataFrame()
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
        df = pd.DataFrame(all_articles)
        
        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ timestamp
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        df = df.dropna(subset=['timestamp'])
        
        # Ø­Ø°Ù duplicates Ø¨Ø± Ø§Ø³Ø§Ø³ title
        if REMOVE_DUPLICATES:
            initial_count = len(df)
            df = df.drop_duplicates(subset=['title'], keep='first')
            final_count = len(df)
            
            if initial_count > final_count:
                logging.info(f"ğŸ§¹ Ø­Ø°Ù {initial_count - final_count} Ø®Ø¨Ø± ØªÚ©Ø±Ø§Ø±ÛŒ")
        
        # Ø§ÙØ²ÙˆØ¯Ù† sentiment_score
        analyzer = SentimentIntensityAnalyzer()
        
        def analyze_sentiment(row):
            text = f"{row.get('title', '')} {row.get('description', '')}"
            try:
                return analyzer.polarity_scores(text)['compound']
            except:
                return 0
        
        df['sentiment_score'] = df.apply(analyze_sentiment, axis=1)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ timestamp
        df = df.sort_values('timestamp', ascending=False).reset_index(drop=True)
        
        logging.info(f"ğŸ‰ Ù…Ø¬Ù…ÙˆØ¹ Ù†Ù‡Ø§ÛŒÛŒ: {len(df)} Ø®Ø¨Ø± Ù…Ù†Ø­ØµØ± Ø§Ø² {len(self.sources)} Ù…Ù†Ø¨Ø¹")
        
        # Ø¢Ù…Ø§Ø± Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ù…Ù†Ø¨Ø¹
        if 'api_source' in df.columns:
            source_stats = df['api_source'].value_counts()
            for source, count in source_stats.items():
                logging.info(f"   ğŸ“Š {source}: {count} Ø®Ø¨Ø±")
        
        return df

# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø§ØµÙ„ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± GNews) ---
def fetch_crypto_news(api_key: str, symbols: List[str], max_news: int = 10, 
                     rate_limiter: UnifiedRateLimiter = None) -> pd.DataFrame:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø§Ø² GNews API
    ØªÙˆØ¬Ù‡: ÙÙ‚Ø· Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù API
    """
    logging.info("Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø¨Ø±ÛŒ GNews (ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)...")
    all_articles = []
    base_url = "https://gnews.io/api/v4/search"
    
    total_requests = len(symbols)  # ÙÙ‚Ø· ÛŒÚ© Ø²Ø¨Ø§Ù†
    current_request = 0
    skipped_due_to_limit = 0
    
    for symbol in symbols:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ø§Ø±Ø² Ø§Ø² Ø¬ÙØª Ø§Ø±Ø²
        crypto_name = symbol.split('/')[0]
        
        current_request += 1
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù‚Ø¨Ù„ Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øª
        if rate_limiter:
            if rate_limiter.request_counters['GNews']['daily'] >= GNEWS_DAILY_LIMIT:
                skipped_due_to_limit += 1
                logging.warning(f"â­ï¸ Ø±Ø¯ Ø´Ø¯Ù† {symbol} Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡")
                continue
        
        query = f"{crypto_name} cryptocurrency"
        
        params = {
            'q': query,
            'lang': 'en',  # ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            'max': max_news,
            'apikey': api_key,
            'sortby': 'publishedAt'  # Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø±
        }
        
        try:
            logging.info(f"[{current_request}/{total_requests}] Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± GNews {symbol}...")
            
            # Ø§Ø¹Ù…Ø§Ù„ rate limit
            if rate_limiter:
                rate_limiter.wait_if_needed('GNews')
            
            response = safe_request(base_url, params=params, api_name='GNews')
            data = response.json()
            
            if 'articles' not in data:
                logging.warning(f"Ù¾Ø§Ø³Ø® ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ GNews Ø¨Ø±Ø§ÛŒ {symbol}: {data}")
                continue
            
            articles = data.get('articles', [])
            
            for article in articles:
                all_articles.append({
                    'timestamp': article.get('publishedAt', ''),
                    'symbol': symbol,
                    'title': article.get('title', ''),
                    'content': article.get('content', ''),
                    'description': article.get('description', ''),
                    'source': article.get('source', {}).get('name', ''),
                    'url': article.get('url', ''),
                    'language': 'en',
                    'image': article.get('image', '')
                })
            
            logging.info(f"âœ… GNews: ØªØ¹Ø¯Ø§Ø¯ {len(articles)} Ø®Ø¨Ø± Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
            
        except requests.exceptions.RequestException as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± GNews Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        except json.JSONDecodeError as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ JSON Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
    
    if skipped_due_to_limit > 0:
        logging.warning(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ {skipped_due_to_limit} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
    
    if not all_articles:
        logging.warning("Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ø§Ø² GNews Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return pd.DataFrame()
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
    df = pd.DataFrame(all_articles)
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df = df.dropna(subset=['timestamp'])
    
    logging.info(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ Ø§Ø®Ø¨Ø§Ø± GNews Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(df)}")
    
    return df

# --- ØªÙˆØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
def fetch_all_tradable_pairs_from_exchange(exchange_name: str, quote_currency="USDT"):
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø§Ø² ØµØ±Ø§ÙÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ"""
    if exchange_name == 'CryptoCompare':
        return fetch_all_tradable_pairs_cryptocompare(quote_currency)
    elif exchange_name == 'Binance':
        return fetch_all_tradable_pairs_binance(quote_currency)
    elif exchange_name == 'Kraken':
        return fetch_all_tradable_pairs_kraken(quote_currency)
    else:
        logging.error(f"Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø² Ø¨Ø±Ø§ÛŒ ØµØ±Ø§ÙÛŒ '{exchange_name}' Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return []

def fetch_all_tradable_pairs_cryptocompare(quote_currency="USDT"):
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø§Ø² CryptoCompare"""
    logging.info(f"[CryptoCompare] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ Ø¨Ø§ Ù…Ø±Ø¬Ø¹ {quote_currency}...")
    try:
        url = "https://min-api.cryptocompare.com/data/all/coinlist"
        params = {}
        if CRYPTOCOMPARE_API_KEY:
            params["api_key"] = CRYPTOCOMPARE_API_KEY
            
        response = safe_request(url, params=params, api_name="CryptoCompare")
        data = response.json()['Data']
        
        pairs = [f"{symbol_data['Symbol']}/{quote_currency}" for symbol, symbol_data in data.items() 
                 if symbol_data.get('IsTrading', False) and symbol.isalpha()]
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±
        valid_pairs = []
        for pair in pairs:
            if len(pair.split('/')[0]) <= 10:  # Ø­Ø°Ù Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø®ÛŒÙ„ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ
                valid_pairs.append(pair)
        
        logging.info(f"[CryptoCompare] ØªØ¹Ø¯Ø§Ø¯ {len(valid_pairs)} Ø¬ÙØª Ø§Ø±Ø² Ù…Ø¹ØªØ¨Ø± ÛŒØ§ÙØª Ø´Ø¯.")
        return valid_pairs[:100]  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ 100 Ø¬ÙØª Ø¨Ø±ØªØ±
    except Exception as e:
        logging.error(f"[CryptoCompare] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§: {e}")
        return []

def fetch_all_tradable_pairs_binance(quote_currency="USDT"):
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø§Ø² Binance"""
    logging.info(f"[Binance] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ Ø¨Ø§ Ù…Ø±Ø¬Ø¹ {quote_currency}...")
    try:
        response = safe_request("https://api.binance.com/api/v3/exchangeInfo", api_name="Binance")
        data = response.json()
        
        pairs = []
        for symbol_info in data['symbols']:
            if (symbol_info['status'] == 'TRADING' and 
                symbol_info['quoteAsset'] == quote_currency):
                pair = f"{symbol_info['baseAsset']}/{symbol_info['quoteAsset']}"
                pairs.append(pair)
        
        logging.info(f"[Binance] ØªØ¹Ø¯Ø§Ø¯ {len(pairs)} Ø¬ÙØª Ø§Ø±Ø² Ù…Ø¹ØªØ¨Ø± ÛŒØ§ÙØª Ø´Ø¯.")
        return pairs
    except Exception as e:
        logging.error(f"[Binance] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§: {e}")
        return []

def fetch_all_tradable_pairs_kraken(quote_currency="USD"):
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø§Ø² Kraken"""
    logging.info(f"[Kraken] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ Ø¨Ø§ Ù…Ø±Ø¬Ø¹ {quote_currency}...")
    try:
        response = safe_request("https://api.kraken.com/0/public/AssetPairs", api_name="Kraken")
        data = response.json()
        
        if 'error' in data and data['error']:
            logging.error(f"[Kraken] Ø®Ø·Ø§ÛŒ API: {data['error']}")
            return []
        
        pairs = []
        for pair_name, pair_info in data['result'].items():
            if quote_currency.upper() in pair_info.get('quote', '').upper():
                base = pair_info.get('base', '')
                quote = pair_info.get('quote', '')
                if base and quote:
                    pairs.append(f"{base}/{quote}")
        
        logging.info(f"[Kraken] ØªØ¹Ø¯Ø§Ø¯ {len(pairs)} Ø¬ÙØª Ø§Ø±Ø² Ù…Ø¹ØªØ¨Ø± ÛŒØ§ÙØª Ø´Ø¯.")
        return pairs
    except Exception as e:
        logging.error(f"[Kraken] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§: {e}")
        return []

# --- Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Unified Data Fetcher (Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡) ---
class UnifiedDataFetcher:
    """Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±"""
    
    def __init__(self):
        self.state_manager = UnifiedStateManager()
        self.rate_limiter = UnifiedRateLimiter(self.state_manager)
        
        self.exchange_functions = {
            'CryptoCompare': fetch_from_cryptocompare,
            'Binance': fetch_from_binance,
            'Kraken': fetch_from_kraken,
        }
        
        # Ø§ÛŒØ¬Ø§Ø¯ sentiment analyzer Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ Ø§Ø®Ø¨Ø§Ø±
        self.sentiment_analyzer = SentimentIntensityAnalyzer()
        
        logging.info("ğŸš€ Enhanced Unified Data Fetcher Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
    
    def fetch_price_data(self, symbol: str, timeframe: str, limit: int, 
                        exchange_name: str, session_id: str) -> bool:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª state"""
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡
        if self.state_manager.is_failed_item('price', symbol, exchange_name):
            logging.info(f"â­ï¸ Ø±Ø¯ Ø´Ø¯Ù† Ø¬ÙØª Ø§Ø±Ø² Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡: {symbol}")
            return True
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ù†ØªØ¸Ø§Ø± rate limit
        if not self.rate_limiter.wait_if_needed(exchange_name):
            logging.error(f"âŒ Rate limit Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ø±Ø§ÛŒ {exchange_name}")
            return False
        
        try:
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
            self.state_manager.update_price_progress(
                session_id, exchange_name, symbol, timeframe, 'processing'
            )
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡
            fetch_function = self.exchange_functions[exchange_name]
            df = fetch_function(symbol, timeframe, limit)
            
            if df.empty:
                error_msg = f"Empty data for {symbol}"
                logging.warning(f"âš ï¸ {error_msg}")
                self.state_manager.add_failed_item('price', symbol, error_msg, exchange_name)
                self.state_manager.update_price_progress(
                    session_id, exchange_name, symbol, timeframe, 'failed',
                    error_message=error_msg
                )
                return True
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡
            filename = self.save_price_data(df, exchange_name, session_id)
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
            self.state_manager.update_price_progress(
                session_id, exchange_name, symbol, timeframe, 'completed',
                file_path=filename, records_count=len(df)
            )
            
            logging.info(f"âœ… Ù‚ÛŒÙ…Øª Ù…ÙˆÙÙ‚: {symbol}|{timeframe} - {len(df)} Ø³Ø·Ø±")
            return True
            
        except Exception as e:
            error_msg = f"Exception: {str(e)}"
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± {symbol}|{timeframe}: {error_msg}")
            
            # Ø§Ú¯Ø± Ø®Ø·Ø§ÛŒ API Ø§Ø³ØªØŒ Ø¨Ù‡ failed items Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if any(x in str(e).lower() for x in ['market does not exist', 'unknown asset pair', 'invalid symbol']):
                self.state_manager.add_failed_item('price', symbol, error_msg, exchange_name)
            
            self.state_manager.update_price_progress(
                session_id, exchange_name, symbol, timeframe, 'failed',
                error_message=error_msg
            )
            
            return True
    
    def fetch_news_data(self, symbols: List[str], max_news: int, session_id: str) -> bool:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª state - Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
        
        logging.info("\n--- Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ ---")
        logging.info(f"ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§: {len(symbols)}")
        logging.info(f"ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯: {max_news}")
        
        # Ø§ÛŒØ¬Ø§Ø¯ multi-source fetcher
        multi_fetcher = MultiSourceNewsFetcher(self.rate_limiter)
        
        if not multi_fetcher.sources:
            logging.error("âŒ Ù‡ÛŒÚ† Ù…Ù†Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ ÙØ¹Ø§Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return False
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ø²ÛŒ/Ù…ØªÙˆØ§Ù„ÛŒ
        df_news = multi_fetcher.fetch_parallel(symbols, max_news)
        
        if df_news.empty:
            logging.warning("âŒ Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return False
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù…Ø§Ø¯ (Ù…Ø´Ø§Ø¨Ù‡ Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ)
        for symbol, group in df_news.groupby('symbol'):
            try:
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª
                self.state_manager.update_news_progress(
                    session_id, symbol, 'en', 'processing'
                )
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡
                filename = self.save_news_data(group, symbol, 'en', session_id)
                
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
                self.state_manager.update_news_progress(
                    session_id, symbol, 'en', 'completed',
                    file_path=filename, news_count=len(group)
                )
                
                logging.info(f"âœ… Ø§Ø®Ø¨Ø§Ø± Ù…ÙˆÙÙ‚: {symbol} - {len(group)} Ø®Ø¨Ø±")
                
            except Exception as e:
                error_msg = f"Error saving news for {symbol}: {str(e)}"
                logging.error(error_msg)
                self.state_manager.update_news_progress(
                    session_id, symbol, 'en', 'failed',
                    error_message=error_msg
                )
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        if 'api_source' in df_news.columns:
            total_by_source = df_news['api_source'].value_counts()
            logging.info("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ:")
            for source, count in total_by_source.items():
                logging.info(f"   {source}: {count} Ø®Ø¨Ø±")
        
        return True
    
    def analyze_sentiment(self, text: str) -> float:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…ØªÙ†"""
        try:
            if not text or not isinstance(text, str):
                return 0
            scores = self.sentiment_analyzer.polarity_scores(text)
            return scores['compound']
        except Exception:
            return 0
    
    def save_price_data(self, df: pd.DataFrame, exchange_name: str, session_id: str) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª"""
        if df.empty:
            return ""
        
        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        required_columns = ['timestamp', 'symbol', 'timeframe', 'exchange', 'open', 'high', 'low', 'close', 'volume']
        df_final = df[required_columns].copy()
        
        # Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„
        symbol = df_final['symbol'].iloc[0]
        timeframe = df_final['timeframe'].iloc[0]
        
        symbol_sanitized = symbol.replace('/', '-')
        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{exchange_name}_{symbol_sanitized}_{timeframe}_{timestamp_str}.csv"
        output_path = os.path.join(RAW_DATA_PATH, filename)        
        # Ø°Ø®ÛŒØ±Ù‡
        df_final.to_csv(output_path, index=False, float_format='%.8f')
        
        return filename
    
    def save_news_data(self, df: pd.DataFrame, symbol: str, language: str, session_id: str) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø®Ø¨Ø§Ø±"""
        if df.empty:
            return ""
        
        # Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„
        symbol_sanitized = symbol.replace('/', '-')
        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"news_{symbol_sanitized}_{language}_{timestamp_str}.csv"
        output_path = os.path.join(RAW_DATA_PATH, filename)        
        # Ø°Ø®ÛŒØ±Ù‡
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        return filename
    
    def run_price_extraction(self, exchange_name: str, symbols: List[str], 
                           timeframes: List[str], session_id: str) -> int:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§"""
        success_count = 0
        
        logging.info(f"\n--- Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ø§Ø² {exchange_name} ---")
        logging.info(f"ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§: {len(symbols)}")
        logging.info(f"ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§: {', '.join(timeframes)}")
        
        for symbol in symbols:
            for timeframe in timeframes:
                success = self.fetch_price_data(
                    symbol, timeframe, LIMIT, exchange_name, session_id
                )
                if success:
                    success_count += 1
                
                # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
                stats = self.rate_limiter.get_stats(exchange_name)
                if stats:
                    logging.info(f"ğŸ“Š Ø¢Ù…Ø§Ø± {exchange_name}: {stats}")
        
        return success_count
    
    def run_news_extraction(self, symbols: List[str], max_news: int, session_id: str) -> bool:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
        success = self.fetch_news_data(symbols, max_news, session_id)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± ØªÙ…Ø§Ù… Ù…Ù†Ø§Ø¨Ø¹
        for source_name in ['GNews', 'NewsAPI', 'CoinGecko', 'RSS']:
            stats = self.rate_limiter.get_stats(source_name)
            if stats:
                logging.info(f"ğŸ“Š Ø¢Ù…Ø§Ø± {source_name}: {stats}")
        
        return success

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ UI (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
def get_user_selection(options: list, title: str, allow_manual=False, allow_multi=False, allow_all=False):
    """Ù…Ù†ÙˆÛŒ Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
    print(f"\n--- {title} ---")
    for i, option in enumerate(options, 1):
        print(f"{i}. {option}")
    
    if allow_all: 
        print(f"{len(options)+1}. Ù‡Ù…Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø¨Ø§Ù„Ø§")
    if allow_manual: 
        print(f"{len(options)+2 if allow_all else len(options)+1}. ÙˆØ±ÙˆØ¯ Ø¯Ø³ØªÛŒ")
    
    if allow_multi:
        prompt = "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯): "
    else:
        prompt = "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±: "
    
    choice_str = input(prompt).strip()
    
    if not choice_str:
        logging.error("ÙˆØ±ÙˆØ¯ÛŒ Ø®Ø§Ù„ÛŒ.")
        return []
    
    try:
        if allow_all and choice_str == str(len(options)+1):
            return options
            
        manual_entry_num = len(options)+2 if allow_all else len(options)+1
        if allow_manual and choice_str == str(manual_entry_num):
            manual_input = input("Ù„Ø·ÙØ§Ù‹ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯ (Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯ Ù…ÙˆØ±Ø¯ØŒ Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯): ").upper()
            return [item.strip() for item in manual_input.split(',')]
        
        if allow_multi:
            selected_indices = [int(i.strip()) - 1 for i in choice_str.split(',')]
            return [options[i] for i in selected_indices if 0 <= i < len(options)]
        else:
            idx = int(choice_str) - 1
            if 0 <= idx < len(options):
                return [options[idx]]
                
    except (ValueError, IndexError):
        logging.error("ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±.")
    
    return []

def get_exchange_selection():
    """Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø±"""
    exchanges = ['Binance', 'CryptoCompare', 'Kraken']
    
    print("\nğŸ¦ Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ:")
    print("ğŸ’¡ ØªÙˆØµÛŒÙ‡: Binance Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ùˆ Ø¹Ø¯Ù… Ù…Ø­Ø¯ÙˆØ¯ÛŒØª")
    
    exchange_list = get_user_selection(exchanges, "Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ", allow_multi=False)
    return exchange_list[0] if exchange_list else None

# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ú©Ø§Ù…Ù„) ---
def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ù…Ù†Ùˆ Ù…Ø­ÙˆØ± - Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ fetch_historical_data_01.py Ø§ØµÙ„ÛŒ"""
    logging.info("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Enhanced Unified Data Fetcher")
    
    # Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ
    fetcher = UnifiedDataFetcher()
    
    # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    print("\n" + "="*80)
    print("ğŸ” ØªÙ†Ø¸ÛŒÙ…Ø§Øª Enhanced Unified Data Fetcher:")
    print(f"ğŸ“Š CryptoCompare: Ø­Ø¯Ø§Ú©Ø«Ø± {DAILY_LIMIT}/Ø±ÙˆØ²ØŒ {HOURLY_LIMIT}/Ø³Ø§Ø¹Øª")
    print(f"ğŸ“° GNews: Ø­Ø¯Ø§Ú©Ø«Ø± {GNEWS_DAILY_LIMIT}/Ø±ÙˆØ²ØŒ {GNEWS_HOURLY_LIMIT}/Ø³Ø§Ø¹Øª")
    
    # === Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ ===
    print("=== Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ø¬Ø¯ÛŒØ¯ ===")
    if NEWSAPI_ENABLED and NEWSAPI_KEY:
        print(f"ğŸ“° NewsAPI: Ø­Ø¯Ø§Ú©Ø«Ø± {NEWSAPI_DAILY_LIMIT}/Ø±ÙˆØ² - ÙØ¹Ø§Ù„")
    else:
        print("ğŸ“° NewsAPI: ØºÛŒØ±ÙØ¹Ø§Ù„")
        
    if COINGECKO_ENABLED:
        print("ğŸ¦ CoinGecko: Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯ - ÙØ¹Ø§Ù„")
    else:
        print("ğŸ¦ CoinGecko: ØºÛŒØ±ÙØ¹Ø§Ù„")
        
    if RSS_ENABLED and RSS_AVAILABLE:
        print("ğŸ“¡ RSS Feeds: Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯ - ÙØ¹Ø§Ù„")
    else:
        print("ğŸ“¡ RSS Feeds: ØºÛŒØ±ÙØ¹Ø§Ù„")
    
    print(f"âš¡ Binance: Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØªØŒ delay {BINANCE_DELAY}s")
    print(f"ğŸ”„ Kraken: delay {KRAKEN_DELAY}s")
    print("ğŸ’¾ State Management: ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±")
    print("ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ: " + ("ÙØ¹Ø§Ù„" if PARALLEL_FETCHING and CONCURRENT_AVAILABLE else "ØºÛŒØ±ÙØ¹Ø§Ù„"))
    print("="*80)
    
    # Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡
    while True:
        print("\n" + "="*80)
        print("   Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ Enhanced Unified Data Fetcher")
        print("="*80)
        print("1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÙØ§Ø±Ø´ÛŒ (Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø² Ù„ÛŒØ³Øª)")
        print("2. Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ (Production Mode)")
        print("3. ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ (Backfill)")
        print("4. Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ùˆ ÙˆØ¶Ø¹ÛŒØª")
        print("5. Ù…Ø¯ÛŒØ±ÛŒØª State (Database)")
        print("6. Ø®Ø±ÙˆØ¬")
        
        main_choice = input("\nÙ„Ø·ÙØ§Ù‹ Ø´Ù…Ø§Ø±Ù‡ Ø¹Ù…Ù„ÛŒØ§Øª Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ")
        
        if main_choice == '1':
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÙØ§Ø±Ø´ÛŒ
            print("\nğŸ¯ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬:")
            print("1. ÙÙ‚Ø· Ù‚ÛŒÙ…Øª")
            print("2. ÙÙ‚Ø· Ø§Ø®Ø¨Ø§Ø±")
            print("3. Ù‡Ø± Ø¯Ùˆ (Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±)")
            
            data_type = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
            
            include_price = data_type in ['1', '3']
            include_news = data_type in ['2', '3']
            
            # Ø§Ú¯Ø± Ø§Ø®Ø¨Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ØŒ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø¨Ø± Ø±Ø§ Ø¨Ù¾Ø±Ø³
            max_news = 10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            if include_news:
                print("\nğŸ“° ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯:")
                print("1. 5 Ø®Ø¨Ø±")
                print("2. 10 Ø®Ø¨Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)")
                print("3. 20 Ø®Ø¨Ø±")
                
                news_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
                news_counts = {'1': 5, '2': 10, '3': 20}
                max_news = news_counts.get(news_choice, 10)
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù…Ø§Ø¯Ù‡Ø§
            pairs = get_user_selection(COMMON_PAIRS, "Ø§Ù†ØªØ®Ø§Ø¨ Ø¬ÙØª Ø§Ø±Ø²", 
                                     allow_manual=True, allow_multi=True, allow_all=True)
            if not pairs:
                input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                continue
            
            # Ø§ÛŒØ¬Ø§Ø¯ session
            session_id = fetcher.state_manager.create_unified_session(
                pairs, include_price, include_news
            )
            
            if include_price:
                # Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ
                exchange = get_exchange_selection()
                if not exchange:
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§Ù†ØªØ®Ø§Ø¨ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…
                timeframes = get_user_selection(COMMON_TIMEFRAMES, "Ø§Ù†ØªØ®Ø§Ø¨ ØªØ§ÛŒÙ… ÙØ±ÛŒÙ…", 
                                              allow_multi=True, allow_all=True)
                if not timeframes:
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª
                success_count = fetcher.run_price_extraction(
                    exchange, pairs, timeframes, session_id
                )
                
                logging.info(f"âœ… Ù‚ÛŒÙ…Øª: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
            
            if include_news:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡
                success = fetcher.run_news_extraction(pairs, max_news, session_id)
                
                if success:
                    logging.info("âœ… Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆÙÙ‚")
            
            # Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ù†Ù‡Ø§ÛŒÛŒ
            final_status = fetcher.state_manager.get_session_status(session_id)
            
            logging.info("\nâœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
            logging.info(f"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
            if include_price:
                logging.info(f"   Ù‚ÛŒÙ…Øª: {final_status['price_progress']['completed']}/{final_status['price_progress']['total']}")
            if include_news:
                logging.info(f"   Ø§Ø®Ø¨Ø§Ø±: {final_status['news_progress']['completed']}/{final_status['news_progress']['total']}")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ...")

        elif main_choice == '2':
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§
            print("\nğŸš¨ Ø­Ø§Ù„Øª Production - Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§")
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡
            print("\nğŸ¯ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬:")
            print("1. ÙÙ‚Ø· Ù‚ÛŒÙ…Øª")
            print("2. ÙÙ‚Ø· Ø§Ø®Ø¨Ø§Ø±")
            print("3. Ù‡Ø± Ø¯Ùˆ (Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±)")
            
            data_type = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
            
            include_price = data_type in ['1', '3']
            include_news = data_type in ['2', '3']
            
            # Ø§Ú¯Ø± Ø§Ø®Ø¨Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ØŒ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø¨Ø± Ø±Ø§ Ø¨Ù¾Ø±Ø³
            max_news = 10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            if include_news:
                print("\nğŸ“° ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯:")
                print("1. 5 Ø®Ø¨Ø±")
                print("2. 10 Ø®Ø¨Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)")
                print("3. 20 Ø®Ø¨Ø±")
                
                news_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
                news_counts = {'1': 5, '2': 10, '3': 20}
                max_news = news_counts.get(news_choice, 10)
            
            # Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ
            exchange = get_exchange_selection()
            if not exchange:
                input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                continue
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§
            quote_currency = "USDT" if exchange != 'Kraken' else "USD"
            all_pairs = fetch_all_tradable_pairs_from_exchange(exchange, quote_currency)
            
            if not all_pairs:
                logging.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§")
                input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                continue
            
            print(f"\nâœ… ØªØ¹Ø¯Ø§Ø¯ {len(all_pairs)} Ø¬ÙØª Ø§Ø±Ø² ÛŒØ§ÙØª Ø´Ø¯")
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ
            if include_price:
                price_requests = len(all_pairs) * len(COMMON_TIMEFRAMES)
                print(f"ğŸ“Š ØªØ®Ù…ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª: {price_requests}")
            
            if include_news:
                news_requests = len(all_pairs)
                remaining_daily = max(0, GNEWS_DAILY_LIMIT - fetcher.rate_limiter.request_counters['GNews']['daily'])
                print(f"ğŸ“° ØªØ®Ù…ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø±: {news_requests}")
                print(f"ğŸ“° Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡ GNews: {remaining_daily}")
                
                # Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ ÙØ¹Ø§Ù„
                active_sources = []
                if GNEWS_ENABLED and GNEWS_API_KEY:
                    active_sources.append("GNews")
                if NEWSAPI_ENABLED and NEWSAPI_KEY:
                    active_sources.append("NewsAPI")
                if COINGECKO_ENABLED:
                    active_sources.append("CoinGecko")
                if RSS_ENABLED and RSS_AVAILABLE:
                    active_sources.append("RSS")
                
                print(f"ğŸ“¡ Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ ÙØ¹Ø§Ù„: {', '.join(active_sources)}")
            
            confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯ØŸ (y/n): ")
            if confirm.lower() != 'y':
                input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                continue
            
            # Ø§ÛŒØ¬Ø§Ø¯ session
            session_id = fetcher.state_manager.create_unified_session(
                all_pairs, include_price, include_news
            )
            
            if include_price:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
                success_count = fetcher.run_price_extraction(
                    exchange, all_pairs, COMMON_TIMEFRAMES, session_id
                )
                logging.info(f"âœ… Ù‚ÛŒÙ…Øª: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
            
            if include_news:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡
                success = fetcher.run_news_extraction(all_pairs, max_news, session_id)
                if success:
                    logging.info("âœ… Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆÙÙ‚")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ...")
        
        elif main_choice == '3':
            # ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ (Backfill)
            print("\nğŸ”„ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ (Backfill)")
            print("="*50)
            print("1. ØªÚ©Ù…ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
            print("2. ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
            print("3. ØªÚ©Ù…ÛŒÙ„ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡")
            print("4. ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯")
            print("5. Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ")
            
            backfill_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
            
            if backfill_choice == '1':
                # ØªÚ©Ù…ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                print("\nğŸ“Š ØªÚ©Ù…ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                price_files = [f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')]
                
                if not price_files:
                    print("âŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù‚ÛŒÙ…Øª Ù…ÙˆØ¬ÙˆØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                existing_combinations = set()
                symbols_found = set()
                
                for filename in price_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 3:
                            exchange = parts[0]
                            symbol = parts[1].replace('-', '/')
                            timeframe = parts[2]
                            existing_combinations.add((exchange, symbol, timeframe))
                            symbols_found.add(symbol)
                    except:
                        continue
                
                print(f"âœ… ÛŒØ§ÙØª Ø´Ø¯: {len(symbols_found)} Ù†Ù…Ø§Ø¯ Ø¯Ø± {len(existing_combinations)} ØªØ±Ú©ÛŒØ¨")
                
                # Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ
                exchange = get_exchange_selection()
                if not exchange:
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                missing_combinations = []
                for symbol in symbols_found:
                    for timeframe in COMMON_TIMEFRAMES:
                        if (exchange, symbol, timeframe) not in existing_combinations:
                            missing_combinations.append((symbol, timeframe))
                
                if not missing_combinations:
                    print("âœ… Ù‡Ù…Ù‡ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ú©Ø§Ù…Ù„ Ø§Ø³Øª")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(missing_combinations)} ØªØ±Ú©ÛŒØ¨ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡ ÛŒØ§ÙØª Ø´Ø¯")
                
                # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡
                print("\nÙ†Ù…ÙˆÙ†Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡:")
                for i, (symbol, timeframe) in enumerate(missing_combinations[:10]):
                    print(f"  - {symbol} | {timeframe}")
                if len(missing_combinations) > 10:
                    print(f"  ... Ùˆ {len(missing_combinations) - 10} Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±")
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§ÛŒØ¬Ø§Ø¯ session Ø¨Ø±Ø§ÛŒ backfill
                unique_symbols = list(set([combo[0] for combo in missing_combinations]))
                session_id = fetcher.state_manager.create_unified_session(unique_symbols, True, False)
                
                # Ø§Ø¬Ø±Ø§ÛŒ backfill
                success_count = 0
                total_items = len(missing_combinations)
                
                for i, (symbol, timeframe) in enumerate(missing_combinations):
                    success = fetcher.fetch_price_data(symbol, timeframe, LIMIT, exchange, session_id)
                    if success:
                        success_count += 1
                    
                    # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
                    progress = ((i + 1) / total_items) * 100
                    print(f"âš¡ Ù¾ÛŒØ´Ø±ÙØª: {progress:.1f}% ({i + 1}/{total_items}) - Ù…ÙˆÙÙ‚: {success_count}")
                
                print(f"\nâœ… Backfill ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯: {success_count} Ù…ÙˆØ±Ø¯ Ù…ÙˆÙÙ‚ Ø§Ø² {total_items}")
                
            elif backfill_choice == '2':
                # ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                print("\nğŸ’° ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                price_files = [f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')]
                existing_symbols = set()
                
                for filename in price_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 2:
                            symbol = parts[1].replace('-', '/')
                            existing_symbols.add(symbol)
                    except:
                        continue
                
                # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                missing_symbols = []
                for symbol in COMMON_PAIRS:
                    if symbol not in existing_symbols:
                        missing_symbols.append(symbol)
                
                if not missing_symbols:
                    print("âœ… Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(missing_symbols)} Ù†Ù…Ø§Ø¯ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡:")
                for symbol in missing_symbols:
                    print(f"  - {symbol}")
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§ÛŒÙ† Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ
                exchange = get_exchange_selection()
                if not exchange:
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§ÛŒØ¬Ø§Ø¯ session
                session_id = fetcher.state_manager.create_unified_session(missing_symbols, True, False)
                
                # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬
                success_count = fetcher.run_price_extraction(exchange, missing_symbols, COMMON_TIMEFRAMES, session_id)
                print(f"\nâœ… ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
                
            elif backfill_choice == '3':
                # ØªÚ©Ù…ÛŒÙ„ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡
                print("\nğŸ”„ ØªÚ©Ù…ÛŒÙ„ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    cursor = conn.execute('''
                        SELECT item_type, exchange, symbol, error_message 
                        FROM failed_items 
                        WHERE item_type = 'price'
                        ORDER BY created_at DESC
                    ''')
                    failed_items = cursor.fetchall()
                
                if not failed_items:
                    print("âœ… Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(failed_items)} Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡:")
                for item in failed_items[:10]:
                    print(f"  - {item[2]} ({item[1]}) | {item[3][:50]}...")
                
                if len(failed_items) > 10:
                    print(f"  ... Ùˆ {len(failed_items) - 10} Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±")
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† failed items Ø¨Ø±Ø§ÛŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    conn.execute("DELETE FROM failed_items WHERE item_type = 'price'")
                
                print("ğŸ§¹ Ù„ÛŒØ³Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡ Ù¾Ø§Ú© Ø´Ø¯")
                
                # ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯
                failed_symbols = list(set([item[2] for item in failed_items]))
                session_id = fetcher.state_manager.create_unified_session(failed_symbols, True, False)
                
                # Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ (Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªØºÛŒÛŒØ± ØµØ±Ø§ÙÛŒ Ú©Ù…Ú© Ú©Ù†Ø¯)
                exchange = get_exchange_selection()
                if not exchange:
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                success_count = fetcher.run_price_extraction(exchange, failed_symbols, COMMON_TIMEFRAMES, session_id)
                print(f"\nâœ… ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
                
            elif backfill_choice == '4':
                # ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                print("\nğŸ“° ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª
                price_files = [f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')]
                symbols_with_price = set()
                
                for filename in price_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 2:
                            symbol = parts[1].replace('-', '/')
                            symbols_with_price.add(symbol)
                    except:
                        continue
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø®Ø¨Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯
                news_files = [f for f in os.listdir(RAW_DATA_PATH) if f.startswith('news_') and f.endswith('.csv')]
                symbols_with_news = set()
                
                for filename in news_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 2:
                            symbol = parts[1].replace('-', '/')
                            symbols_with_news.add(symbol)
                    except:
                        continue
                
                # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‚ÛŒÙ…Øª Ø¯Ø§Ø±Ù†Ø¯ ÙˆÙ„ÛŒ Ø§Ø®Ø¨Ø§Ø± Ù†Ø¯Ø§Ø±Ù†Ø¯
                symbols_need_news = symbols_with_price - symbols_with_news
                
                if not symbols_need_news:
                    print("âœ… Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø®Ø¨Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(symbols_need_news)} Ù†Ù…Ø§Ø¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø®Ø¨Ø§Ø±:")
                symbols_list = list(symbols_need_news)
                for symbol in symbols_list[:10]:
                    print(f"  - {symbol}")
                if len(symbols_need_news) > 10:
                    print(f"  ... Ùˆ {len(symbols_need_news) - 10} Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±")
                
                # Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø±
                print("\nğŸ“° ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯:")
                print("1. 5 Ø®Ø¨Ø±")
                print("2. 10 Ø®Ø¨Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)")
                print("3. 20 Ø®Ø¨Ø±")
                
                news_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
                news_counts = {'1': 5, '2': 10, '3': 20}
                max_news = news_counts.get(news_choice, 10)
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª GNews
                remaining_daily = max(0, GNEWS_DAILY_LIMIT - fetcher.rate_limiter.request_counters['GNews']['daily'])
                
                if len(symbols_need_news) > remaining_daily:
                    print(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ ({len(symbols_need_news)}) Ø¨ÛŒØ´ØªØ± Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ ({remaining_daily}) Ø§Ø³Øª")
                    symbols_list = symbols_list[:remaining_daily]
                    print(f"ğŸ“Š Ù…Ø­Ø¯ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ù‡ {len(symbols_list)} Ù†Ù…Ø§Ø¯ Ø§ÙˆÙ„")
                else:
                    symbols_list = list(symbols_need_news)
                
                # Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ ÙØ¹Ø§Ù„
                active_sources = []
                if GNEWS_ENABLED and GNEWS_API_KEY:
                    active_sources.append("GNews")
                if NEWSAPI_ENABLED and NEWSAPI_KEY:
                    active_sources.append("NewsAPI")
                if COINGECKO_ENABLED:
                    active_sources.append("CoinGecko")
                if RSS_ENABLED and RSS_AVAILABLE:
                    active_sources.append("RSS")
                
                print(f"ğŸ“¡ Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ ÙØ¹Ø§Ù„: {', '.join(active_sources)}")
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø®Ø¨Ø§Ø± Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§ÛŒØ¬Ø§Ø¯ session Ø¨Ø±Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø±
                session_id = fetcher.state_manager.create_unified_session(symbols_list, False, True)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡
                success = fetcher.run_news_extraction(symbols_list, max_news, session_id)
                
                if success:
                    print("âœ… ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡ Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
                else:
                    print("âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø±")
                    
            elif backfill_choice == '5':
                pass  # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ
            else:
                print("Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±.")
                
            if backfill_choice != '5':
                input("\nEnter Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ...")
        
        elif main_choice == '4':
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
            print("\nğŸ“Š Ø¢Ù…Ø§Ø± ÙˆØ¶Ø¹ÛŒØª:")
            
            # Ø¢Ù…Ø§Ø± Ù…Ù†Ø§Ø¨Ø¹ Ù‚ÛŒÙ…Øª
            for api_name in ['CryptoCompare', 'Binance', 'Kraken']:
                stats = fetcher.rate_limiter.get_stats(api_name)
                if stats:
                    print(f"\nğŸ”‘ {api_name}:")
                    for key, value in stats.items():
                        print(f"   {key}: {value}")
            
            # Ø¢Ù…Ø§Ø± Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ
            print("\nğŸ“° Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ:")
            for api_name in ['GNews', 'NewsAPI', 'CoinGecko', 'RSS']:
                stats = fetcher.rate_limiter.get_stats(api_name)
                if stats:
                    print(f"\nğŸ“¡ {api_name}:")
                    for key, value in stats.items():
                        print(f"   {key}: {value}")
                else:
                    # Ù†Ù…Ø§ÛŒØ´ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ø§Ù„/ØºÛŒØ±ÙØ¹Ø§Ù„
                    status = "ØºÛŒØ±ÙØ¹Ø§Ù„"
                    if api_name == 'GNews' and GNEWS_ENABLED and GNEWS_API_KEY:
                        status = "ÙØ¹Ø§Ù„"
                    elif api_name == 'NewsAPI' and NEWSAPI_ENABLED and NEWSAPI_KEY:
                        status = "ÙØ¹Ø§Ù„"
                    elif api_name == 'CoinGecko' and COINGECKO_ENABLED:
                        status = "ÙØ¹Ø§Ù„"
                    elif api_name == 'RSS' and RSS_ENABLED and RSS_AVAILABLE:
                        status = "ÙØ¹Ø§Ù„"
                    print(f"\nğŸ“¡ {api_name}: {status}")
            
            # Ø¢Ù…Ø§Ø± database
            with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                cursor = conn.execute('SELECT COUNT(*) FROM price_progress WHERE status = "completed"')
                price_completed = cursor.fetchone()[0]
                
                cursor = conn.execute('SELECT COUNT(*) FROM news_progress WHERE status = "completed"')
                news_completed = cursor.fetchone()[0]
                
                cursor = conn.execute('SELECT COUNT(*) FROM failed_items')
                failed_count = cursor.fetchone()[0]
                
                # Ø¢Ù…Ø§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
                price_files = len([f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')])
                news_files = len([f for f in os.listdir(RAW_DATA_PATH) if f.startswith('news_') and f.endswith('.csv')])
                
                print(f"\nğŸ’¾ Ø¢Ù…Ø§Ø± Database:")
                print(f"   âœ… Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {price_completed}")
                print(f"   âœ… Ø§Ø®Ø¨Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {news_completed}")
                print(f"   âŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡: {failed_count}")
                
                print(f"\nğŸ“ Ø¢Ù…Ø§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§:")
                print(f"   ğŸ“Š ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª: {price_files}")
                print(f"   ğŸ“° ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø±: {news_files}")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
            
        elif main_choice == '5':
            # Ù…Ø¯ÛŒØ±ÛŒØª State
            print("\nğŸ’¾ Ù…Ø¯ÛŒØ±ÛŒØª State Database:")
            print("1. Ù†Ù…Ø§ÛŒØ´ Sessions ÙØ¹Ø§Ù„")
            print("2. Ù†Ù…Ø§ÛŒØ´ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡")
            print("3. Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Database")
            print("4. Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª Session")
            print("5. Ø¨Ø§Ø²Ú¯Ø´Øª")
            
            state_choice = input("Ø§Ù†ØªØ®Ø§Ø¨: ")
            
            if state_choice == '1':
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    cursor = conn.execute('''
                        SELECT session_id, session_type, status, total_symbols, completed_symbols, created_at
                        FROM extraction_sessions ORDER BY created_at DESC LIMIT 10
                    ''')
                    
                    print("\nğŸ“‹ Sessions Ø§Ø®ÛŒØ±:")
                    sessions = cursor.fetchall()
                    if sessions:
                        for row in sessions:
                            print(f"   {row[0]} | {row[1]} | {row[2]} | {row[4]}/{row[3]} | {row[5]}")
                    else:
                        print("   Ù‡ÛŒÚ† sessionâ€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            elif state_choice == '2':
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    cursor = conn.execute('''
                        SELECT item_type, exchange, symbol, error_message 
                        FROM failed_items ORDER BY created_at DESC LIMIT 20
                    ''')
                    
                    print("\nâŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡:")
                    failed_items = cursor.fetchall()
                    if failed_items:
                        for row in failed_items:
                            print(f"   {row[0]} | {row[1]} | {row[2]} | {row[3][:50]}...")
                    else:
                        print("   Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            elif state_choice == '3':
                confirm = input("âš ï¸ Ø¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ø¨Ù‡ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Database Ù‡Ø³ØªÛŒØ¯ØŸ (yes/no): ")
                if confirm == 'yes':
                    with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                        conn.executescript('''
                            DELETE FROM extraction_sessions;
                            DELETE FROM price_progress;
                            DELETE FROM news_progress;
                            DELETE FROM rate_limits;
                            DELETE FROM failed_items;
                        ''')
                    print("âœ… Database Ù¾Ø§Ú© Ø´Ø¯")
                    logging.info("âœ… Database Ù¾Ø§Ú© Ø´Ø¯")
            
            elif state_choice == '4':
                # Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª Session
                session_id = input("Session ID Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ").strip()
                if session_id:
                    status = fetcher.state_manager.get_session_status(session_id)
                    if status:
                        print(f"\nğŸ“Š Ø¬Ø²Ø¦ÛŒØ§Øª Session: {session_id}")
                        print(f"   Ù†ÙˆØ¹: {status['session_type']}")
                        print(f"   ÙˆØ¶Ø¹ÛŒØª: {status['status']}")
                        print(f"   Ú©Ù„ Ù†Ù…Ø§Ø¯Ù‡Ø§: {status['total_symbols']}")
                        print(f"   Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {status['completed_symbols']}")
                        print(f"   Ù‚ÛŒÙ…Øª: {status['price_progress']['completed']}/{status['price_progress']['total']}")
                        print(f"   Ø§Ø®Ø¨Ø§Ø±: {status['news_progress']['completed']}/{status['news_progress']['total']}")
                    else:
                        print("âŒ Session ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            if state_choice != '5':
                input("\nEnter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
        
        elif main_choice == '6':
            print("\nğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸! Enhanced Unified Data Fetcher Ø¨Ø³ØªÙ‡ Ø´Ø¯.")
            logging.info("--- Enhanced Unified Data Fetcher Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯ ---")
            break
        else:
            print("\nâŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±. Ù„Ø·ÙØ§Ù‹ Ø´Ù…Ø§Ø±Ù‡â€ŒØ§ÛŒ Ø¨ÛŒÙ† 1 ØªØ§ 6 ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
            input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")

if __name__ == '__main__':
    main()