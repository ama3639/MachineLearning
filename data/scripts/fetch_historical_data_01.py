#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø± (ÙÙ‚Ø· Binance + GNews)

ğŸ”§ ØªØºÛŒÛŒØ±Ø§Øª Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡:
- âœ… Ø­Ø°Ù Ù‡Ù…Ù‡ Ù…Ù†Ø§Ø¨Ø¹ ØºÛŒØ± Ø§Ø² Binance Ùˆ GNews
- âœ… Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø¯ Ø¨Ø§ Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ø§ØµÙ„ÛŒ
- âœ… Ø­ÙØ¸ Ù…Ù†ÙˆÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ú©Ø§Ù…Ù„
- âœ… Ø­ÙØ¸ State Management ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡
- âœ… Ø­ÙØ¸ Rate Limiting

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² fetch_historical_data_01.py Ø§Ø³Øª
Ú©Ù‡ ÙÙ‚Ø· Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Binance (Ù‚ÛŒÙ…Øª) Ùˆ GNews (Ø§Ø®Ø¨Ø§Ø±) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
- State Management ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù…Ø§Ø¯ Ùˆ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ
- Ù…Ø¯ÛŒØ±ÛŒØª Rate Limit Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡
- Ù…Ù†ÙˆÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ú©Ø§Ù…Ù„
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¯Ø± Ù‡Ù…Ù‡ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
- Ø§Ø®Ø¨Ø§Ø± ÙÙ‚Ø· Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
- Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ ÙØ¹Ø§Ù„
- Backfill Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
"""

import os
import time
import pandas as pd
import requests
import logging
import configparser
from datetime import datetime, timezone, timedelta
import threading
import json
import sqlite3
from typing import Dict, List, Optional, Tuple
import threading
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# --- Ø¨Ø®Ø´ Ø®ÙˆØ§Ù†Ø¯Ù† Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ---
config = configparser.ConfigParser()
CONFIG_FILE_PATH = 'config.ini'
try:
    config.read(CONFIG_FILE_PATH, encoding='utf-8')
    RAW_DATA_PATH = config.get('Paths', 'raw')
    LOG_PATH = config.get('Paths', 'logs')
    
    # Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
    GNEWS_API_KEY = config.get('API_Keys', 'gnews_api_key', fallback=None)
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡
    GNEWS_ENABLED = config.getboolean('News_Sources', 'gnews_enabled', fallback=True)
    REMOVE_DUPLICATES = config.getboolean('News_Sources', 'remove_duplicates', fallback=True)
    
    # Rate Limits Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡
    BINANCE_DELAY = config.getfloat('Rate_Limits', 'binance_delay', fallback=0.1)
    GNEWS_DELAY = config.getfloat('Rate_Limits', 'gnews_delay', fallback=1.0)
    
    # Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
    GNEWS_DAILY_LIMIT = config.getint('Rate_Limits', 'gnews_daily_limit', fallback=100)
    GNEWS_HOURLY_LIMIT = config.getint('Rate_Limits', 'gnews_hourly_limit', fallback=10)
    
    MAX_REQUESTS_PER_SESSION = config.getint('Data_Settings', 'max_requests_per_session', fallback=500)
    
except Exception as e:
    print(f"CRITICAL ERROR: Could not read 'config.ini'. Error: {e}")
    exit()

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª logging
script_name = os.path.splitext(os.path.basename(__file__))[0]
log_subfolder_path = os.path.join(LOG_PATH, script_name)
os.makedirs(log_subfolder_path, exist_ok=True)
os.makedirs(RAW_DATA_PATH, exist_ok=True)

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² Ù…Ø³ÛŒØ± raw Ø¨Ø¯ÙˆÙ† Ø§ÛŒØ¬Ø§Ø¯ Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡
price_data_path = RAW_DATA_PATH
news_data_path = RAW_DATA_PATH
os.makedirs(price_data_path, exist_ok=True)
os.makedirs(news_data_path, exist_ok=True)

log_filename = os.path.join(log_subfolder_path, f"log_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler(log_filename, encoding='utf-8'), logging.StreamHandler()])

# Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ - Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù…
COMMON_PAIRS = [
    "BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "SOL/USDT", "ADA/USDT", 
    "DOGE/USDT", "SHIB/USDT", "TRX/USDT", "MATIC/USDT", "LTC/USDT", "DOT/USDT", 
    "AVAX/USDT", "LINK/USDT", "BCH/USDT", "UNI/USDT", "FIL/USDT", "ETC/USDT", 
    "ATOM/USDT", "ICP/USDT", "VET/USDT", "OP/USDT", "ARB/USDT", "APT/USDT", 
    "NEAR/USDT", "FTM/USDT", "RNDR/USDT", "GRT/USDT", "MANA/USDT", "SAND/USDT"
]
COMMON_TIMEFRAMES = ["1m", "5m", "15m", "1h", "4h", "1d"]
LIMIT = 2000
MAX_NEWS_PER_SYMBOL = 10

# --- Ú©Ù„Ø§Ø³ State Management ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ ---
class UnifiedStateManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª state ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±"""
    
    def __init__(self, db_path: str = None):
        if db_path is None:
            db_path = os.path.join(RAW_DATA_PATH, 'unified_extraction_state.db')
        self.db_path = db_path
        self.setup_database()
        logging.info(f"ğŸ’¾ Unified State Manager initialized: {db_path}")
    
    def setup_database(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²"""
        with sqlite3.connect(self.db_path) as conn:
            conn.executescript('''
                -- Ø¬Ø¯ÙˆÙ„ Ø§ØµÙ„ÛŒ sessions
                CREATE TABLE IF NOT EXISTS extraction_sessions (
                    session_id TEXT PRIMARY KEY,
                    session_type TEXT CHECK(session_type IN ('price', 'news', 'unified')),
                    status TEXT DEFAULT 'active',
                    total_symbols INTEGER,
                    completed_symbols INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                
                -- Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª
                CREATE TABLE IF NOT EXISTS price_progress (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    exchange TEXT,
                    symbol TEXT,
                    timeframe TEXT,
                    status TEXT DEFAULT 'pending',
                    file_path TEXT,
                    records_count INTEGER,
                    error_message TEXT,
                    completed_at TIMESTAMP,
                    FOREIGN KEY (session_id) REFERENCES extraction_sessions(session_id)
                );
                
                -- Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ´Ø±ÙØª Ø§Ø®Ø¨Ø§Ø±
                CREATE TABLE IF NOT EXISTS news_progress (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    symbol TEXT,
                    language TEXT,
                    status TEXT DEFAULT 'pending',
                    file_path TEXT,
                    news_count INTEGER,
                    error_message TEXT,
                    completed_at TIMESTAMP,
                    FOREIGN KEY (session_id) REFERENCES extraction_sessions(session_id)
                );
                
                -- Ø¬Ø¯ÙˆÙ„ rate limits
                CREATE TABLE IF NOT EXISTS rate_limits (
                    api_name TEXT PRIMARY KEY,
                    daily_count INTEGER DEFAULT 0,
                    hourly_count INTEGER DEFAULT 0,
                    last_daily_reset TEXT,
                    last_hourly_reset TEXT,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                
                -- Ø¬Ø¯ÙˆÙ„ failed items
                CREATE TABLE IF NOT EXISTS failed_items (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    item_type TEXT CHECK(item_type IN ('price', 'news')),
                    exchange TEXT,
                    symbol TEXT,
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            ''')
        logging.info("âœ… Database setup completed")
    
    def create_unified_session(self, symbols: List[str], include_price: bool = True, 
                              include_news: bool = True) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ session ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¬Ø¯ÛŒØ¯"""
        session_id = f"unified_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        session_type = 'unified' if include_price and include_news else ('price' if include_price else 'news')
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT INTO extraction_sessions 
                (session_id, session_type, total_symbols, status)
                VALUES (?, ?, ?, 'active')
            ''', (session_id, session_type, len(symbols)))
        
        logging.info(f"ğŸ†• Unified Session created: {session_id} (type: {session_type})")
        return session_id
    
    def update_price_progress(self, session_id: str, exchange: str, symbol: str, 
                            timeframe: str, status: str, **kwargs):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª"""
        with sqlite3.connect(self.db_path) as conn:
            # Ú†Ú© ÙˆØ¬ÙˆØ¯ Ø±Ú©ÙˆØ±Ø¯
            cursor = conn.execute('''
                SELECT id FROM price_progress 
                WHERE session_id = ? AND exchange = ? AND symbol = ? AND timeframe = ?
            ''', (session_id, exchange, symbol, timeframe))
            
            if cursor.fetchone():
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
                update_fields = ['status = ?']
                update_values = [status]
                
                if 'file_path' in kwargs:
                    update_fields.append('file_path = ?')
                    update_values.append(kwargs['file_path'])
                if 'records_count' in kwargs:
                    update_fields.append('records_count = ?')
                    update_values.append(kwargs['records_count'])
                if 'error_message' in kwargs:
                    update_fields.append('error_message = ?')
                    update_values.append(kwargs['error_message'])
                
                if status == 'completed':
                    update_fields.append('completed_at = CURRENT_TIMESTAMP')
                
                update_values.extend([session_id, exchange, symbol, timeframe])
                
                conn.execute(f'''
                    UPDATE price_progress 
                    SET {', '.join(update_fields)}
                    WHERE session_id = ? AND exchange = ? AND symbol = ? AND timeframe = ?
                ''', update_values)
            else:
                # Ø¯Ø±Ø¬ Ø¬Ø¯ÛŒØ¯
                conn.execute('''
                    INSERT INTO price_progress 
                    (session_id, exchange, symbol, timeframe, status, file_path, records_count, error_message)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (session_id, exchange, symbol, timeframe, status, 
                     kwargs.get('file_path'), kwargs.get('records_count'), kwargs.get('error_message')))
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ session
            if status == 'completed':
                conn.execute('''
                    UPDATE extraction_sessions 
                    SET completed_symbols = completed_symbols + 1, updated_at = CURRENT_TIMESTAMP
                    WHERE session_id = ?
                ''', (session_id,))
    
    def update_news_progress(self, session_id: str, symbol: str, language: str, 
                           status: str, **kwargs):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø§Ø®Ø¨Ø§Ø±"""
        with sqlite3.connect(self.db_path) as conn:
            # Ú†Ú© ÙˆØ¬ÙˆØ¯ Ø±Ú©ÙˆØ±Ø¯
            cursor = conn.execute('''
                SELECT id FROM news_progress 
                WHERE session_id = ? AND symbol = ? AND language = ?
            ''', (session_id, symbol, language))
            
            if cursor.fetchone():
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
                update_fields = ['status = ?']
                update_values = [status]
                
                if 'file_path' in kwargs:
                    update_fields.append('file_path = ?')
                    update_values.append(kwargs['file_path'])
                if 'news_count' in kwargs:
                    update_fields.append('news_count = ?')
                    update_values.append(kwargs['news_count'])
                if 'error_message' in kwargs:
                    update_fields.append('error_message = ?')
                    update_values.append(kwargs['error_message'])
                
                if status == 'completed':
                    update_fields.append('completed_at = CURRENT_TIMESTAMP')
                
                update_values.extend([session_id, symbol, language])
                
                conn.execute(f'''
                    UPDATE news_progress 
                    SET {', '.join(update_fields)}
                    WHERE session_id = ? AND symbol = ? AND language = ?
                ''', update_values)
            else:
                # Ø¯Ø±Ø¬ Ø¬Ø¯ÛŒØ¯
                conn.execute('''
                    INSERT INTO news_progress 
                    (session_id, symbol, language, status, file_path, news_count, error_message)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (session_id, symbol, language, status, 
                     kwargs.get('file_path'), kwargs.get('news_count'), kwargs.get('error_message')))
    
    def get_session_status(self, session_id: str) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ session"""
        with sqlite3.connect(self.db_path) as conn:
            # Ø§Ø·Ù„Ø§Ø¹Ø§Øª session
            cursor = conn.execute('''
                SELECT * FROM extraction_sessions WHERE session_id = ?
            ''', (session_id,))
            session_info = cursor.fetchone()
            
            if not session_info:
                return None
            
            # Ù¾ÛŒØ´Ø±ÙØª Ù‚ÛŒÙ…Øª
            cursor = conn.execute('''
                SELECT COUNT(*) total, 
                       SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) completed
                FROM price_progress WHERE session_id = ?
            ''', (session_id,))
            price_progress = cursor.fetchone()
            
            # Ù¾ÛŒØ´Ø±ÙØª Ø§Ø®Ø¨Ø§Ø±
            cursor = conn.execute('''
                SELECT COUNT(*) total, 
                       SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) completed
                FROM news_progress WHERE session_id = ?
            ''', (session_id,))
            news_progress = cursor.fetchone()
            
            return {
                'session_id': session_info[0],
                'session_type': session_info[1],
                'status': session_info[2],
                'total_symbols': session_info[3],
                'completed_symbols': session_info[4],
                'price_progress': {
                    'total': price_progress[0] if price_progress else 0,
                    'completed': price_progress[1] if price_progress else 0
                },
                'news_progress': {
                    'total': news_progress[0] if news_progress else 0,
                    'completed': news_progress[1] if news_progress else 0
                }
            }
    
    def add_failed_item(self, item_type: str, symbol: str, error_msg: str, exchange: str = None):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO failed_items (item_type, exchange, symbol, error_message)
                VALUES (?, ?, ?, ?)
            ''', (item_type, exchange, symbol, error_msg))
    
    def is_failed_item(self, item_type: str, symbol: str, exchange: str = None) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø¢ÛŒØªÙ… Ù‚Ø¨Ù„Ø§Ù‹ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT 1 FROM failed_items 
                WHERE item_type = ? AND symbol = ? AND (exchange = ? OR exchange IS NULL)
            ''', (item_type, symbol, exchange))
            return cursor.fetchone() is not None

# --- Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Rate Limit Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ ---
class SimplifiedRateLimiter:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø§Ø¯Ù‡ Ù†Ø±Ø® Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Binance Ùˆ GNews"""
    
    def __init__(self, state_manager: UnifiedStateManager):
        self.state_manager = state_manager
        self.last_request_time = {}
        self.request_counters = {
            'Binance': {'session': 0},
            'GNews': {'daily': 0, 'hourly': 0, 'session': 0}
        }
        
        self.min_intervals = {
            'Binance': BINANCE_DELAY,
            'GNews': GNEWS_DELAY
        }
        
        self.limits = {
            'GNews': {
                'daily': GNEWS_DAILY_LIMIT,
                'hourly': GNEWS_HOURLY_LIMIT,
                'session': MAX_REQUESTS_PER_SESSION
            }
        }
        
        self.lock = threading.Lock()
        self.load_persisted_state()
        logging.info(f"ğŸ”§ Simplified Rate Limiter initialized (Binance + GNews only)")
    
    def load_persisted_state(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø² database"""
        with sqlite3.connect(self.state_manager.db_path) as conn:
            cursor = conn.execute('SELECT * FROM rate_limits WHERE api_name = ?', ('GNews',))
            row = cursor.fetchone()
            
            if row:
                self.request_counters['GNews']['daily'] = row[1]
                self.request_counters['GNews']['hourly'] = row[2]
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø±ÛŒØ³Øª
                if row[3]:  # last_daily_reset
                    last_daily = datetime.fromisoformat(row[3])
                    if (datetime.now() - last_daily).days >= 1:
                        self.reset_daily_counter('GNews')
                
                if row[4]:  # last_hourly_reset  
                    last_hourly = datetime.fromisoformat(row[4])
                    if (datetime.now() - last_hourly).total_seconds() >= 3600:
                        self.reset_hourly_counter('GNews')
    
    def save_state(self, api_name: str):
        """Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± database"""
        if api_name != 'GNews':
            return
            
        counters = self.request_counters[api_name]
        now = datetime.now().isoformat()
        
        with sqlite3.connect(self.state_manager.db_path) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO rate_limits 
                (api_name, daily_count, hourly_count, last_daily_reset, last_hourly_reset)
                VALUES (?, ?, ?, ?, ?)
            ''', (api_name, counters.get('daily', 0), counters.get('hourly', 0), now, now))
    
    def reset_daily_counter(self, api_name: str):
        """Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡"""
        if api_name in self.request_counters:
            self.request_counters[api_name]['daily'] = 0
            logging.info(f"ğŸ”„ Daily counter reset for {api_name}")
            self.save_state(api_name)
    
    def reset_hourly_counter(self, api_name: str):
        """Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø³Ø§Ø¹ØªÛŒ"""
        if api_name in self.request_counters:
            self.request_counters[api_name]['hourly'] = 0
            logging.info(f"ğŸ”„ Hourly counter reset for {api_name}")
            self.save_state(api_name)
    
    def check_and_wait_for_reset(self, api_name: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ùˆ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø±ÛŒØ³Øª Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²"""
        if api_name not in self.limits:
            return True
        
        counters = self.request_counters[api_name]
        limits = self.limits[api_name]
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø§Ø¹ØªÛŒ
        if 'hourly' in limits and counters.get('hourly', 0) >= limits['hourly']:
            logging.warning(f"â³ Hourly limit reached for {api_name} - waiting...")
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† ØªØ§ Ø±ÛŒØ³Øª
            now = datetime.now()
            next_hour = now.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)
            wait_seconds = (next_hour - now).total_seconds()
            
            logging.info(f"â° Waiting {wait_seconds:.0f} seconds for hourly reset...")
            time.sleep(wait_seconds)
            self.reset_hourly_counter(api_name)
            return True
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡
        if 'daily' in limits and counters.get('daily', 0) >= limits['daily']:
            logging.warning(f"â³ Daily limit reached for {api_name} - waiting...")
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† ØªØ§ Ø±ÛŒØ³Øª
            now = datetime.now()
            next_day = now.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1)
            wait_seconds = (next_day - now).total_seconds()
            
            logging.info(f"â° Waiting {wait_seconds:.0f} seconds for daily reset...")
            time.sleep(wait_seconds)
            self.reset_daily_counter(api_name)
            return True
        
        return True
    
    def wait_if_needed(self, api_name: str) -> bool:
        """Ø§Ø¹Ù…Ø§Ù„ ØªØ£Ø®ÛŒØ± Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª"""
        with self.lock:
            # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø±ÛŒØ³Øª Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
            if not self.check_and_wait_for_reset(api_name):
                return False
            
            # Ø§Ø¹Ù…Ø§Ù„ ØªØ£Ø®ÛŒØ± Ù…Ø¹Ù…ÙˆÙ„
            current_time = time.time()
            if api_name in self.last_request_time:
                elapsed = current_time - self.last_request_time[api_name]
                required_interval = self.min_intervals.get(api_name, 1.0)
                
                if elapsed < required_interval:
                    wait_time = required_interval - elapsed
                    time.sleep(wait_time)
            
            # Ø«Ø¨Øª Ø²Ù…Ø§Ù† Ùˆ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡
            self.last_request_time[api_name] = time.time()
            
            if api_name in self.request_counters:
                self.request_counters[api_name]['session'] += 1
                if api_name == 'GNews':
                    self.request_counters[api_name]['daily'] += 1
                    self.request_counters[api_name]['hourly'] += 1
                    self.save_state(api_name)
            
            return True
    
    def get_stats(self, api_name: str) -> dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡"""
        if api_name not in self.request_counters:
            return {}
            
        counters = self.request_counters[api_name]
        if api_name in self.limits:
            limits = self.limits[api_name]
            result = {}
            if 'daily' in limits:
                result['daily'] = f"{counters.get('daily', 0)}/{limits['daily']}"
            if 'hourly' in limits:
                result['hourly'] = f"{counters.get('hourly', 0)}/{limits['hourly']}"
            result['session'] = f"{counters['session']}/{limits.get('session', 'N/A')}"
            return result
        else:
            return {'session': counters['session']}

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
def safe_request(url: str, params: dict = None, headers: dict = None, 
                api_name: str = None, max_retries: int = 3) -> requests.Response:
    """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§ÛŒÙ…Ù† Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯"""
    for retry in range(max_retries):
        try:
            response = requests.get(url, params=params, headers=headers, timeout=30)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            if retry == max_retries - 1:
                logging.error(f"Request failed after {max_retries} attempts: {e}")
                raise
            
            wait_time = 2 ** retry
            logging.warning(f"Request error. Waiting {wait_time}s before retry...")
            time.sleep(wait_time)

# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª (ÙÙ‚Ø· Binance) ---
def fetch_from_binance(symbol: str, timeframe: str, limit: int, **kwargs) -> pd.DataFrame:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Binance API"""
    try:
        binance_symbol = symbol.replace('/', '').upper()
        timeframe_map = {
            '1m': '1m', '3m': '3m', '5m': '5m', '15m': '15m', '30m': '30m',
            '1h': '1h', '2h': '2h', '4h': '4h', '6h': '6h', '8h': '8h', '12h': '12h',
            '1d': '1d', '3d': '3d', '1w': '1w', '1M': '1M'
        }
        
        binance_interval = timeframe_map.get(timeframe, timeframe)
        params = {
            'symbol': binance_symbol,
            'interval': binance_interval,
            'limit': min(limit, 1000)
        }
        
        logging.info(f"[Binance] Fetching data for {symbol} | {timeframe}...")
        
        response = safe_request("https://api.binance.com/api/v3/klines", params=params, api_name="Binance")
        data = response.json()
        
        if not data:
            logging.warning(f"[Binance] No data received for {symbol} | {timeframe}.")
            return pd.DataFrame()
        
        df = pd.DataFrame(data, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_asset_volume', 'number_of_trades',
            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
        ])
        
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].copy()
        
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['symbol'] = symbol
        df['timeframe'] = timeframe
        df['exchange'] = 'Binance'
        
        return df
        
    except Exception as e:
        logging.error(f"[Binance] Error fetching data for {symbol} | {timeframe}: {e}")
        return pd.DataFrame()

# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± (ÙÙ‚Ø· GNews) ---
def fetch_crypto_news(api_key: str, symbols: List[str], max_news: int = 10, 
                     rate_limiter: SimplifiedRateLimiter = None) -> pd.DataFrame:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø§Ø² GNews API
    ØªÙˆØ¬Ù‡: ÙÙ‚Ø· Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù API
    """
    logging.info("Starting GNews data collection (English only)...")
    all_articles = []
    base_url = "https://gnews.io/api/v4/search"
    
    total_requests = len(symbols)  # ÙÙ‚Ø· ÛŒÚ© Ø²Ø¨Ø§Ù†
    current_request = 0
    skipped_due_to_limit = 0
    
    for symbol in symbols:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ø§Ø±Ø² Ø§Ø² Ø¬ÙØª Ø§Ø±Ø²
        crypto_name = symbol.split('/')[0]
        
        current_request += 1
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù‚Ø¨Ù„ Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øª
        if rate_limiter:
            if rate_limiter.request_counters['GNews']['daily'] >= GNEWS_DAILY_LIMIT:
                skipped_due_to_limit += 1
                logging.warning(f"â­ï¸ Skipping {symbol} due to daily limit")
                continue
        
        query = f"{crypto_name} cryptocurrency"
        
        params = {
            'q': query,
            'lang': 'en',  # ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            'max': max_news,
            'apikey': api_key,
            'sortby': 'publishedAt'  # Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø±
        }
        
        try:
            logging.info(f"[{current_request}/{total_requests}] Fetching GNews for {symbol}...")
            
            # Ø§Ø¹Ù…Ø§Ù„ rate limit
            if rate_limiter:
                rate_limiter.wait_if_needed('GNews')
            
            response = safe_request(base_url, params=params, api_name='GNews')
            data = response.json()
            
            if 'articles' not in data:
                logging.warning(f"Unexpected GNews response for {symbol}: {data}")
                continue
            
            articles = data.get('articles', [])
            
            for article in articles:
                all_articles.append({
                    'timestamp': article.get('publishedAt', ''),
                    'symbol': symbol,
                    'title': article.get('title', ''),
                    'content': article.get('content', ''),
                    'description': article.get('description', ''),
                    'source': article.get('source', {}).get('name', ''),
                    'url': article.get('url', ''),
                    'language': 'en',
                    'image': article.get('image', ''),
                    'api_source': 'GNews'
                })
            
            logging.info(f"âœ… GNews: {len(articles)} news received for {symbol}.")
            
        except requests.exceptions.RequestException as e:
            logging.error(f"Error fetching GNews for {symbol}: {e}")
        except json.JSONDecodeError as e:
            logging.error(f"JSON decode error for {symbol}: {e}")
        except Exception as e:
            logging.error(f"Unexpected error for {symbol}: {e}")
    
    if skipped_due_to_limit > 0:
        logging.warning(f"âš ï¸ {skipped_due_to_limit} requests skipped due to limits.")
    
    if not all_articles:
        logging.warning("No news received from GNews.")
        return pd.DataFrame()
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
    df = pd.DataFrame(all_articles)
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df = df.dropna(subset=['timestamp'])
    
    # Ø­Ø°Ù duplicates
    if REMOVE_DUPLICATES:
        initial_count = len(df)
        df = df.drop_duplicates(subset=['title'], keep='first')
        final_count = len(df)
        
        if initial_count > final_count:
            logging.info(f"ğŸ§¹ Removed {initial_count - final_count} duplicate news")
    
    # Ø§ÙØ²ÙˆØ¯Ù† sentiment_score
    analyzer = SentimentIntensityAnalyzer()
    
    def analyze_sentiment(row):
        text = f"{row.get('title', '')} {row.get('description', '')}"
        try:
            return analyzer.polarity_scores(text)['compound']
        except:
            return 0
    
    df['sentiment_score'] = df.apply(analyze_sentiment, axis=1)
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ timestamp
    df = df.sort_values('timestamp', ascending=False).reset_index(drop=True)
    
    logging.info(f"ğŸ“Š Total GNews received: {len(df)}")
    
    return df

# --- ØªÙˆØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ (ÙÙ‚Ø· Binance) ---
def fetch_all_tradable_pairs_from_exchange(exchange_name: str, quote_currency="USDT"):
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø§Ø² Binance"""
    if exchange_name == 'Binance':
        return fetch_all_tradable_pairs_binance(quote_currency)
    else:
        logging.error(f"Only Binance is supported in simplified version.")
        return []

def fetch_all_tradable_pairs_binance(quote_currency="USDT"):
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø§Ø² Binance"""
    logging.info(f"[Binance] Fetching all pairs with {quote_currency}...")
    try:
        response = safe_request("https://api.binance.com/api/v3/exchangeInfo", api_name="Binance")
        data = response.json()
        
        pairs = []
        for symbol_info in data['symbols']:
            if (symbol_info['status'] == 'TRADING' and 
                symbol_info['quoteAsset'] == quote_currency):
                pair = f"{symbol_info['baseAsset']}/{symbol_info['quoteAsset']}"
                pairs.append(pair)
        
        logging.info(f"[Binance] Found {len(pairs)} valid pairs.")
        return pairs
    except Exception as e:
        logging.error(f"[Binance] Error fetching pairs: {e}")
        return []

# --- Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Simplified Data Fetcher ---
class SimplifiedDataFetcher:
    """Ú©Ù„Ø§Ø³ Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª (Binance) Ùˆ Ø§Ø®Ø¨Ø§Ø± (GNews)"""
    
    def __init__(self):
        self.state_manager = UnifiedStateManager()
        self.rate_limiter = SimplifiedRateLimiter(self.state_manager)
        
        # ÙÙ‚Ø· Binance Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øª
        self.exchange_functions = {
            'Binance': fetch_from_binance
        }
        
        # Ø§ÛŒØ¬Ø§Ø¯ sentiment analyzer
        self.sentiment_analyzer = SentimentIntensityAnalyzer()
        
        logging.info("ğŸš€ Simplified Data Fetcher ready (Binance + GNews only)")
    
    def fetch_price_data(self, symbol: str, timeframe: str, limit: int, 
                        exchange_name: str, session_id: str) -> bool:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª state"""
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡
        if self.state_manager.is_failed_item('price', symbol, exchange_name):
            logging.info(f"â­ï¸ Skipping failed pair: {symbol}")
            return True
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ù†ØªØ¸Ø§Ø± rate limit
        if not self.rate_limiter.wait_if_needed(exchange_name):
            logging.error(f"âŒ Rate limit reached for {exchange_name}")
            return False
        
        try:
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
            self.state_manager.update_price_progress(
                session_id, exchange_name, symbol, timeframe, 'processing'
            )
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡
            fetch_function = self.exchange_functions[exchange_name]
            df = fetch_function(symbol, timeframe, limit)
            
            if df.empty:
                error_msg = f"Empty data for {symbol}"
                logging.warning(f"âš ï¸ {error_msg}")
                self.state_manager.add_failed_item('price', symbol, error_msg, exchange_name)
                self.state_manager.update_price_progress(
                    session_id, exchange_name, symbol, timeframe, 'failed',
                    error_message=error_msg
                )
                return True
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡
            filename = self.save_price_data(df, exchange_name, session_id)
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
            self.state_manager.update_price_progress(
                session_id, exchange_name, symbol, timeframe, 'completed',
                file_path=filename, records_count=len(df)
            )
            
            logging.info(f"âœ… Price success: {symbol}|{timeframe} - {len(df)} rows")
            return True
            
        except Exception as e:
            error_msg = f"Exception: {str(e)}"
            logging.error(f"âŒ Error in {symbol}|{timeframe}: {error_msg}")
            
            # Ø§Ú¯Ø± Ø®Ø·Ø§ÛŒ API Ø§Ø³ØªØŒ Ø¨Ù‡ failed items Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if any(x in str(e).lower() for x in ['market does not exist', 'unknown asset pair', 'invalid symbol']):
                self.state_manager.add_failed_item('price', symbol, error_msg, exchange_name)
            
            self.state_manager.update_price_progress(
                session_id, exchange_name, symbol, timeframe, 'failed',
                error_message=error_msg
            )
            
            return True
    
    def fetch_news_data(self, symbols: List[str], max_news: int, session_id: str) -> bool:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± ÙÙ‚Ø· Ø§Ø² GNews"""
        
        logging.info("\n--- Starting GNews extraction ---")
        logging.info(f"Symbols count: {len(symbols)}")
        logging.info(f"News per symbol: {max_news}")
        
        if not GNEWS_ENABLED or not GNEWS_API_KEY:
            logging.error("âŒ GNews is not enabled or API key missing")
            return False
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² GNews
        df_news = fetch_crypto_news(GNEWS_API_KEY, symbols, max_news, self.rate_limiter)
        
        if df_news.empty:
            logging.warning("âŒ No news received from GNews")
            return False
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù…Ø§Ø¯
        for symbol, group in df_news.groupby('symbol'):
            try:
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª
                self.state_manager.update_news_progress(
                    session_id, symbol, 'en', 'processing'
                )
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡
                filename = self.save_news_data(group, symbol, 'en', session_id)
                
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
                self.state_manager.update_news_progress(
                    session_id, symbol, 'en', 'completed',
                    file_path=filename, news_count=len(group)
                )
                
                logging.info(f"âœ… News success: {symbol} - {len(group)} news")
                
            except Exception as e:
                error_msg = f"Error saving news for {symbol}: {str(e)}"
                logging.error(error_msg)
                self.state_manager.update_news_progress(
                    session_id, symbol, 'en', 'failed',
                    error_message=error_msg
                )
        
        return True
    
    def save_price_data(self, df: pd.DataFrame, exchange_name: str, session_id: str) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª"""
        if df.empty:
            return ""
        
        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        required_columns = ['timestamp', 'symbol', 'timeframe', 'exchange', 'open', 'high', 'low', 'close', 'volume']
        df_final = df[required_columns].copy()
        
        # Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„
        symbol = df_final['symbol'].iloc[0]
        timeframe = df_final['timeframe'].iloc[0]
        
        symbol_sanitized = symbol.replace('/', '-')
        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{exchange_name}_{symbol_sanitized}_{timeframe}_{timestamp_str}.csv"
        output_path = os.path.join(RAW_DATA_PATH, filename)        
        # Ø°Ø®ÛŒØ±Ù‡
        df_final.to_csv(output_path, index=False, float_format='%.8f')
        
        return filename
    
    def save_news_data(self, df: pd.DataFrame, symbol: str, language: str, session_id: str) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø®Ø¨Ø§Ø±"""
        if df.empty:
            return ""
        
        # Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„
        symbol_sanitized = symbol.replace('/', '-')
        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"news_{symbol_sanitized}_{language}_{timestamp_str}.csv"
        output_path = os.path.join(RAW_DATA_PATH, filename)        
        # Ø°Ø®ÛŒØ±Ù‡
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        return filename
    
    def run_price_extraction(self, exchange_name: str, symbols: List[str], 
                           timeframes: List[str], session_id: str) -> int:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§"""
        success_count = 0
        
        logging.info(f"\n--- Starting price data extraction from {exchange_name} ---")
        logging.info(f"Symbols count: {len(symbols)}")
        logging.info(f"Timeframes: {', '.join(timeframes)}")
        
        for symbol in symbols:
            for timeframe in timeframes:
                success = self.fetch_price_data(
                    symbol, timeframe, LIMIT, exchange_name, session_id
                )
                if success:
                    success_count += 1
                
                # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
                stats = self.rate_limiter.get_stats(exchange_name)
                if stats:
                    logging.info(f"ğŸ“Š {exchange_name} Stats: {stats}")
        
        return success_count
    
    def run_news_extraction(self, symbols: List[str], max_news: int, session_id: str) -> bool:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± ÙÙ‚Ø· Ø§Ø² GNews"""
        success = self.fetch_news_data(symbols, max_news, session_id)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± GNews
        stats = self.rate_limiter.get_stats('GNews')
        if stats:
            logging.info(f"ğŸ“Š GNews Stats: {stats}")
        
        return success

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ UI (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
def get_user_selection(options: list, title: str, allow_manual=False, allow_multi=False, allow_all=False):
    """Ù…Ù†ÙˆÛŒ Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
    print(f"\n--- {title} ---")
    for i, option in enumerate(options, 1):
        print(f"{i}. {option}")
    
    if allow_all: 
        print(f"{len(options)+1}. Ù‡Ù…Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø¨Ø§Ù„Ø§")
    if allow_manual: 
        print(f"{len(options)+2 if allow_all else len(options)+1}. ÙˆØ±ÙˆØ¯ Ø¯Ø³ØªÛŒ")
    
    if allow_multi:
        prompt = "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯): "
    else:
        prompt = "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±: "
    
    choice_str = input(prompt).strip()
    
    if not choice_str:
        logging.error("ÙˆØ±ÙˆØ¯ÛŒ Ø®Ø§Ù„ÛŒ.")
        return []
    
    try:
        if allow_all and choice_str == str(len(options)+1):
            return options
            
        manual_entry_num = len(options)+2 if allow_all else len(options)+1
        if allow_manual and choice_str == str(manual_entry_num):
            manual_input = input("Ù„Ø·ÙØ§Ù‹ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯ (Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯ Ù…ÙˆØ±Ø¯ØŒ Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯): ").upper()
            return [item.strip() for item in manual_input.split(',')]
        
        if allow_multi:
            selected_indices = [int(i.strip()) - 1 for i in choice_str.split(',')]
            return [options[i] for i in selected_indices if 0 <= i < len(options)]
        else:
            idx = int(choice_str) - 1
            if 0 <= idx < len(options):
                return [options[idx]]
                
    except (ValueError, IndexError):
        logging.error("ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±.")
    
    return []

def get_exchange_selection():
    """Ø§Ù†ØªØ®Ø§Ø¨ ØµØ±Ø§ÙÛŒ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± - ÙÙ‚Ø· Binance"""
    print("\nğŸ¦ ØµØ±Ø§ÙÛŒ:")
    print("ğŸ’¡ Ø¯Ø± Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ ÙÙ‚Ø· Binance Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
    return 'Binance'

# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ (Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡) ---
def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ù…Ù†Ùˆ Ù…Ø­ÙˆØ± - Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡"""
    logging.info("ğŸš€ Starting Simplified Data Fetcher script")
    
    # Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ
    fetcher = SimplifiedDataFetcher()
    
    # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    print("\n" + "="*80)
    print("ğŸ” Simplified Data Fetcher Settings:")
    print(f"ğŸ“Š Binance: No limits, delay {BINANCE_DELAY}s")
    print(f"ğŸ“° GNews: Max {GNEWS_DAILY_LIMIT}/day, {GNEWS_HOURLY_LIMIT}/hour")
    print("ğŸ’¾ State Management: Unified for price and news")
    print("ğŸ¯ Focus: Binance (Price) + GNews (News) only")
    print("="*80)
    
    # Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡
    while True:
        print("\n" + "="*80)
        print("   Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ Simplified Data Fetcher")
        print("="*80)
        print("1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÙØ§Ø±Ø´ÛŒ (Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø² Ù„ÛŒØ³Øª)")
        print("2. Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ (Production Mode)")
        print("3. ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ (Backfill)")
        print("4. Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ùˆ ÙˆØ¶Ø¹ÛŒØª")
        print("5. Ù…Ø¯ÛŒØ±ÛŒØª State (Database)")
        print("6. Ø®Ø±ÙˆØ¬")
        
        main_choice = input("\nÙ„Ø·ÙØ§Ù‹ Ø´Ù…Ø§Ø±Ù‡ Ø¹Ù…Ù„ÛŒØ§Øª Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ")
        
        if main_choice == '1':
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÙØ§Ø±Ø´ÛŒ
            print("\nğŸ¯ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬:")
            print("1. ÙÙ‚Ø· Ù‚ÛŒÙ…Øª (Binance)")
            print("2. ÙÙ‚Ø· Ø§Ø®Ø¨Ø§Ø± (GNews)")
            print("3. Ù‡Ø± Ø¯Ùˆ (Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±)")
            
            data_type = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
            
            include_price = data_type in ['1', '3']
            include_news = data_type in ['2', '3']
            
            # Ø§Ú¯Ø± Ø§Ø®Ø¨Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ØŒ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø¨Ø± Ø±Ø§ Ø¨Ù¾Ø±Ø³
            max_news = 10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            if include_news:
                print("\nğŸ“° ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯:")
                print("1. 5 Ø®Ø¨Ø±")
                print("2. 10 Ø®Ø¨Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)")
                print("3. 20 Ø®Ø¨Ø±")
                
                news_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
                news_counts = {'1': 5, '2': 10, '3': 20}
                max_news = news_counts.get(news_choice, 10)
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù…Ø§Ø¯Ù‡Ø§
            pairs = get_user_selection(COMMON_PAIRS, "Ø§Ù†ØªØ®Ø§Ø¨ Ø¬ÙØª Ø§Ø±Ø²", 
                                     allow_manual=True, allow_multi=True, allow_all=True)
            if not pairs:
                input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                continue
            
            # Ø§ÛŒØ¬Ø§Ø¯ session
            session_id = fetcher.state_manager.create_unified_session(
                pairs, include_price, include_news
            )
            
            if include_price:
                # Ø§Ù†ØªØ®Ø§Ø¨ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…
                timeframes = get_user_selection(COMMON_TIMEFRAMES, "Ø§Ù†ØªØ®Ø§Ø¨ ØªØ§ÛŒÙ… ÙØ±ÛŒÙ…", 
                                              allow_multi=True, allow_all=True)
                if not timeframes:
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª (ÙÙ‚Ø· Binance)
                success_count = fetcher.run_price_extraction(
                    'Binance', pairs, timeframes, session_id
                )
                
                logging.info(f"âœ… Ù‚ÛŒÙ…Øª: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
            
            if include_news:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± (ÙÙ‚Ø· GNews)
                success = fetcher.run_news_extraction(pairs, max_news, session_id)
                
                if success:
                    logging.info("âœ… Ø§Ø®Ø¨Ø§Ø± GNews: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆÙÙ‚")
            
            # Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ù†Ù‡Ø§ÛŒÛŒ
            final_status = fetcher.state_manager.get_session_status(session_id)
            
            logging.info("\nâœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
            logging.info(f"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
            if include_price:
                logging.info(f"   Ù‚ÛŒÙ…Øª: {final_status['price_progress']['completed']}/{final_status['price_progress']['total']}")
            if include_news:
                logging.info(f"   Ø§Ø®Ø¨Ø§Ø±: {final_status['news_progress']['completed']}/{final_status['news_progress']['total']}")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ...")

        elif main_choice == '2':
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§
            print("\nğŸš¨ Ø­Ø§Ù„Øª Production - Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§ (Binance)")
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡
            print("\nğŸ¯ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬:")
            print("1. ÙÙ‚Ø· Ù‚ÛŒÙ…Øª (Binance)")
            print("2. ÙÙ‚Ø· Ø§Ø®Ø¨Ø§Ø± (GNews)")
            print("3. Ù‡Ø± Ø¯Ùˆ (Ù‚ÛŒÙ…Øª Ùˆ Ø§Ø®Ø¨Ø§Ø±)")
            
            data_type = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
            
            include_price = data_type in ['1', '3']
            include_news = data_type in ['2', '3']
            
            # Ø§Ú¯Ø± Ø§Ø®Ø¨Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ØŒ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø¨Ø± Ø±Ø§ Ø¨Ù¾Ø±Ø³
            max_news = 10  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            if include_news:
                print("\nğŸ“° ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯:")
                print("1. 5 Ø®Ø¨Ø±")
                print("2. 10 Ø®Ø¨Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)")
                print("3. 20 Ø®Ø¨Ø±")
                
                news_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
                news_counts = {'1': 5, '2': 10, '3': 20}
                max_news = news_counts.get(news_choice, 10)
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ Ø§Ø² Binance
            all_pairs = fetch_all_tradable_pairs_from_exchange('Binance', 'USDT')
            
            if not all_pairs:
                logging.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬ÙØªâ€ŒØ§Ø±Ø²Ù‡Ø§")
                input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                continue
            
            print(f"\nâœ… ØªØ¹Ø¯Ø§Ø¯ {len(all_pairs)} Ø¬ÙØª Ø§Ø±Ø² ÛŒØ§ÙØª Ø´Ø¯ Ø§Ø² Binance")
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ
            if include_price:
                price_requests = len(all_pairs) * len(COMMON_TIMEFRAMES)
                print(f"ğŸ“Š ØªØ®Ù…ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª: {price_requests}")
            
            if include_news:
                news_requests = len(all_pairs)
                remaining_daily = max(0, GNEWS_DAILY_LIMIT - fetcher.rate_limiter.request_counters['GNews']['daily'])
                print(f"ğŸ“° ØªØ®Ù…ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø±: {news_requests}")
                print(f"ğŸ“° Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡ GNews: {remaining_daily}")
            
            confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯ØŸ (y/n): ")
            if confirm.lower() != 'y':
                input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                continue
            
            # Ø§ÛŒØ¬Ø§Ø¯ session
            session_id = fetcher.state_manager.create_unified_session(
                all_pairs, include_price, include_news
            )
            
            if include_price:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
                success_count = fetcher.run_price_extraction(
                    'Binance', all_pairs, COMMON_TIMEFRAMES, session_id
                )
                logging.info(f"âœ… Ù‚ÛŒÙ…Øª: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
            
            if include_news:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² GNews
                success = fetcher.run_news_extraction(all_pairs, max_news, session_id)
                if success:
                    logging.info("âœ… Ø§Ø®Ø¨Ø§Ø± GNews: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆÙÙ‚")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ...")
        
        elif main_choice == '3':
            # ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ (Backfill)
            print("\nğŸ”„ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ (Backfill)")
            print("="*50)
            print("1. ØªÚ©Ù…ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
            print("2. ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
            print("3. ØªÚ©Ù…ÛŒÙ„ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡")
            print("4. ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯")
            print("5. Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ")
            
            backfill_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
            
            if backfill_choice == '1':
                # ØªÚ©Ù…ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                print("\nğŸ“Š ØªÚ©Ù…ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                price_files = [f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')]
                
                if not price_files:
                    print("âŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù‚ÛŒÙ…Øª Ù…ÙˆØ¬ÙˆØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                existing_combinations = set()
                symbols_found = set()
                
                for filename in price_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 3:
                            exchange = parts[0]
                            symbol = parts[1].replace('-', '/')
                            timeframe = parts[2]
                            existing_combinations.add((exchange, symbol, timeframe))
                            symbols_found.add(symbol)
                    except:
                        continue
                
                print(f"âœ… ÛŒØ§ÙØª Ø´Ø¯: {len(symbols_found)} Ù†Ù…Ø§Ø¯ Ø¯Ø± {len(existing_combinations)} ØªØ±Ú©ÛŒØ¨")
                
                # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                missing_combinations = []
                for symbol in symbols_found:
                    for timeframe in COMMON_TIMEFRAMES:
                        if ('Binance', symbol, timeframe) not in existing_combinations:
                            missing_combinations.append((symbol, timeframe))
                
                if not missing_combinations:
                    print("âœ… Ù‡Ù…Ù‡ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ú©Ø§Ù…Ù„ Ø§Ø³Øª")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(missing_combinations)} ØªØ±Ú©ÛŒØ¨ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡ ÛŒØ§ÙØª Ø´Ø¯")
                
                # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡
                print("\nÙ†Ù…ÙˆÙ†Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡:")
                for i, (symbol, timeframe) in enumerate(missing_combinations[:10]):
                    print(f"  - {symbol} | {timeframe}")
                if len(missing_combinations) > 10:
                    print(f"  ... Ùˆ {len(missing_combinations) - 10} Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±")
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§ÛŒØ¬Ø§Ø¯ session Ø¨Ø±Ø§ÛŒ backfill
                unique_symbols = list(set([combo[0] for combo in missing_combinations]))
                session_id = fetcher.state_manager.create_unified_session(unique_symbols, True, False)
                
                # Ø§Ø¬Ø±Ø§ÛŒ backfill
                success_count = 0
                total_items = len(missing_combinations)
                
                for i, (symbol, timeframe) in enumerate(missing_combinations):
                    success = fetcher.fetch_price_data(symbol, timeframe, LIMIT, 'Binance', session_id)
                    if success:
                        success_count += 1
                    
                    # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
                    progress = ((i + 1) / total_items) * 100
                    print(f"âš¡ Ù¾ÛŒØ´Ø±ÙØª: {progress:.1f}% ({i + 1}/{total_items}) - Ù…ÙˆÙÙ‚: {success_count}")
                
                print(f"\nâœ… Backfill ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯: {success_count} Ù…ÙˆØ±Ø¯ Ù…ÙˆÙÙ‚ Ø§Ø² {total_items}")
                
            elif backfill_choice == '2':
                # ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                print("\nğŸ’° ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                price_files = [f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')]
                existing_symbols = set()
                
                for filename in price_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 2:
                            symbol = parts[1].replace('-', '/')
                            existing_symbols.add(symbol)
                    except:
                        continue
                
                # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡
                missing_symbols = []
                for symbol in COMMON_PAIRS:
                    if symbol not in existing_symbols:
                        missing_symbols.append(symbol)
                
                if not missing_symbols:
                    print("âœ… Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(missing_symbols)} Ù†Ù…Ø§Ø¯ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡:")
                for symbol in missing_symbols:
                    print(f"  - {symbol}")
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§ÛŒÙ† Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§ÛŒØ¬Ø§Ø¯ session
                session_id = fetcher.state_manager.create_unified_session(missing_symbols, True, False)
                
                # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬
                success_count = fetcher.run_price_extraction('Binance', missing_symbols, COMMON_TIMEFRAMES, session_id)
                print(f"\nâœ… ØªÚ©Ù…ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
                
            elif backfill_choice == '3':
                # ØªÚ©Ù…ÛŒÙ„ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡
                print("\nğŸ”„ ØªÚ©Ù…ÛŒÙ„ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    cursor = conn.execute('''
                        SELECT item_type, exchange, symbol, error_message 
                        FROM failed_items 
                        WHERE item_type = 'price'
                        ORDER BY created_at DESC
                    ''')
                    failed_items = cursor.fetchall()
                
                if not failed_items:
                    print("âœ… Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(failed_items)} Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡:")
                for item in failed_items[:10]:
                    print(f"  - {item[2]} ({item[1]}) | {item[3][:50]}...")
                
                if len(failed_items) > 10:
                    print(f"  ... Ùˆ {len(failed_items) - 10} Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±")
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† failed items Ø¨Ø±Ø§ÛŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    conn.execute("DELETE FROM failed_items WHERE item_type = 'price'")
                
                print("ğŸ§¹ Ù„ÛŒØ³Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡ Ù¾Ø§Ú© Ø´Ø¯")
                
                # ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯
                failed_symbols = list(set([item[2] for item in failed_items]))
                session_id = fetcher.state_manager.create_unified_session(failed_symbols, True, False)
                
                success_count = fetcher.run_price_extraction('Binance', failed_symbols, COMMON_TIMEFRAMES, session_id)
                print(f"\nâœ… ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯: {success_count} Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÙˆÙÙ‚")
                
            elif backfill_choice == '4':
                # ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                print("\nğŸ“° ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª
                price_files = [f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')]
                symbols_with_price = set()
                
                for filename in price_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 2:
                            symbol = parts[1].replace('-', '/')
                            symbols_with_price.add(symbol)
                    except:
                        continue
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø®Ø¨Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯
                news_files = [f for f in os.listdir(RAW_DATA_PATH) if f.startswith('news_') and f.endswith('.csv')]
                symbols_with_news = set()
                
                for filename in news_files:
                    try:
                        parts = filename.replace('.csv', '').split('_')
                        if len(parts) >= 2:
                            symbol = parts[1].replace('-', '/')
                            symbols_with_news.add(symbol)
                    except:
                        continue
                
                # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‚ÛŒÙ…Øª Ø¯Ø§Ø±Ù†Ø¯ ÙˆÙ„ÛŒ Ø§Ø®Ø¨Ø§Ø± Ù†Ø¯Ø§Ø±Ù†Ø¯
                symbols_need_news = symbols_with_price - symbols_with_news
                
                if not symbols_need_news:
                    print("âœ… Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø®Ø¨Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯")
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                print(f"ğŸ“‹ ØªØ¹Ø¯Ø§Ø¯ {len(symbols_need_news)} Ù†Ù…Ø§Ø¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø®Ø¨Ø§Ø±:")
                symbols_list = list(symbols_need_news)
                for symbol in symbols_list[:10]:
                    print(f"  - {symbol}")
                if len(symbols_need_news) > 10:
                    print(f"  ... Ùˆ {len(symbols_need_news) - 10} Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±")
                
                # Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø±
                print("\nğŸ“° ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯:")
                print("1. 5 Ø®Ø¨Ø±")
                print("2. 10 Ø®Ø¨Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)")
                print("3. 20 Ø®Ø¨Ø±")
                
                news_choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: ")
                news_counts = {'1': 5, '2': 10, '3': 20}
                max_news = news_counts.get(news_choice, 10)
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª GNews
                remaining_daily = max(0, GNEWS_DAILY_LIMIT - fetcher.rate_limiter.request_counters['GNews']['daily'])
                
                if len(symbols_need_news) > remaining_daily:
                    print(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ ({len(symbols_need_news)}) Ø¨ÛŒØ´ØªØ± Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ ({remaining_daily}) Ø§Ø³Øª")
                    symbols_list = symbols_list[:remaining_daily]
                    print(f"ğŸ“Š Ù…Ø­Ø¯ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ù‡ {len(symbols_list)} Ù†Ù…Ø§Ø¯ Ø§ÙˆÙ„")
                else:
                    symbols_list = list(symbols_need_news)
                
                confirm = input("\nØ¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø®Ø¨Ø§Ø± Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯ØŸ (y/n): ")
                if confirm.lower() != 'y':
                    input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
                    continue
                
                # Ø§ÛŒØ¬Ø§Ø¯ session Ø¨Ø±Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø±
                session_id = fetcher.state_manager.create_unified_session(symbols_list, False, True)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² GNews
                success = fetcher.run_news_extraction(symbols_list, max_news, session_id)
                
                if success:
                    print("âœ… ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± GNews Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
                else:
                    print("âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÚ©Ù…ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø±")
                    
            elif backfill_choice == '5':
                pass  # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ
            else:
                print("Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±.")
                
            if backfill_choice != '5':
                input("\nEnter Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ...")
        
        elif main_choice == '4':
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
            print("\nğŸ“Š Ø¢Ù…Ø§Ø± ÙˆØ¶Ø¹ÛŒØª:")
            
            # Ø¢Ù…Ø§Ø± Binance
            stats = fetcher.rate_limiter.get_stats('Binance')
            if stats:
                print(f"\nğŸ”‘ Binance:")
                for key, value in stats.items():
                    print(f"   {key}: {value}")
            
            # Ø¢Ù…Ø§Ø± GNews
            stats = fetcher.rate_limiter.get_stats('GNews')
            if stats:
                print(f"\nğŸ“° GNews:")
                for key, value in stats.items():
                    print(f"   {key}: {value}")
            
            # Ø¢Ù…Ø§Ø± database
            with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                cursor = conn.execute('SELECT COUNT(*) FROM price_progress WHERE status = "completed"')
                price_completed = cursor.fetchone()[0]
                
                cursor = conn.execute('SELECT COUNT(*) FROM news_progress WHERE status = "completed"')
                news_completed = cursor.fetchone()[0]
                
                cursor = conn.execute('SELECT COUNT(*) FROM failed_items')
                failed_count = cursor.fetchone()[0]
                
                # Ø¢Ù…Ø§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
                price_files = len([f for f in os.listdir(RAW_DATA_PATH) if f.endswith('.csv') and not f.startswith('news_')])
                news_files = len([f for f in os.listdir(RAW_DATA_PATH) if f.startswith('news_') and f.endswith('.csv')])
                
                print(f"\nğŸ’¾ Ø¢Ù…Ø§Ø± Database:")
                print(f"   âœ… Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {price_completed}")
                print(f"   âœ… Ø§Ø®Ø¨Ø§Ø± ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {news_completed}")
                print(f"   âŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡: {failed_count}")
                
                print(f"\nğŸ“ Ø¢Ù…Ø§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§:")
                print(f"   ğŸ“Š ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª: {price_files}")
                print(f"   ğŸ“° ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø±: {news_files}")
            
            input("\nEnter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
            
        elif main_choice == '5':
            # Ù…Ø¯ÛŒØ±ÛŒØª State
            print("\nğŸ’¾ Ù…Ø¯ÛŒØ±ÛŒØª State Database:")
            print("1. Ù†Ù…Ø§ÛŒØ´ Sessions ÙØ¹Ø§Ù„")
            print("2. Ù†Ù…Ø§ÛŒØ´ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡")
            print("3. Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Database")
            print("4. Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª Session")
            print("5. Ø¨Ø§Ø²Ú¯Ø´Øª")
            
            state_choice = input("Ø§Ù†ØªØ®Ø§Ø¨: ")
            
            if state_choice == '1':
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    cursor = conn.execute('''
                        SELECT session_id, session_type, status, total_symbols, completed_symbols, created_at
                        FROM extraction_sessions ORDER BY created_at DESC LIMIT 10
                    ''')
                    
                    print("\nğŸ“‹ Sessions Ø§Ø®ÛŒØ±:")
                    sessions = cursor.fetchall()
                    if sessions:
                        for row in sessions:
                            print(f"   {row[0]} | {row[1]} | {row[2]} | {row[4]}/{row[3]} | {row[5]}")
                    else:
                        print("   Ù‡ÛŒÚ† sessionâ€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            elif state_choice == '2':
                with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                    cursor = conn.execute('''
                        SELECT item_type, exchange, symbol, error_message 
                        FROM failed_items ORDER BY created_at DESC LIMIT 20
                    ''')
                    
                    print("\nâŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡:")
                    failed_items = cursor.fetchall()
                    if failed_items:
                        for row in failed_items:
                            print(f"   {row[0]} | {row[1]} | {row[2]} | {row[3][:50]}...")
                    else:
                        print("   Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            elif state_choice == '3':
                confirm = input("âš ï¸ Ø¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ø¨Ù‡ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Database Ù‡Ø³ØªÛŒØ¯ØŸ (yes/no): ")
                if confirm == 'yes':
                    with sqlite3.connect(fetcher.state_manager.db_path) as conn:
                        conn.executescript('''
                            DELETE FROM extraction_sessions;
                            DELETE FROM price_progress;
                            DELETE FROM news_progress;
                            DELETE FROM rate_limits;
                            DELETE FROM failed_items;
                        ''')
                    print("âœ… Database Ù¾Ø§Ú© Ø´Ø¯")
                    logging.info("âœ… Database Ù¾Ø§Ú© Ø´Ø¯")
            
            elif state_choice == '4':
                # Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª Session
                session_id = input("Session ID Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ").strip()
                if session_id:
                    status = fetcher.state_manager.get_session_status(session_id)
                    if status:
                        print(f"\nğŸ“Š Ø¬Ø²Ø¦ÛŒØ§Øª Session: {session_id}")
                        print(f"   Ù†ÙˆØ¹: {status['session_type']}")
                        print(f"   ÙˆØ¶Ø¹ÛŒØª: {status['status']}")
                        print(f"   Ú©Ù„ Ù†Ù…Ø§Ø¯Ù‡Ø§: {status['total_symbols']}")
                        print(f"   Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {status['completed_symbols']}")
                        print(f"   Ù‚ÛŒÙ…Øª: {status['price_progress']['completed']}/{status['price_progress']['total']}")
                        print(f"   Ø§Ø®Ø¨Ø§Ø±: {status['news_progress']['completed']}/{status['news_progress']['total']}")
                    else:
                        print("âŒ Session ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            if state_choice != '5':
                input("\nEnter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")
        
        elif main_choice == '6':
            print("\nğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸! Simplified Data Fetcher Ø¨Ø³ØªÙ‡ Ø´Ø¯.")
            logging.info("--- Simplified Data Fetcher Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯ ---")
            break
        else:
            print("\nâŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±. Ù„Ø·ÙØ§Ù‹ Ø´Ù…Ø§Ø±Ù‡â€ŒØ§ÛŒ Ø¨ÛŒÙ† 1 ØªØ§ 6 ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
            input("Enter Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡...")

if __name__ == '__main__':
    main()