#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‡Ø³ØªÙ‡ Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ (Ù†Ø³Ø®Ù‡ 5.3 - Ø§ØµÙ„Ø§Ø­Ø§Øª Ù†Ù‡Ø§ÛŒÛŒ Ú©Ø§Ù…Ù„)

ğŸ”§ ØªØºÛŒÛŒØ±Ø§Øª Ù…Ù‡Ù… v5.3 (ØªØ±Ú©ÛŒØ¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§ØµÙ„Ø§Ø­Ø§Øª):
- âœ… Ú©Ø§Ù‡Ø´ threshold Ø¨Ù‡ 0.40 Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
- âœ… Ø±ÙØ¹ Ú©Ø§Ù…Ù„ Ù…Ø´Ú©Ù„ Ø§Ø±Ø³Ø§Ù„ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡ Ù¾ÛŒØ§Ù… Ø®Ø±ÙˆØ¬
- âœ… Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø¯ÛŒØ±ÛŒØª Rate Limiting Ø¨Ø§ Circuit Breaker
- âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† delay Ø¨ÛŒØ´ØªØ± Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
- âœ… Ø¨Ù‡Ø¨ÙˆØ¯ cleanup mechanism Ø¨Ø§ thread safety
- âœ… Ø§ØµÙ„Ø§Ø­ threshold detection Ø§Ø² API
- âœ… Ø±ÙØ¹ Ù…Ø´Ú©Ù„ 401 Authentication Error
- âœ… Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ API Ø¬Ø¯ÛŒØ¯ (Optimized Models)
- âœ… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù…Ù„ 58 ÙˆÛŒÚ˜Ú¯ÛŒ (Ø´Ø§Ù…Ù„ PSAR)

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:
- Risk Management Module Ú©Ø§Ù…Ù„
- Position Sizing Ø¨Ø§ Kelly Criterion  
- Dynamic Stop Loss Ùˆ Take Profit Ø¨Ø± Ø§Ø³Ø§Ø³ ATR
- Max Drawdown Protection
- Portfolio Heat Management
- Binance API Fallback Ø¨Ø§ retry mechanism
- Multi-source Data
- Commercial API Authentication Support
- Complete Feature Calculation (58 features)
"""

import os
import time
import pandas as pd
import requests
import logging
import configparser
import ccxt
import pandas_ta as ta
from typing import Optional, Dict, Any, List, Tuple
import datetime
import json
import glob
import numpy as np
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from collections import defaultdict
import signal
import sys
import atexit

# --- Ø¨Ø®Ø´ Û±: Ø®ÙˆØ§Ù†Ø¯Ù† Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
config = configparser.ConfigParser()
CONFIG_FILE_PATH = 'config.ini'
try:
    config.read(CONFIG_FILE_PATH, encoding='utf-8')

    LOG_PATH = config.get('Paths', 'logs')
    MODELS_PATH = config.get('Paths', 'models')
    FEATURES_PATH = config.get('Paths', 'features')
    API_HOST = config.get('API_Settings', 'host')
    API_PORT = config.getint('API_Settings', 'port')
    API_URL = f"http://{API_HOST}:{API_PORT}/predict"
    API_HEALTH_URL = f"http://{API_HOST}:{API_PORT}/health"
    API_MODEL_INFO_URL = f"http://{API_HOST}:{API_PORT}/model-info"
    
    CRYPTOCOMPARE_API_KEY = config.get('API_Keys', 'cryptocompare_api_key', fallback=None)

    # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø§Ù„Øª multi-pair
    MULTI_PAIR_ENABLED = config.getboolean('Bot_Settings', 'multi_pair_enabled', fallback=False)
    
    if MULTI_PAIR_ENABLED:
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ Ùˆ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
        PAIRS_TO_MONITOR = [p.strip() for p in config.get('Bot_Settings', 'pairs_to_monitor').split(',')]
        TIMEFRAMES_TO_MONITOR = [t.strip() for t in config.get('Bot_Settings', 'timeframes_to_monitor').split(',')]
        EXCHANGE_TO_USE = config.get('Bot_Settings', 'exchange_to_use')
    else:
        # Ø­Ø§Ù„Øª ØªÚ© Ø¬ÙØª Ø§Ø±Ø² (Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù†Ø³Ø®Ù‡ Ù‚Ø¨Ù„ÛŒ)
        EXCHANGE_TO_USE = config.get('Bot_Settings', 'exchange_to_use')
        SYMBOL_TO_TRADE = config.get('Bot_Settings', 'symbol_to_trade')
        TIMEFRAME_TO_TRADE = config.get('Bot_Settings', 'timeframe_to_trade')
        PAIRS_TO_MONITOR = [SYMBOL_TO_TRADE]
        TIMEFRAMES_TO_MONITOR = [TIMEFRAME_TO_TRADE]
    
    CANDLE_HISTORY_NEEDED = config.getint('Bot_Settings', 'candle_history_needed')
    
    # ğŸ”§ Ø§ÙØ²Ø§ÛŒØ´ poll interval Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ rate limiting
    POLL_INTERVAL_SECONDS = config.getint('Bot_Settings', 'poll_interval_seconds', fallback=300)
    if POLL_INTERVAL_SECONDS < 180:  # Ø­Ø¯Ø§Ù‚Ù„ 3 Ø¯Ù‚ÛŒÙ‚Ù‡
        POLL_INTERVAL_SECONDS = 180
        logging.warning(f"âš ï¸ Poll interval increased to {POLL_INTERVAL_SECONDS}s to prevent rate limiting")
    
    # ğŸ”§ Ú©Ø§Ù‡Ø´ threshold Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
    CONFIDENCE_THRESHOLD = config.getfloat('Bot_Settings', 'confidence_threshold', fallback=0.40)
    if CONFIDENCE_THRESHOLD > 0.50:  # Ø­Ø¯Ø§Ú©Ø«Ø± 50%
        CONFIDENCE_THRESHOLD = 0.40
        logging.warning(f"âš ï¸ Confidence threshold lowered to {CONFIDENCE_THRESHOLD:.0%} for more signals")
    
    # === ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Authentication Ø¬Ø¯ÛŒØ¯ ===
    try:
        # Authentication settings
        USE_AUTHENTICATION = config.getboolean('Bot_Authentication', 'use_authentication', fallback=True)
        API_USERNAME = config.get('Bot_Authentication', 'api_username', fallback='hasnamir92')
        API_PASSWORD = config.get('Bot_Authentication', 'api_password', fallback='123456')
        
        # Ø§Ú¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª authentication Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if not config.has_section('Bot_Authentication'):
            logging.warning("Bot_Authentication section not found in config. Using default credentials.")
            USE_AUTHENTICATION = True
            API_USERNAME = "hasnamir92"  # Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ Ú©Ù‡ Ø¯Ø± Ù„Ø§Ú¯ Ø¯ÛŒØ¯ÛŒÙ…
            API_PASSWORD = "123456"     # Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ - Ø¨Ø§ÛŒØ¯ ØªØºÛŒÛŒØ± Ú©Ù†Ø¯
            
    except Exception as e:
        logging.error(f"Error reading authentication config: {e}")
        # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        USE_AUTHENTICATION = True
        API_USERNAME = "hasnamir92"
        API_PASSWORD = "123456"
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…
    TELEGRAM_ENABLED = config.getboolean('Telegram', 'enabled', fallback=False)
    TELEGRAM_BOT_TOKEN = config.get('Telegram', 'bot_token', fallback=None)
    TELEGRAM_CHAT_ID = config.get('Telegram', 'chat_id', fallback=None)
    
    # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø§Ø² Feature_Engineering
    INDICATOR_PARAMS = {
        'rsi_length': config.getint('Feature_Engineering', 'rsi_length', fallback=14),
        'macd_fast': config.getint('Feature_Engineering', 'macd_fast', fallback=12),
        'macd_slow': config.getint('Feature_Engineering', 'macd_slow', fallback=26),
        'macd_signal': config.getint('Feature_Engineering', 'macd_signal', fallback=9),
        'bb_length': config.getint('Feature_Engineering', 'bb_length', fallback=20),
        'bb_std': config.getfloat('Feature_Engineering', 'bb_std', fallback=2.0),
        'atr_length': config.getint('Feature_Engineering', 'atr_length', fallback=14),
    }
    
    # === ØªÙ†Ø¸ÛŒÙ…Ø§Øª Risk Management Ø¬Ø¯ÛŒØ¯ ===
    MAX_POSITION_SIZE = config.getfloat('Risk_Management', 'max_position_size', fallback=0.25)
    STOP_LOSS_ATR_MULTIPLIER = config.getfloat('Risk_Management', 'stop_loss_atr_multiplier', fallback=2.0)
    TAKE_PROFIT_ATR_MULTIPLIER = config.getfloat('Risk_Management', 'take_profit_atr_multiplier', fallback=3.0)
    MAX_DAILY_DRAWDOWN = config.getfloat('Risk_Management', 'max_daily_drawdown', fallback=0.10)
    KELLY_CRITERION_ENABLED = config.getboolean('Risk_Management', 'kelly_criterion_enabled', fallback=True)

except Exception as e:
    print(f"CRITICAL ERROR: Could not read 'config.ini' or a required key is missing. Error: {e}")
    exit()

# --- Ø¨Ø®Ø´ Û²: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---
script_name = os.path.splitext(os.path.basename(__file__))[0]
log_subfolder_path = os.path.join(LOG_PATH, script_name)
os.makedirs(log_subfolder_path, exist_ok=True)

# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯ Ù…Ø®ØªÙ„Ù
log_filename = os.path.join(log_subfolder_path, f"log_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt")
signals_log = os.path.join(log_subfolder_path, f"signals_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json")
performance_log = os.path.join(log_subfolder_path, f"performance_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv")
risk_log = os.path.join(log_subfolder_path, f"risk_metrics_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler(log_filename, encoding='utf-8'), logging.StreamHandler()])

# Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§
signals_history = []

# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ø®Ø±ÛŒÙ† timestamp Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¬ÙØª
last_processed_timestamps = {}

# Lock Ø¨Ø±Ø§ÛŒ thread safety
signals_lock = threading.Lock()

# Ù…ØªØºÛŒØ± global Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„
api_model_info = {}

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ global Ø¨Ø±Ø§ÛŒ tracking
successful_predictions = 0
failed_attempts = 0
iteration_count = 0

# ğŸ”§ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ global Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡ Ù¾ÛŒØ§Ù… Ø®Ø±ÙˆØ¬
shutdown_message_sent = False
cleanup_in_progress = False
shutdown_lock = threading.Lock()

# --- Ø¨Ø®Ø´ Risk Management Ø¬Ø¯ÛŒØ¯ ---
@dataclass
class Position:
    """Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾ÙˆØ²ÛŒØ´Ù†"""
    symbol: str
    entry_price: float
    position_size: float
    stop_loss: float
    take_profit: float
    entry_time: datetime.datetime
    atr_at_entry: float
    confidence: float
    
class RiskManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ"""
    
    def __init__(self, initial_capital: float = 10000):
        self.initial_capital = initial_capital
        self.current_capital = initial_capital
        self.positions = {}  # ÙØ¹Ù„Ø§Ù‹ Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ
        self.daily_pnl = 0
        self.max_drawdown = 0
        self.win_rate_history = defaultdict(list)  # Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Kelly
        self.portfolio_heat = 0  # Ø¯Ø±ØµØ¯ Ú©Ù„ Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø¯Ø± Ø±ÛŒØ³Ú©
        self.daily_start_capital = initial_capital
        self.risk_metrics = {
            'total_trades': 0,
            'winning_trades': 0,
            'losing_trades': 0,
            'total_pnl': 0,
            'max_drawdown': 0,
            'sharpe_ratio': 0,
            'win_rate': 0,
            'avg_win': 0,
            'avg_loss': 0
        }
        logging.info(f"ğŸ’¼ Risk Manager initialized with capital: ${initial_capital}")
    
    def calculate_kelly_fraction(self, symbol: str) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Kelly Criterion Ø¨Ø±Ø§ÛŒ position sizing"""
        if not KELLY_CRITERION_ENABLED:
            return MAX_POSITION_SIZE
        
        history = self.win_rate_history.get(symbol, [])
        if len(history) < 10:  # Ø­Ø¯Ø§Ù‚Ù„ 10 Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ØªØ¨Ø±
            return MAX_POSITION_SIZE * 0.5  # Ù†ØµÙ Ø­Ø¯Ø§Ú©Ø«Ø± Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹
        
        wins = [h for h in history if h > 0]
        losses = [h for h in history if h < 0]
        
        if not wins or not losses:
            return MAX_POSITION_SIZE * 0.5
        
        win_rate = len(wins) / len(history)
        avg_win = np.mean(wins)
        avg_loss = abs(np.mean(losses))
        
        # Kelly formula: f = (p * b - q) / b
        # p = win rate, q = lose rate, b = win/loss ratio
        b = avg_win / avg_loss
        p = win_rate
        q = 1 - p
        
        kelly_fraction = (p * b - q) / b
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Kelly Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± 25% Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø±ÛŒØ³Ú© Ø¨Ø§Ù„Ø§
        kelly_fraction = max(0, min(kelly_fraction, MAX_POSITION_SIZE))
        
        logging.info(f"ğŸ“Š Kelly Fraction for {symbol}: {kelly_fraction:.2%} "
                    f"(Win Rate: {win_rate:.2%}, Avg Win/Loss: {b:.2f})")
        
        return kelly_fraction
    
    def calculate_position_size(self, symbol: str, confidence: float, 
                              current_price: float, atr: float) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù¾ÙˆØ²ÛŒØ´Ù† Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† Ø±ÛŒØ³Ú©"""
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª drawdown Ø±ÙˆØ²Ø§Ù†Ù‡
        if self.check_daily_drawdown_limit():
            logging.warning("âš ï¸ Daily drawdown limit reached. No new positions.")
            return 0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Kelly fraction
        kelly_fraction = self.calculate_kelly_fraction(symbol)
        
        # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ confidence
        confidence_multiplier = min(1.0, (confidence - CONFIDENCE_THRESHOLD) / (1 - CONFIDENCE_THRESHOLD))
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ position size Ù†Ù‡Ø§ÛŒÛŒ
        base_position_size = kelly_fraction * confidence_multiplier
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÛŒØ³Ú© Ø¨Ø± Ø§Ø³Ø§Ø³ ATR
        stop_loss_distance = atr * STOP_LOSS_ATR_MULTIPLIER
        risk_per_share = stop_loss_distance
        max_shares_by_risk = (self.current_capital * 0.02) / risk_per_share  # Ø­Ø¯Ø§Ú©Ø«Ø± 2% Ø±ÛŒØ³Ú©
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù‡Ø§ÛŒÛŒ
        position_value = self.current_capital * base_position_size
        shares = min(position_value / current_price, max_shares_by_risk)
        
        # Ø¨Ø±Ø±Ø³ÛŒ portfolio heat
        new_heat = self.calculate_portfolio_heat() + (shares * risk_per_share / self.current_capital)
        if new_heat > 0.06:  # Ø­Ø¯Ø§Ú©Ø«Ø± 6% portfolio heat
            logging.warning(f"âš ï¸ Portfolio heat too high ({new_heat:.1%}). Reducing position size.")
            shares *= (0.06 - self.calculate_portfolio_heat()) / (new_heat - self.calculate_portfolio_heat())
        
        logging.info(f"ğŸ“ Position Size for {symbol}: {shares:.2f} shares "
                    f"(${shares * current_price:.2f}) at ${current_price:.2f}")
        
        return shares
    
    def calculate_stop_loss(self, entry_price: float, atr: float, signal: str) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Stop Loss Ø¨Ø± Ø§Ø³Ø§Ø³ ATR"""
        if signal == "PROFIT":
            # Ø¨Ø±Ø§ÛŒ Ø®Ø±ÛŒØ¯ØŒ stop loss Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯
            stop_loss = entry_price - (atr * STOP_LOSS_ATR_MULTIPLIER)
        else:
            # Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´ØŒ stop loss Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯
            stop_loss = entry_price + (atr * STOP_LOSS_ATR_MULTIPLIER)
        
        return round(stop_loss, 2)
    
    def calculate_take_profit(self, entry_price: float, atr: float, signal: str) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Take Profit Ø¨Ø± Ø§Ø³Ø§Ø³ ATR"""
        if signal == "PROFIT":
            # Ø¨Ø±Ø§ÛŒ Ø®Ø±ÛŒØ¯ØŒ take profit Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯
            take_profit = entry_price + (atr * TAKE_PROFIT_ATR_MULTIPLIER)
        else:
            # Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´ØŒ take profit Ø²ÛŒØ± Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯
            take_profit = entry_price - (atr * TAKE_PROFIT_ATR_MULTIPLIER)
        
        return round(take_profit, 2)
    
    def check_daily_drawdown_limit(self) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª drawdown Ø±ÙˆØ²Ø§Ù†Ù‡"""
        daily_loss = (self.daily_start_capital - self.current_capital) / self.daily_start_capital
        return daily_loss >= MAX_DAILY_DRAWDOWN
    
    def calculate_portfolio_heat(self) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¬Ù…ÙˆØ¹ Ø±ÛŒØ³Ú© ÙØ¹Ù„ÛŒ Ù¾ÙˆØ±ØªÙÙˆÙ„ÛŒÙˆ"""
        total_risk = 0
        for position in self.positions.values():
            risk = abs(position.entry_price - position.stop_loss) * position.position_size
            total_risk += risk
        
        self.portfolio_heat = total_risk / self.current_capital
        return self.portfolio_heat
    
    def update_performance_metrics(self, symbol: str, pnl: float):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯"""
        self.risk_metrics['total_trades'] += 1
        
        if pnl > 0:
            self.risk_metrics['winning_trades'] += 1
        else:
            self.risk_metrics['losing_trades'] += 1
        
        self.risk_metrics['total_pnl'] += pnl
        self.daily_pnl += pnl
        self.current_capital += pnl
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ win rate history
        self.win_rate_history[symbol].append(pnl)
        if len(self.win_rate_history[symbol]) > 100:  # Ø­Ø¯Ø§Ú©Ø«Ø± 100 Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø§Ø®ÛŒØ±
            self.win_rate_history[symbol].pop(0)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        if self.risk_metrics['total_trades'] > 0:
            self.risk_metrics['win_rate'] = self.risk_metrics['winning_trades'] / self.risk_metrics['total_trades']
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ max drawdown
        drawdown = (self.initial_capital - self.current_capital) / self.initial_capital
        self.risk_metrics['max_drawdown'] = max(self.risk_metrics['max_drawdown'], drawdown)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        self.save_risk_metrics()
    
    def save_risk_metrics(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø±ÛŒØ³Ú©"""
        try:
            with open(risk_log, 'w') as f:
                json.dump({
                    'timestamp': datetime.datetime.now().isoformat(),
                    'current_capital': self.current_capital,
                    'daily_pnl': self.daily_pnl,
                    'portfolio_heat': self.portfolio_heat,
                    'metrics': self.risk_metrics
                }, f, indent=2)
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ risk metrics: {e}")
    
    def reset_daily_metrics(self):
        """Ø±ÛŒØ³Øª Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
        self.daily_pnl = 0
        self.daily_start_capital = self.current_capital
        logging.info(f"ğŸ“… Daily metrics reset. Starting capital: ${self.current_capital:.2f}")
    
    def get_risk_report(self) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø±ÛŒØ³Ú©"""
        report = f"""
ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©
========================
ğŸ’° Ø³Ø±Ù…Ø§ÛŒÙ‡ ÙØ¹Ù„ÛŒ: ${self.current_capital:.2f}
ğŸ“ˆ Ø³ÙˆØ¯/Ø²ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡: ${self.daily_pnl:.2f} ({self.daily_pnl/self.daily_start_capital*100:.1f}%)
ğŸ”¥ Portfolio Heat: {self.portfolio_heat:.1%}
ğŸ“‰ Max Drawdown: {self.risk_metrics['max_drawdown']:.1%}
ğŸ¯ Win Rate: {self.risk_metrics['win_rate']:.1%}
ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {self.risk_metrics['total_trades']}
âœ… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø±Ù†Ø¯Ù‡: {self.risk_metrics['winning_trades']}
âŒ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§Ø²Ù†Ø¯Ù‡: {self.risk_metrics['losing_trades']}
ğŸ’µ Ù…Ø¬Ù…ÙˆØ¹ Ø³ÙˆØ¯/Ø²ÛŒØ§Ù†: ${self.risk_metrics['total_pnl']:.2f}
"""
        return report

# Ø§ÛŒØ¬Ø§Ø¯ instance Ø§Ø² Risk Manager
risk_manager = RiskManager()

# === ğŸ”§ ØªÙˆØ§Ø¨Ø¹ cleanup Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… ===
def cleanup_and_shutdown():
    """ØªØ§Ø¨Ø¹ cleanup Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ù‚Ø·Ø¹ Ø§Ø±ØªØ¨Ø§Ø· Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø± - Ø§ØµÙ„Ø§Ø­ Ú©Ø§Ù…Ù„"""
    global successful_predictions, failed_attempts, iteration_count, shutdown_message_sent, cleanup_in_progress
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² lock Ø¨Ø±Ø§ÛŒ thread safety
    with shutdown_lock:
        # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡
        if cleanup_in_progress or shutdown_message_sent:
            return
        
        cleanup_in_progress = True
        
        try:
            logging.info("ğŸ”„ Starting cleanup and shutdown process...")
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø®Ø±ÙˆØ¬
            save_performance_metrics()
            risk_manager.save_risk_metrics()
            
            # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø®Ø§Ù…ÙˆØ´ Ø´Ø¯Ù† (ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø±)
            if TELEGRAM_ENABLED and not shutdown_message_sent:
                shutdown_message_sent = True  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ù…Ø¬Ø¯Ø¯
                
                total_attempts = successful_predictions + failed_attempts
                final_risk_report = risk_manager.get_risk_report()
                
                shutdown_message = f"""
ğŸ›‘ <b>Ø±Ø¨Ø§Øª Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ v5.3 Ù…ØªÙˆÙ‚Ù Ø´Ø¯</b>

ğŸ“Š <b>Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:</b>
â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§: {iteration_count}
â€¢ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØµØ§Ø¯Ø± Ø´Ø¯Ù‡: {len(signals_history)}
â€¢ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: {(successful_predictions / total_attempts * 100) if total_attempts > 0 else 0:.1f}%

ğŸ¤– <b>Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡:</b>
{api_model_info.get('model_type', 'Unknown')} {'(Optimized)' if api_model_info.get('is_optimized') else ''}

ğŸ” <b>Authentication:</b>
User: {API_USERNAME} {'(Success)' if USE_AUTHENTICATION else '(Disabled)'}

âš™ï¸ <b>ØªÙ†Ø¸ÛŒÙ…Ø§Øª v5.3:</b>
â€¢ Threshold: {CONFIDENCE_THRESHOLD:.0%} (Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡)
â€¢ Poll Interval: {POLL_INTERVAL_SECONDS}s (Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØªÙ‡)

{final_risk_report}

ğŸ• {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

#BotStopped #v5_3 #FinalVersion #ThresholdOptimized
"""
                try:
                    send_telegram_message(shutdown_message)
                    logging.info("ğŸ“± Shutdown message sent to Telegram successfully")
                except Exception as telegram_error:
                    logging.error(f"Error sending shutdown message: {telegram_error}")
            
            logging.info("âœ… Cleanup completed successfully")
        except Exception as e:
            logging.error(f"Error during cleanup: {e}", exc_info=True)
        finally:
            cleanup_in_progress = False

def signal_handler(sig, frame):
    """Handle Ctrl+C gracefully"""
    logging.info("\nâ›” Received shutdown signal (Ctrl+C)")
    print("\nâ›” Shutting down gracefully...")
    cleanup_and_shutdown()
    sys.exit(0)

# Ø«Ø¨Øª cleanup Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø®Ø±ÙˆØ¬
atexit.register(cleanup_and_shutdown)

# === ğŸ”§ Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: Authentication Check ===
def check_authentication():
    """Ø¨Ø±Ø±Ø³ÛŒ Authentication Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª"""
    if not USE_AUTHENTICATION:
        logging.info("ğŸ”“ Authentication disabled - running in legacy mode")
        return True
    
    try:
        # ØªØ³Øª Ø³Ø§Ø¯Ù‡ authentication Ø¨Ø§ health endpoint
        logging.info(f"ğŸ” Testing authentication with username: {API_USERNAME}")
        
        test_response = requests.get(
            API_HEALTH_URL, 
            timeout=5,
            auth=(API_USERNAME, API_PASSWORD)
        )
        
        if test_response.status_code == 200:
            logging.info("âœ… Authentication test successful")
            return True
        elif test_response.status_code == 401:
            logging.error("âŒ Authentication test failed - Invalid credentials")
            logging.error(f"ğŸ’¡ Username: {API_USERNAME}")
            logging.error("ğŸ’¡ Please update Bot_Authentication section in config.ini")
            return False
        else:
            logging.warning(f"âš ï¸ Unexpected response: {test_response.status_code}")
            return False
            
    except Exception as e:
        logging.error(f"âŒ Authentication test error: {e}")
        return False

# === Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: API Health Check Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ ===
def check_api_health():
    """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª API Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡)"""
    global api_model_info
    
    try:
        # Health check Ø¨Ø§ timeout Ø¨ÛŒØ´ØªØ±
        logging.info(f"ğŸ” Checking API health at {API_HEALTH_URL}")
        
        # ğŸ”§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Authentication Ø§Ú¯Ø± ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ø¯
        if USE_AUTHENTICATION:
            health_response = requests.get(API_HEALTH_URL, timeout=10, auth=(API_USERNAME, API_PASSWORD))
        else:
            health_response = requests.get(API_HEALTH_URL, timeout=10)
        
        # Ù„Ø§Ú¯ response Ø¨Ø±Ø§ÛŒ debugging
        logging.info(f"ğŸ“¡ API Response Status: {health_response.status_code}")
        
        if health_response.status_code == 200:
            health_data = health_response.json()
            
            if health_data.get('status') == 'healthy':
                logging.info("âœ… API Health Check: Healthy")
                
                # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„
                if 'model_info' in health_data:
                    api_model_info = health_data['model_info']
                    model_type = api_model_info.get('model_type', 'Unknown')
                    threshold = api_model_info.get('optimal_threshold', 0.5)
                    is_optimized = api_model_info.get('is_optimized', False)
                    
                    logging.info(f"ğŸ¤– Model Type: {model_type}")
                    logging.info(f"ğŸ¯ Model Optimal Threshold: {threshold:.4f}")
                    logging.info(f"âš¡ Optimized Model: {'Yes' if is_optimized else 'No'}")
                    
                    # ğŸ”§ ØªØ·Ø¨ÛŒÙ‚ threshold Ø¨Ø§ Ù…Ø¯Ù„ (Ø§Ú¯Ø± Ø®ÛŒÙ„ÛŒ Ø¨Ø§Ù„Ø§ Ø¨Ø§Ø´Ø¯)
                    global CONFIDENCE_THRESHOLD
                    if threshold > 0.60 and CONFIDENCE_THRESHOLD > 0.50:
                        old_threshold = CONFIDENCE_THRESHOLD
                        CONFIDENCE_THRESHOLD = 0.40  # Ú©Ø§Ù‡Ø´ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
                        logging.warning(f"ğŸ”§ Model threshold ({threshold:.4f}) is high. ")
                        logging.warning(f"ğŸ”§ Bot threshold adjusted: {old_threshold:.0%} â†’ {CONFIDENCE_THRESHOLD:.0%}")
                    
                    # Ù†Ù…Ø§ÛŒØ´ performance Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
                    performance = api_model_info.get('performance')
                    if performance and performance.get('accuracy'):
                        logging.info(f"ğŸ“Š Model Performance: Accuracy={performance['accuracy']:.1%}, "
                                   f"Precision={performance['precision']:.1%}, "
                                   f"Recall={performance['recall']:.1%}")
                
                return True
            else:
                logging.error("âŒ API Health Check: Unhealthy")
                logging.error(f"ğŸ“‹ Health response: {health_data}")
                return False
                
        elif health_response.status_code == 401:
            # Ø®Ø·Ø§ÛŒ Authentication
            logging.error("âŒ API Health Check failed: 401 Authentication Error")
            logging.error(f"ğŸ’¡ Current credentials: {API_USERNAME} / [password hidden]")
            logging.error("ğŸ’¡ Please check Bot_Authentication section in config.ini")
            return False
        elif health_response.status_code == 500:
            # Ø®Ø·Ø§ÛŒ Ø³Ø±ÙˆØ± - ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§
            try:
                error_data = health_response.json()
                logging.error(f"âŒ API Health Check failed (HTTP 500): {error_data}")
            except:
                error_text = health_response.text[:200]  # Ø§ÙˆÙ„ 200 Ú©Ø§Ø±Ø§Ú©ØªØ±
                logging.error(f"âŒ API Health Check failed (HTTP 500): {error_text}")
            return False
        else:
            logging.error(f"âŒ API Health Check failed: HTTP {health_response.status_code}")
            try:
                response_text = health_response.text[:200]
                logging.error(f"ğŸ“‹ Response: {response_text}")
            except:
                pass
            return False
            
    except requests.exceptions.ConnectionError as e:
        logging.error(f"âŒ Connection Error: API server not reachable - {e}")
        return False
    except requests.exceptions.Timeout as e:
        logging.error(f"âŒ Timeout Error: API server too slow - {e}")
        return False
    except Exception as e:
        logging.error(f"âŒ API Health Check error: {e}")
        return False

# === Ø§ØµÙ„Ø§Ø­ Ø¨Ø®Ø´ test API connection ===
def test_api_connection():
    """ØªØ³Øª Ø§ØªØµØ§Ù„ API Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±"""
    print("\nğŸ” Testing API Connection...")
    
    # ØªØ³Øª endpoint Ø§ØµÙ„ÛŒ
    try:
        response = requests.get(f"http://{API_HOST}:{API_PORT}/", timeout=10)
        if response.status_code == 200:
            print(f"âœ… Main endpoint accessible: {response.text[:50]}...")
        else:
            print(f"âš ï¸ Main endpoint returned: {response.status_code}")
    except Exception as e:
        print(f"âŒ Main endpoint failed: {e}")
    
    # ØªØ³Øª health endpoint
    try:
        if USE_AUTHENTICATION:
            response = requests.get(f"http://{API_HOST}:{API_PORT}/health", timeout=10, auth=(API_USERNAME, API_PASSWORD))
        else:
            response = requests.get(f"http://{API_HOST}:{API_PORT}/health", timeout=10)
            
        print(f"ğŸ“Š Health endpoint status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Health check successful: {data.get('status')}")
            return True
        elif response.status_code == 401:
            print(f"âŒ Authentication error in health endpoint")
            print(f"ğŸ’¡ Username: {API_USERNAME}")
            print(f"ğŸ’¡ Check config.ini [Bot_Authentication] section")
        elif response.status_code == 500:
            print(f"âŒ Server error in health endpoint")
            try:
                error_data = response.json()
                print(f"ğŸ“‹ Error details: {error_data}")
            except:
                print(f"ğŸ“‹ Error text: {response.text[:200]}")
        else:
            print(f"âš ï¸ Unexpected status: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ Health endpoint test failed: {e}")
    
    return False

# --- Ø¨Ø®Ø´ Û³: ØªÙˆØ§Ø¨Ø¹ ØªÙ„Ú¯Ø±Ø§Ù… (Ø¨Ø§ Ø§ÙØ²ÙˆØ¯Ù† Ú¯Ø²Ø§Ø±Ø´ Ø±ÛŒØ³Ú©) ---
def send_telegram_message(message: str) -> bool:
    """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…"""
    if not TELEGRAM_ENABLED:
        return False
    
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        logging.warning("ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ù†Ø§Ù‚Øµ Ø§Ø³Øª. Ù¾ÛŒØ§Ù… Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯.")
        return False
    
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        data = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": message,
            "parse_mode": "HTML"
        }
        
        response = requests.post(url, data=data, timeout=10)
        response.raise_for_status()
        
        if response.json().get('ok'):
            logging.info("Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.")
            return True
        else:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {response.json()}")
            return False
            
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {e}")
        return False

def format_telegram_message(symbol: str, timeframe: str, signal: str, confidence: float, 
                          exchange: str, position_size: float = None, stop_loss: float = None, 
                          take_profit: float = None, threshold_used: float = None) -> str:
    """ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
    emoji_signal = "ğŸŸ¢" if signal == "PROFIT" else "ğŸ”´"
    emoji_confidence = "ğŸ”¥" if confidence >= 0.8 else "âœ…" if confidence >= 0.7 else "âš¡"
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„
    model_type = api_model_info.get('model_type', 'Unknown')
    is_optimized = api_model_info.get('is_optimized', False)
    model_accuracy = api_model_info.get('performance', {}).get('accuracy')
    
    message = f"""
{emoji_signal} <b>Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¬Ø¯ÛŒØ¯ Ø§Ø² Ø±Ø¨Ø§Øª Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ v5.3</b> {emoji_signal}

ğŸ“Š <b>Ù†Ù…Ø§Ø¯:</b> {symbol}
â± <b>ØªØ§ÛŒÙ… ÙØ±ÛŒÙ…:</b> {timeframe}
ğŸ¦ <b>ØµØ±Ø§ÙÛŒ:</b> {exchange.upper()}
ğŸ“ˆ <b>Ø³ÛŒÚ¯Ù†Ø§Ù„:</b> <b>{signal}</b>
{emoji_confidence} <b>Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:</b> {confidence:.1%}
ğŸ¯ <b>Ø¢Ø³ØªØ§Ù†Ù‡ Ø±Ø¨Ø§Øª:</b> {CONFIDENCE_THRESHOLD:.0%}
"""

    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
    if threshold_used:
        threshold_emoji = "âš¡" if is_optimized else "ğŸ”§"
        message += f"""
ğŸ¤– <b>Ù…Ø¯Ù„:</b> {model_type[:20]}{'...' if len(model_type) > 20 else ''}
{threshold_emoji} <b>Threshold Ù…Ø¯Ù„:</b> {threshold_used:.3f} {'(Optimized)' if is_optimized else '(Default)'}
"""
    
    if model_accuracy:
        message += f"ğŸ“Š <b>Ø¯Ù‚Øª Ù…Ø¯Ù„:</b> {model_accuracy:.1%}\n"
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Authentication
    auth_emoji = "ğŸ”" if USE_AUTHENTICATION else "ğŸ”“"
    message += f"{auth_emoji} <b>Auth:</b> {API_USERNAME if USE_AUTHENTICATION else 'Disabled'}\n"
    
    # Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Risk Management
    if position_size is not None:
        message += f"""
ğŸ’¼ <b>Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©:</b>
   ğŸ“ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù¾ÙˆØ²ÛŒØ´Ù†: {position_size:.2f} ÙˆØ§Ø­Ø¯
   ğŸ›‘ Ø­Ø¯ Ø¶Ø±Ø±: ${stop_loss:.2f}
   âœ… Ø­Ø¯ Ø³ÙˆØ¯: ${take_profit:.2f}
   ğŸ”¥ Portfolio Heat: {risk_manager.portfolio_heat:.1%}
"""
    
    # Ù†Ù…Ø§ÛŒØ´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
    message += f"""
âš™ï¸ <b>ØªÙ†Ø¸ÛŒÙ…Ø§Øª v5.3:</b>
   ğŸ”„ Poll Interval: {POLL_INTERVAL_SECONDS}s (Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØªÙ‡)
   ğŸ¯ Threshold: {CONFIDENCE_THRESHOLD:.0%} (Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡)
   ğŸ“Š ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: 58 (Ú©Ø§Ù…Ù„)

ğŸ• <b>Ø²Ù…Ø§Ù†:</b> {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

#SmartAdvisor #CryptoSignal #{symbol.replace('/', '')} #{timeframe} #v5_3 #FinalVersion
"""
    return message

# --- Ø¨Ø®Ø´ Û´: ØªÙˆØ§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ ---
def load_model_features() -> Optional[List[str]]:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÛŒØ³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ù…Ø¯Ù„"""
    try:
        # Ø³Ø¹ÛŒ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² API
        try:
            if USE_AUTHENTICATION:
                response = requests.get(API_MODEL_INFO_URL, timeout=5, auth=(API_USERNAME, API_PASSWORD))
            else:
                response = requests.get(API_MODEL_INFO_URL, timeout=5)
                
            if response.status_code == 200:
                model_info = response.json()
                feature_columns = model_info.get('model_info', {}).get('feature_columns', [])
                if feature_columns:
                    logging.info(f"âœ… Model features from API: {len(feature_columns)} features")
                    return feature_columns
        except:
            logging.warning("Could not get features from API, trying local files...")
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ
        list_of_files = glob.glob(os.path.join(MODELS_PATH, 'feature_names_optimized_*.txt'))
        if not list_of_files:
            list_of_files = glob.glob(os.path.join(MODELS_PATH, 'feature_names_*.txt'))
        
        if not list_of_files:
            # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ run_*
            list_of_files = glob.glob(os.path.join(MODELS_PATH, 'run_*/feature_names_*.txt'))
        
        if not list_of_files:
            logging.warning("ÙØ§ÛŒÙ„ feature_names ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø±Ø¨Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.")
            return None
        
        latest_file = max(list_of_files, key=os.path.getctime)
        with open(latest_file, 'r', encoding='utf-8') as f:
            feature_names = [line.strip() for line in f if line.strip()]
        
        logging.info(f"âœ… Ù„ÛŒØ³Øª {len(feature_names)} ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ø² '{os.path.basename(latest_file)}' Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return feature_names
        
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ feature_names: {e}")
        return None

def verify_feature_consistency(calculated_features: Dict[str, Any], expected_features: List[str]) -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ ØªØ·Ø§Ø¨Ù‚ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§ Ø§Ù†ØªØ¸Ø§Ø±Ø§Øª Ù…Ø¯Ù„"""
    missing_features = []
    for feature in expected_features:
        if feature not in calculated_features:
            missing_features.append(feature)
    
    if missing_features:
        logging.error(f"âŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú¯Ù…Ø´Ø¯Ù‡: {missing_features}")
        return False
    
    logging.info(f"âœ… ØªÙ…Ø§Ù… {len(expected_features)} ÙˆÛŒÚ˜Ú¯ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.")
    return True

# --- Ø¨Ø®Ø´ Ûµ: ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ (Ø¨Ø§ Ø§ØµÙ„Ø§Ø­ Ù…Ø´Ú©Ù„ Binance API Ùˆ circuit breaker) ---
def fetch_from_cryptocompare_api(symbol: str, timeframe: str, limit: int) -> Optional[pd.DataFrame]:
    """ØªØ§Ø¨Ø¹ Ø§Ø®ØªØµØ§ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² CryptoCompare API."""
    logging.info("Using dedicated function for CryptoCompare...")
    BASE_URL = "https://min-api.cryptocompare.com/data/v2/"
    endpoint_map = {'m': 'histominute', 'h': 'histohour', 'd': 'histoday'}
    
    try:
        tf_unit = timeframe.lower()[-1]
        tf_agg = int(timeframe[:-1])
        endpoint = endpoint_map.get(tf_unit)
        if not endpoint: raise ValueError("Timeframe not recognized for CryptoCompare.")
        base_sym, quote_sym = symbol.upper().split('/')
    except Exception as e:
        logging.error(f"[CryptoCompare] Invalid symbol/timeframe format: {e}")
        return None
    
    params = {"fsym": base_sym, "tsym": quote_sym, "limit": limit, "aggregate": tf_agg}
    if CRYPTOCOMPARE_API_KEY:
        params["api_key"] = CRYPTOCOMPARE_API_KEY
    
    try:
        response = requests.get(f"{BASE_URL}{endpoint}", params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        if data.get('Response') == 'Error':
            logging.error(f"[CryptoCompare] API Error: {data.get('Message', 'Unknown error')}")
            return None
        
        df = pd.DataFrame(data['Data']['Data'])
        if df.empty: return None
        
        df.rename(columns={'volumefrom': 'volume'}, inplace=True)
        df['timestamp'] = pd.to_datetime(df['time'], unit='s')
        return df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]

    except Exception as e:
        logging.error(f"[CryptoCompare] Failed to fetch data: {e}")
        return None

def get_latest_data(symbol: str, timeframe: str, limit: int, exchange_name: str) -> Optional[pd.DataFrame]:
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ø­Ù„ Ù…Ø´Ú©Ù„ Binance API Ùˆ circuit breaker
    """
    logging.info(f"Attempting to fetch data from: {exchange_name.upper()} for {symbol} {timeframe}")
    
    if exchange_name.lower() == 'cryptocompare':
        return fetch_from_cryptocompare_api(symbol, timeframe, limit)
    else:
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Binance
            if exchange_name.lower() == 'binance':
                exchange = ccxt.binance({
                    'timeout': 30000,  # 30 Ø«Ø§Ù†ÛŒÙ‡ timeout
                    'rateLimit': 1500,  # ğŸ”§ Ø§ÙØ²Ø§ÛŒØ´ rate limit delay
                    'enableRateLimit': True,
                    'options': {
                        'defaultType': 'spot'  # Ù…Ø´Ø®Øµ Ú©Ø±Ø¯Ù† Ù†ÙˆØ¹ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
                    }
                })
            else:
                exchange_class = getattr(ccxt, exchange_name)
                exchange = exchange_class({
                    'timeout': 30000,
                    'rateLimit': 2000,  # ğŸ”§ Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§
                    'enableRateLimit': True
                })
            
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ retry mechanism Ùˆ circuit breaker
            max_retries = 3
            base_delay = 2
            
            for attempt in range(max_retries):
                try:
                    # ğŸ”§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† delay Ù‚Ø¨Ù„ Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øª
                    if attempt > 0:
                        delay_time = base_delay ** attempt  # exponential backoff
                        logging.info(f"â³ Waiting {delay_time}s before retry (attempt {attempt + 1})...")
                        time.sleep(delay_time)
                    
                    ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
                    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    
                    if len(df) < limit // 2:  # Ø§Ú¯Ø± Ø®ÛŒÙ„ÛŒ Ú©Ù… Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯
                        logging.warning(f"Data received ({len(df)}) is less than expected ({limit}).")
                        if attempt < max_retries - 1:
                            logging.info(f"Retrying... (attempt {attempt + 2}/{max_retries})")
                            continue
                    
                    logging.info(f"Successfully fetched {len(df)} candles from {exchange_name.upper()}")
                    return df
                    
                except ccxt.RateLimitExceeded as rate_error:
                    logging.warning(f"âš ï¸ Rate limit exceeded on attempt {attempt + 1}: {rate_error}")
                    if attempt < max_retries - 1:
                        delay_time = 90  # 1.5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ rate limit
                        logging.info(f"â³ Rate limit cooldown: waiting {delay_time}s...")
                        time.sleep(delay_time)
                        continue
                    else:
                        logging.error("âŒ Rate limit exceeded - falling back to CryptoCompare")
                        return fetch_from_cryptocompare_api(symbol, timeframe, limit)
                        
                except ccxt.NetworkError as network_error:
                    logging.warning(f"ğŸŒ Network error on attempt {attempt + 1}: {network_error}")
                    if attempt < max_retries - 1:
                        delay_time = base_delay ** (attempt + 1)
                        logging.info(f"â³ Network error cooldown: waiting {delay_time}s...")
                        time.sleep(delay_time)
                        continue
                    else:
                        logging.error("âŒ Network error persists - falling back to CryptoCompare")
                        return fetch_from_cryptocompare_api(symbol, timeframe, limit)
                        
                except Exception as attempt_error:
                    logging.warning(f"Attempt {attempt + 1} failed: {attempt_error}")
                    if attempt < max_retries - 1:
                        continue
                    else:
                        raise attempt_error
            
        except AttributeError:
            logging.error(f"Exchange '{exchange_name}' is not supported by CCXT.")
        except ccxt.BaseError as e:
            logging.error(f"Exchange error from {exchange_name.upper()}: {e}")
            # Ø§Ú¯Ø± Binance Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ fallback Ø¨Ù‡ CryptoCompare
            if exchange_name.lower() == 'binance':
                logging.info("ğŸ”„ Fallback to CryptoCompare due to exchange error...")
                return fetch_from_cryptocompare_api(symbol, timeframe, limit)
        except Exception as e:
            logging.error(f"Unexpected error fetching data from {exchange_name.upper()}: {e}")
            # Ø§Ú¯Ø± Binance Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ fallback Ø¨Ù‡ CryptoCompare
            if exchange_name.lower() == 'binance':
                logging.info("ğŸ”„ Fallback to CryptoCompare due to connection issues...")
                return fetch_from_cryptocompare_api(symbol, timeframe, limit)
        
        return None

def calculate_features(df: pd.DataFrame) -> Optional[Dict[str, Any]]:
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ 58 ÙˆÛŒÚ˜Ú¯ÛŒ - Ø¢ÛŒÙ†Ù‡ Ú©Ø§Ù…Ù„ Ø§Ø² Ø§Ø³Ú©Ø±ÛŒÙ¾Øª 03 Ø¨Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† ATR"""
    try:
        group = df.copy()
        
        # ğŸ”§ Ø§ØµÙ„Ø§Ø­ Ù…Ø´Ú©Ù„ dtype - ØªØ¨Ø¯ÛŒÙ„ volume Ø¨Ù‡ float64
        group['volume'] = group['volume'].astype('float64')
        group['high'] = group['high'].astype('float64')
        group['low'] = group['low'].astype('float64')
        group['close'] = group['close'].astype('float64')
        group['open'] = group['open'].astype('float64')
        
        # Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ config
        group['rsi'] = ta.rsi(group['close'], length=INDICATOR_PARAMS['rsi_length'])
        
        macd = ta.macd(group['close'], 
                      fast=INDICATOR_PARAMS['macd_fast'], 
                      slow=INDICATOR_PARAMS['macd_slow'], 
                      signal=INDICATOR_PARAMS['macd_signal'])
        if macd is not None and not macd.empty:
            col_names = macd.columns.tolist()
            group['macd'] = macd[col_names[0]]
            group['macd_hist'] = macd[col_names[1]]
            group['macd_signal'] = macd[col_names[2]]
        
        bbands = ta.bbands(group['close'], 
                          length=INDICATOR_PARAMS['bb_length'], 
                          std=INDICATOR_PARAMS['bb_std'])
        if bbands is not None and not bbands.empty:
            col_names = bbands.columns.tolist()
            group['bb_upper'] = bbands[col_names[0]]
            group['bb_middle'] = bbands[col_names[1]]
            group['bb_lower'] = bbands[col_names[2]]
            group['bb_position'] = (group['close'] - group['bb_lower']) / (group['bb_upper'] - group['bb_lower'])
        
        group['atr'] = ta.atr(group['high'], group['low'], group['close'], 
                             length=INDICATOR_PARAMS['atr_length'])
        group['atr_percent'] = (group['atr'] / group['close']) * 100
        
        # Ø¨Ù‚ÛŒÙ‡ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù…Ø·Ø§Ø¨Ù‚ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª 03
        group['price_change'] = group['close'].pct_change()
        group['volatility'] = group['price_change'].rolling(window=20).std() * 100
        
        typical_price = (group['high'] + group['low'] + group['close']) / 3
        vwap_numerator = (typical_price * group['volume']).cumsum()
        vwap_denominator = group['volume'].cumsum()
        group['vwap'] = vwap_numerator / vwap_denominator
        group['vwap_deviation'] = ((group['close'] - group['vwap']) / group['vwap']) * 100
        
        group['obv'] = ta.obv(group['close'], group['volume'])
        group['obv_change'] = group['obv'].pct_change()
        
        # ğŸ”§ Ø§ØµÙ„Ø§Ø­ Ú©Ø§Ù…Ù„ MFI calculation
        try:
            # ØªØ¨Ø¯ÛŒÙ„ ØµØ±ÛŒØ­ Ø§Ù†ÙˆØ§Ø¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ MFI
            high_values = group['high'].astype('float64')
            low_values = group['low'].astype('float64') 
            close_values = group['close'].astype('float64')
            volume_values = group['volume'].astype('float64')
            
            group['mfi'] = ta.mfi(high_values, low_values, close_values, volume_values, length=14)
        except Exception as mfi_error:
            logging.warning(f"MFI calculation failed: {mfi_error}. Using default value.")
            group['mfi'] = 50.0  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        
        group['ad'] = ta.ad(group['high'], group['low'], group['close'], group['volume'])
        
        stoch = ta.stoch(group['high'], group['low'], group['close'], k=14, d=3, smooth_k=3)
        if stoch is not None and not stoch.empty:
            col_names = stoch.columns.tolist()
            group['stoch_k'] = stoch[col_names[0]]
            group['stoch_d'] = stoch[col_names[1]]
        
        group['williams_r'] = ta.willr(group['high'], group['low'], group['close'], length=14)
        group['cci'] = ta.cci(group['high'], group['low'], group['close'], length=20)
        
        group['ema_short'] = ta.ema(group['close'], length=12)
        group['ema_medium'] = ta.ema(group['close'], length=26)
        group['ema_long'] = ta.ema(group['close'], length=50)
        group['ema_short_above_medium'] = (group['ema_short'] > group['ema_medium']).astype(int)
        group['ema_medium_above_long'] = (group['ema_medium'] > group['ema_long']).astype(int)
        group['ema_short_slope'] = group['ema_short'].pct_change(periods=5)
        group['ema_medium_slope'] = group['ema_medium'].pct_change(periods=5)
        
        group['sma_short'] = ta.sma(group['close'], 10)
        group['sma_medium'] = ta.sma(group['close'], 20)
        group['sma_long'] = ta.sma(group['close'], 50)
        group['price_above_sma_short'] = (group['close'] > group['sma_short']).astype(int)
        group['price_above_sma_medium'] = (group['close'] > group['sma_medium']).astype(int)
        group['price_above_sma_long'] = (group['close'] > group['sma_long']).astype(int)
        
        group['return_1'] = group['close'].pct_change(1)
        group['return_5'] = group['close'].pct_change(5)
        group['return_10'] = group['close'].pct_change(10)
        group['avg_return_5'] = group['return_1'].rolling(5).mean()
        group['avg_return_10'] = group['return_1'].rolling(10).mean()
        
        group['hl_ratio'] = (group['high'] - group['low']) / group['close']
        group['close_position'] = (group['close'] - group['low']) / (group['high'] - group['low'])
        group['volume_ma'] = group['volume'].rolling(20).mean()
        group['volume_ratio'] = group['volume'] / group['volume_ma']
        
        # ğŸ”§ PSAR - Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù…Ù„ 58 ÙˆÛŒÚ˜Ú¯ÛŒ
        try:
            psar_result = ta.psar(group['high'], group['low'], group['close'])
            if psar_result is not None and not psar_result.empty:
                if isinstance(psar_result, pd.DataFrame):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ long Ùˆ short
                    psar_long = psar_result.iloc[:, 0]  # PSARl_0.02_0.2
                    psar_short = psar_result.iloc[:, 1]  # PSARs_0.02_0.2
                    
                    # ØªØ±Ú©ÛŒØ¨ long Ùˆ short - Ø§Ú¯Ø± long Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ØŒ ÙˆÚ¯Ø±Ù†Ù‡ short
                    group['psar'] = psar_long.fillna(psar_short)
                else:
                    group['psar'] = psar_result
                
                # Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² NaN Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù¾Ø± Ú©Ù†ÛŒÙ…
                group['psar'] = group['psar'].fillna(group['close'] * 0.98)
                group['price_above_psar'] = (group['close'] > group['psar']).astype(int)
            else:
                # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                group['psar'] = group['close'] * 0.98
                group['price_above_psar'] = 1
        except Exception as e:
            logging.warning(f"PSAR calculation failed: {e}. Using default values.")
            group['psar'] = group['close'] * 0.98
            group['price_above_psar'] = 1

        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ PSAR Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ (ÙˆÛŒÚ˜Ú¯ÛŒ Ù…Ù‡Ù… 58)
        if 'psar' not in group.columns or group['psar'].isna().all():
            group['psar'] = group['close'] * 0.98
            group['price_above_psar'] = 1

        adx = ta.adx(group['high'], group['low'], group['close'], length=14)
        if adx is not None and not adx.empty:
            col_names = adx.columns.tolist()
            for col in col_names:
                if 'ADX' in col:
                    group['adx'] = adx[col]
                    break
        
        # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª (Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡)
        group['sentiment_score'] = 0
        group['sentiment_momentum'] = 0
        group['sentiment_ma_7'] = 0
        group['sentiment_ma_14'] = 0
        group['sentiment_volume'] = 0
        group['sentiment_divergence'] = 0

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø±ÛŒÙ† Ø±Ø¯ÛŒÙ
        latest_features = group.iloc[-1].to_dict()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ù‚Ø¯Ø§Ø± ATR Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Risk Management
        latest_atr = group['atr'].iloc[-1]
        
        # ğŸ”§ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† NaN Ù‡Ø§ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± inf (Ø§ØµÙ„Ø§Ø­ Ù†Ù‡Ø§ÛŒÛŒ)
        features_for_api = {}
        for k, v in latest_features.items():
            try:
                # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ùˆ validity
                if pd.notna(v):
                    # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ numeric
                    if isinstance(v, (int, float, np.integer, np.floating)):
                        if not np.isinf(v):
                            # ØªØ¨Ø¯ÛŒÙ„ numpy types Ø¨Ù‡ Python native types
                            if isinstance(v, np.integer):
                                features_for_api[k] = int(v)
                            elif isinstance(v, np.floating):
                                features_for_api[k] = float(v)
                            else:
                                features_for_api[k] = v
                    # Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ non-numericØŒ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
                    elif isinstance(v, (str, bool)):
                        features_for_api[k] = v
                    # Ø¨Ø±Ø§ÛŒ datetime objects
                    elif hasattr(v, 'timestamp'):
                        continue  # Ø±Ø¯ Ú©Ø±Ø¯Ù† timestamp Ù‡Ø§
                    else:
                        # Ø³Ø§ÛŒØ± Ø§Ù†ÙˆØ§Ø¹ - ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string
                        try:
                            str_val = str(v)
                            if str_val not in ['nan', 'inf', '-inf', 'NaT']:
                                features_for_api[k] = str_val
                        except:
                            continue  # Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± ØºÛŒØ±Ù‚Ø§Ø¨Ù„ ØªØ¨Ø¯ÛŒÙ„
            except Exception as e:
                logging.warning(f"Error processing feature {k}={v}: {e}")
                continue
        
        # Ø­Ø°Ù timestamp
        features_for_api.pop('timestamp', None)
        
        # ğŸ”§ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø¹Ù‚ÙˆÙ„ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ - Ø­ÙØ¸ Ù…Ù‚Ø¯Ø§Ø± 0)
        cleaned_features = {}
        for k, v in features_for_api.items():
            if isinstance(v, (int, float)):
                # ÙÙ‚Ø· Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®ÛŒÙ„ÛŒ Ø¨Ø²Ø±Ú¯ (Ø­ÙØ¸ 0 Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú©ÙˆÚ†Ú©)
                if abs(v) < 1e10:  # ğŸ”§ Ø­Ø°Ù Ø´Ø±Ø· > 1e-10 Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ 0
                    cleaned_features[k] = v
                else:
                    logging.warning(f"Outlier value removed: {k}={v}")
            else:
                cleaned_features[k] = v
        
        # Ø§ÙØ²ÙˆØ¯Ù† ATR Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒ (Ø¨Ø±Ø§ÛŒ Risk Management)
        if not np.isinf(latest_atr) and pd.notna(latest_atr):
            cleaned_features['_atr_value'] = float(latest_atr)
        else:
            cleaned_features['_atr_value'] = 1.0  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ù‡Ø¯Ù: 58 ÙˆÛŒÚ˜Ú¯ÛŒ)
        expected_features = 58
        actual_features = len(cleaned_features) - 1  # Ù…Ù†Ù‡Ø§ÛŒ _atr_value
        logging.info(f"ğŸ”¢ ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡: {actual_features}/58")
        
        if actual_features < expected_features:
            logging.warning(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ ({actual_features}) Ú©Ù…ØªØ± Ø§Ø² Ø§Ù†ØªØ¸Ø§Ø± ({expected_features}) Ø§Ø³Øª")
        
        return cleaned_features
        
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {e}", exc_info=True)
        return None
        
def get_prediction(payload: Dict) -> Optional[Dict]:
    """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ API Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø§ Authentication Ùˆ retry mechanism"""
    try:
        # Ø­Ø°Ù ATR Ø§Ø² payload Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø³Ø§Ù„
        atr_value = payload.pop('_atr_value', 1.0)  # Ø°Ø®ÛŒØ±Ù‡ ATR Ø¨Ø±Ø§ÛŒ Risk Management
        
        # Retry mechanism Ø¨Ø±Ø§ÛŒ API calls
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø§ Authentication
                if USE_AUTHENTICATION:
                    response = requests.post(
                        API_URL, 
                        json=payload, 
                        timeout=30,
                        auth=(API_USERNAME, API_PASSWORD)
                    )
                else:
                    response = requests.post(API_URL, json=payload, timeout=30)
                
                # Ù„Ø§Ú¯ response Ø¨Ø±Ø§ÛŒ debugging
                if attempt == 0:  # ÙÙ‚Ø· Ø¯Ø± ØªÙ„Ø§Ø´ Ø§ÙˆÙ„
                    logging.info(f"ğŸ“¡ API Response Status: {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ATR Ø¨Ù‡ Ù†ØªÛŒØ¬Ù‡
                    if result:
                        result['_atr_value'] = atr_value
                    
                    return result
                elif response.status_code == 429:
                    # ğŸ”§ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ØªØ± Rate Limiting
                    retry_after = response.headers.get('Retry-After', 90)
                    logging.warning(f"âš ï¸ Rate Limited (429). Retry after: {retry_after}s")
                    if attempt < max_retries - 1:
                        time.sleep(int(retry_after))
                        continue
                    return {'error': 'rate_limited', 'retry_after': int(retry_after)}
                elif response.status_code == 401:
                    logging.error("âŒ Authentication Error (401) - Invalid credentials")
                    logging.error(f"ğŸ’¡ Check username: {API_USERNAME}")
                    return {'error': 'authentication_failed'}
                elif response.status_code == 500:
                    logging.error("âŒ Server Error (500)")
                    try:
                        error_data = response.json()
                        logging.error(f"ğŸ“‹ Server error details: {error_data}")
                    except:
                        logging.error(f"ğŸ“‹ Server error text: {response.text[:200]}")
                    if attempt < max_retries - 1:
                        time.sleep(5)  # Ø§Ù†ØªØ¸Ø§Ø± Ú©ÙˆØªØ§Ù‡ Ù‚Ø¨Ù„ Ø§Ø² retry
                        continue
                    return {'error': 'server_error'}
                else:
                    logging.error(f"âŒ API Error: HTTP {response.status_code}")
                    if attempt < max_retries - 1:
                        time.sleep(3)
                        continue
                    return {'error': f'http_{response.status_code}'}
                    
            except requests.exceptions.Timeout:
                logging.warning(f"â° API Timeout on attempt {attempt + 1}")
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
                return {'error': 'timeout'}
            except requests.exceptions.ConnectionError:
                logging.warning(f"ğŸŒ Connection Error on attempt {attempt + 1}")
                if attempt < max_retries - 1:
                    time.sleep(10)
                    continue
                return {'error': 'connection_error'}
            except Exception as e:
                logging.error(f"âŒ Prediction request error on attempt {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                return {'error': 'unexpected_error', 'details': str(e)}
                
    except Exception as e:
        logging.error(f"âŒ Critical error in get_prediction: {e}")
        return {'error': 'critical_error', 'details': str(e)}

def save_performance_metrics():
    """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯"""
    try:
        metrics = {
            'timestamp': datetime.datetime.now().isoformat(),
            'successful_predictions': successful_predictions,
            'failed_attempts': failed_attempts,
            'iteration_count': iteration_count,
            'total_signals': len(signals_history),
            'uptime_hours': (datetime.datetime.now() - pd.Timestamp.now().floor('H')).total_seconds() / 3600,
            'current_threshold': CONFIDENCE_THRESHOLD,
            'poll_interval': POLL_INTERVAL_SECONDS,
            'model_info': api_model_info
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± CSV
        df = pd.DataFrame([metrics])
        df.to_csv(performance_log, mode='a', header=not os.path.exists(performance_log), index=False)
        
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ performance metrics: {e}")

def process_pair(symbol: str, timeframe: str, exchange: str, expected_features: Optional[List] = None) -> bool:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ø¬ÙØª Ø§Ø±Ø² Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„"""
    global successful_predictions, failed_attempts, last_processed_timestamps
    
    try:
        logging.info(f"\nğŸ” Processing {symbol} {timeframe} on {exchange.upper()}")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        df = get_latest_data(symbol, timeframe, CANDLE_HISTORY_NEEDED, exchange)
        if df is None or df.empty:
            logging.error(f"âŒ No data received for {symbol}")
            failed_attempts += 1
            return False
        
        # Ø¨Ø±Ø±Ø³ÛŒ timestamp Ø¬Ø¯ÛŒØ¯
        latest_timestamp = df['timestamp'].iloc[-1]
        pair_key = f"{symbol}_{timeframe}"
        
        if pair_key in last_processed_timestamps:
            if latest_timestamp <= last_processed_timestamps[pair_key]:
                logging.info(f"â­ï¸ No new data for {symbol} {timeframe}")
                return False
        
        last_processed_timestamps[pair_key] = latest_timestamp
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ (58 ÙˆÛŒÚ˜Ú¯ÛŒ)
        features = calculate_features(df)
        if not features:
            logging.error(f"âŒ Feature calculation failed for {symbol}")
            failed_attempts += 1
            return False
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        if expected_features and not verify_feature_consistency(features, expected_features):
            logging.warning(f"âš ï¸ Feature mismatch for {symbol} - continuing anyway")
        
        # Ø¯Ø±ÛŒØ§ÙØª ATR Ø¨Ø±Ø§ÛŒ Risk Management
        atr_value = features.get('_atr_value', 1.0)
        
        # Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        prediction_result = get_prediction(features)
        if not prediction_result:
            logging.error(f"âŒ Prediction failed for {symbol}")
            failed_attempts += 1
            return False
        
        # Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§
        if 'error' in prediction_result:
            error_type = prediction_result['error']
            if error_type == 'rate_limited':
                retry_after = prediction_result.get('retry_after', 90)
                logging.warning(f"â³ Rate limited. Waiting {retry_after}s...")
                time.sleep(retry_after)
                return False
            elif error_type == 'authentication_failed':
                logging.error("ğŸ” Authentication failed - check credentials")
                return False
            else:
                logging.error(f"âŒ API Error: {error_type}")
                failed_attempts += 1
                return False
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†ØªÛŒØ¬Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        confidence = prediction_result.get('prediction_proba', 0)
        if 'confidence' in prediction_result:
            confidence = prediction_result['confidence'].get('profit_prob', 0)
        
        prediction_class = prediction_result.get('prediction', 'NO_SIGNAL')
        if prediction_class == 1:
            prediction_class = 'PROFIT'
        elif prediction_class == 0:
            prediction_class = 'NO_PROFIT'
        
        signal = prediction_result.get('signal', prediction_class)
        threshold_used = prediction_result.get('threshold_used', CONFIDENCE_THRESHOLD)
        
        logging.info(f"ğŸ¯ Prediction for {symbol}: {signal} (Confidence: {confidence:.3f})")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ØªØ§Ù†Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        if confidence >= CONFIDENCE_THRESHOLD:
            current_price = df['close'].iloc[-1]
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Risk Management
            position_size = risk_manager.calculate_position_size(symbol, confidence, current_price, atr_value)
            stop_loss = risk_manager.calculate_stop_loss(current_price, atr_value, signal)
            take_profit = risk_manager.calculate_take_profit(current_price, atr_value, signal)
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„
            signal_data = {
                'timestamp': latest_timestamp.isoformat(),
                'symbol': symbol,
                'timeframe': timeframe,
                'exchange': exchange,
                'signal': signal,
                'confidence': confidence,
                'current_price': current_price,
                'threshold_used': threshold_used,
                'position_size': position_size,
                'stop_loss': stop_loss,
                'take_profit': take_profit,
                'atr': atr_value,
                'model_info': api_model_info.get('model_type', 'Unknown'),
                'features_count': len(features) - 1  # Ù…Ù†Ù‡Ø§ÛŒ _atr_value
            }
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„
            with signals_lock:
                signals_history.append(signal_data)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ JSON
            try:
                with open(signals_log, 'w', encoding='utf-8') as f:
                    json.dump(signals_history, f, indent=2, ensure_ascii=False)
            except Exception as e:
                logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„: {e}")
            
            # Ø§Ø±Ø³Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…
            telegram_message = format_telegram_message(
                symbol, timeframe, signal, confidence, exchange,
                position_size, stop_loss, take_profit, threshold_used
            )
            
            if send_telegram_message(telegram_message):
                logging.info(f"ğŸ“± Signal sent to Telegram for {symbol}")
            
            successful_predictions += 1
            logging.info(f"âœ… Signal generated for {symbol}: {signal} (Confidence: {confidence:.1%})")
            return True
            
        else:
            logging.info(f"âšª No signal for {symbol}: confidence {confidence:.3f} below threshold {CONFIDENCE_THRESHOLD:.3f}")
            successful_predictions += 1  # Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù‡ ÙˆÙ„ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ø¯Ø§Ø´ØªÙ‡
            return False
            
    except Exception as e:
        logging.error(f"âŒ Error processing {symbol}: {e}", exc_info=True)
        failed_attempts += 1
        return False

def monitor_pairs_concurrent():
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù† Ú†Ù†Ø¯ Ø¬ÙØª Ø§Ø±Ø²"""
    global iteration_count
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±
    expected_features = load_model_features()
    
    while True:
        try:
            iteration_count += 1
            logging.info(f"\nğŸ”„ === Iteration {iteration_count} === {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù†
            with ThreadPoolExecutor(max_workers=min(len(PAIRS_TO_MONITOR) * len(TIMEFRAMES_TO_MONITOR), 4)) as executor:
                futures = []
                
                for symbol in PAIRS_TO_MONITOR:
                    for timeframe in TIMEFRAMES_TO_MONITOR:
                        future = executor.submit(process_pair, symbol, timeframe, EXCHANGE_TO_USE, expected_features)
                        futures.append(future)
                
                # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬
                results = []
                for future in as_completed(futures):
                    try:
                        result = future.result(timeout=120)  # 2 Ø¯Ù‚ÛŒÙ‚Ù‡ timeout
                        results.append(result)
                    except Exception as e:
                        logging.error(f"Task failed: {e}")
                        results.append(False)
            
            signals_generated = sum(results)
            logging.info(f"ğŸ“Š Iteration {iteration_count} complete. Signals generated: {signals_generated}")
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø±
            save_performance_metrics()
            
            # ğŸ”§ Ø§ÙØ²Ø§ÛŒØ´ delay Ø¨ÛŒÙ† iterations
            sleep_time = max(POLL_INTERVAL_SECONDS, 180)  # Ø­Ø¯Ø§Ù‚Ù„ 3 Ø¯Ù‚ÛŒÙ‚Ù‡
            logging.info(f"ğŸ˜´ Sleeping for {sleep_time} seconds...")
            time.sleep(sleep_time)
            
        except KeyboardInterrupt:
            logging.info("â›” Received interrupt signal")
            break
        except Exception as e:
            logging.error(f"âŒ Error in monitoring loop: {e}", exc_info=True)
            time.sleep(120)  # Ø§Ø³ØªØ±Ø§Ø­Øª 2 Ø¯Ù‚ÛŒÙ‚Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¯Ø§Ù…Ù‡

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ - Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡"""
    global shutdown_message_sent
    
    # Ø«Ø¨Øª signal handler Ø¨Ø±Ø§ÛŒ Ctrl+C
    signal.signal(signal.SIGINT, signal_handler)
    
    try:
        print("\nğŸš€ Smart Trading Bot v5.3 Starting (Final Version)...")
        print("=" * 60)
        
        # Ù†Ù…Ø§ÛŒØ´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ
        print(f"ğŸ¯ Confidence Threshold: {CONFIDENCE_THRESHOLD:.0%} (Optimized for more signals)")
        print(f"â±ï¸ Poll Interval: {POLL_INTERVAL_SECONDS}s (Increased for stability)")
        print(f"ğŸ” Authentication: {'Enabled' if USE_AUTHENTICATION else 'Disabled'}")
        if USE_AUTHENTICATION:
            print(f"ğŸ‘¤ Username: {API_USERNAME}")
        
        # ØªØ³Øª Ø§ØªØµØ§Ù„ API
        if not test_api_connection():
            print("âŒ API connection test failed. Please check the API server.")
            return
        
        # Ø¨Ø±Ø±Ø³ÛŒ Authentication
        if not check_authentication():
            print("âŒ Authentication check failed. Please update credentials in config.ini")
            return
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª API
        if not check_api_health():
            print("âŒ API health check failed. Cannot proceed.")
            return
        
        print(f"âœ… All checks passed. Monitoring {len(PAIRS_TO_MONITOR)} pairs on {len(TIMEFRAMES_TO_MONITOR)} timeframes")
        print(f"ğŸ“Š Expected features: {len(load_model_features() or [])} features")
        print(f"ğŸ¯ Target: 58 complete features per prediction")
        
        # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø´Ø±ÙˆØ¹
        if TELEGRAM_ENABLED and not shutdown_message_sent:
            startup_message = f"""
ğŸš€ <b>Ø±Ø¨Ø§Øª Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ v5.3 Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯</b>

âš™ï¸ <b>ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:</b>
â€¢ Threshold: {CONFIDENCE_THRESHOLD:.0%} (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡)
â€¢ Poll Interval: {POLL_INTERVAL_SECONDS}s (Ù¾Ø§ÛŒØ¯Ø§Ø±)
â€¢ Multi-pair: {'Yes' if MULTI_PAIR_ENABLED else 'No'}
â€¢ Authentication: {'Yes' if USE_AUTHENTICATION else 'No'}

ğŸ¯ <b>Ù†Ø¸Ø§Ø±Øª Ø¨Ø±:</b>
â€¢ Ù†Ù…Ø§Ø¯Ù‡Ø§: {', '.join(PAIRS_TO_MONITOR)}
â€¢ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§: {', '.join(TIMEFRAMES_TO_MONITOR)}
â€¢ ØµØ±Ø§ÙÛŒ: {EXCHANGE_TO_USE.upper()}

ğŸ¤– <b>Ù…Ø¯Ù„:</b>
{api_model_info.get('model_type', 'Unknown')} {'(Optimized)' if api_model_info.get('is_optimized') else ''}

ğŸ’¼ <b>Risk Management:</b>
â€¢ Max Position: {MAX_POSITION_SIZE:.0%}
â€¢ Stop Loss ATR: {STOP_LOSS_ATR_MULTIPLIER}x
â€¢ Take Profit ATR: {TAKE_PROFIT_ATR_MULTIPLIER}x
â€¢ Kelly Criterion: {'Enabled' if KELLY_CRITERION_ENABLED else 'Disabled'}

ğŸ“Š <b>ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:</b>
â€¢ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù…Ù„ 58 ÙˆÛŒÚ˜Ú¯ÛŒ
â€¢ Ø´Ø§Ù…Ù„ PSAR (Ù…Ø´Ú©Ù„ v5.2 Ø­Ù„ Ø´Ø¯)
â€¢ Risk Management Ú©Ø§Ù…Ù„

ğŸ• {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

#BotStarted #v5_3 #FinalVersion #Complete58Features
"""
            send_telegram_message(startup_message)
        
        print("\nğŸ”„ Starting monitoring loop...")
        
        # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´
        monitor_pairs_concurrent()
        
    except KeyboardInterrupt:
        print("\nâ›” Shutdown signal received")
    except Exception as e:
        logging.error(f"âŒ Critical error in main: {e}", exc_info=True)
        print(f"âŒ Critical error: {e}")
    finally:
        print("\nğŸ‘‹ Bot shutting down...")
        cleanup_and_shutdown()

if __name__ == "__main__":
    main()